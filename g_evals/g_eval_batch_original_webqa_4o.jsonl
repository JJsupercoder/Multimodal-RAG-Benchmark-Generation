{"custom_id": "d5bef79a0dba11ecb1e81171463288e9_geval", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-mini-2025-04-14", "max_tokens": 200, "temperature": 1, "n": 20, "messages": [{"role": "system", "content": "You are an evaluation assistant. You will be given:\n  - A question Q.\n  - A gold/reference answer (one or more short reference sentences).\n  - A candidate/sample answer produced by a system.\n\nYour job is to **assign integer scores** (1..5) for the following criteria comparing the *candidate* to the *gold/reference*:\n\n1. correctness (1-5): How factually correct is the candidate vs the gold answer? (5 = fully correct, 1 = mostly or fully incorrect).\n2. completeness (1-5): How completely does the candidate cover the key points in the gold answer? (5 = covers all key points; 1 = almost none).\n3. precision (1-5): How concise and focused is the candidate (not too long answer)? (5 = concise & precise; 1 = verbose / many extraneous claims).\n4. coherence (1-5): Is the candidate fluent and well-structured? (5 = natural, coherent; 1 = disfluent or incoherent).\n5. relevance (1-5): Are the statements in the candidate relevant to the question and gold answer (not introducing unrelated claims)? (5 = fully relevant; 1 = mostly irrelevant).\n\nREQUIREMENTS (strict):\n- Output **ONLY** a JSON object EXACTLY of the form:\n  {\"correctness\": <1-5>, \"completeness\": <1-5>, \"precision\": <1-5>, \"coherence\": <1-5>, \"relevance\": <1-5>}\n- No additional text, explanation, or whitespace outside the JSON object.\n\nFEW-SHOT EXAMPLE (this demonstrates the required output; do not include the example in actual responses):\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"No, the capital of Germany is not Paris, the capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":5,\"coherence\":5,\"relevance\":5}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"The capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":3,\"completeness\":2,\"precision\":5,\"coherence\":5,\"relevance\":2}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"If capital stands for the central administrative region of a country, then no, Paris is not the capital of Germany. It's important to note what is the definintion of a 'capital'. However, due to the common popular opinion, a capital of a country is well defined.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":1,\"coherence\":4,\"relevance\":1}\n\nEND OF SYSTEM PROMPT."}, {"role": "user", "content": [{"type": "text", "text": "Question: "}, {"type": "text", "text": "Gold reference 1: \"Yes, there are trees near the Barcelona Pavilion that are taller than the pavilion.\""}, {"type": "text", "text": "Candidate answer: Yes, there are trees near the Barcelona Pavilion that are taller than the pavilion."}, {"type": "text", "text": "Please score the candidate exactly with the five integer ratings in JSON as instructed by the system prompt."}]}]}}
{"custom_id": "d5bcc3a80dba11ecb1e81171463288e9_geval", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-mini-2025-04-14", "max_tokens": 200, "temperature": 1, "n": 20, "messages": [{"role": "system", "content": "You are an evaluation assistant. You will be given:\n  - A question Q.\n  - A gold/reference answer (one or more short reference sentences).\n  - A candidate/sample answer produced by a system.\n\nYour job is to **assign integer scores** (1..5) for the following criteria comparing the *candidate* to the *gold/reference*:\n\n1. correctness (1-5): How factually correct is the candidate vs the gold answer? (5 = fully correct, 1 = mostly or fully incorrect).\n2. completeness (1-5): How completely does the candidate cover the key points in the gold answer? (5 = covers all key points; 1 = almost none).\n3. precision (1-5): How concise and focused is the candidate (not too long answer)? (5 = concise & precise; 1 = verbose / many extraneous claims).\n4. coherence (1-5): Is the candidate fluent and well-structured? (5 = natural, coherent; 1 = disfluent or incoherent).\n5. relevance (1-5): Are the statements in the candidate relevant to the question and gold answer (not introducing unrelated claims)? (5 = fully relevant; 1 = mostly irrelevant).\n\nREQUIREMENTS (strict):\n- Output **ONLY** a JSON object EXACTLY of the form:\n  {\"correctness\": <1-5>, \"completeness\": <1-5>, \"precision\": <1-5>, \"coherence\": <1-5>, \"relevance\": <1-5>}\n- No additional text, explanation, or whitespace outside the JSON object.\n\nFEW-SHOT EXAMPLE (this demonstrates the required output; do not include the example in actual responses):\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"No, the capital of Germany is not Paris, the capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":5,\"coherence\":5,\"relevance\":5}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"The capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":3,\"completeness\":2,\"precision\":5,\"coherence\":5,\"relevance\":2}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"If capital stands for the central administrative region of a country, then no, Paris is not the capital of Germany. It's important to note what is the definintion of a 'capital'. However, due to the common popular opinion, a capital of a country is well defined.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":1,\"coherence\":4,\"relevance\":1}\n\nEND OF SYSTEM PROMPT."}, {"role": "user", "content": [{"type": "text", "text": "Question: "}, {"type": "text", "text": "Gold reference 1: \"The 2011 Cadillac Escalade has the taller break lights.\""}, {"type": "text", "text": "Candidate answer: The 2011 Cadillac Escalade has taller brake lights compared to the Bentley Continental GT."}, {"type": "text", "text": "Please score the candidate exactly with the five integer ratings in JSON as instructed by the system prompt."}]}]}}
{"custom_id": "d5bd99860dba11ecb1e81171463288e9_geval", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-mini-2025-04-14", "max_tokens": 200, "temperature": 1, "n": 20, "messages": [{"role": "system", "content": "You are an evaluation assistant. You will be given:\n  - A question Q.\n  - A gold/reference answer (one or more short reference sentences).\n  - A candidate/sample answer produced by a system.\n\nYour job is to **assign integer scores** (1..5) for the following criteria comparing the *candidate* to the *gold/reference*:\n\n1. correctness (1-5): How factually correct is the candidate vs the gold answer? (5 = fully correct, 1 = mostly or fully incorrect).\n2. completeness (1-5): How completely does the candidate cover the key points in the gold answer? (5 = covers all key points; 1 = almost none).\n3. precision (1-5): How concise and focused is the candidate (not too long answer)? (5 = concise & precise; 1 = verbose / many extraneous claims).\n4. coherence (1-5): Is the candidate fluent and well-structured? (5 = natural, coherent; 1 = disfluent or incoherent).\n5. relevance (1-5): Are the statements in the candidate relevant to the question and gold answer (not introducing unrelated claims)? (5 = fully relevant; 1 = mostly irrelevant).\n\nREQUIREMENTS (strict):\n- Output **ONLY** a JSON object EXACTLY of the form:\n  {\"correctness\": <1-5>, \"completeness\": <1-5>, \"precision\": <1-5>, \"coherence\": <1-5>, \"relevance\": <1-5>}\n- No additional text, explanation, or whitespace outside the JSON object.\n\nFEW-SHOT EXAMPLE (this demonstrates the required output; do not include the example in actual responses):\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"No, the capital of Germany is not Paris, the capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":5,\"coherence\":5,\"relevance\":5}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"The capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":3,\"completeness\":2,\"precision\":5,\"coherence\":5,\"relevance\":2}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"If capital stands for the central administrative region of a country, then no, Paris is not the capital of Germany. It's important to note what is the definintion of a 'capital'. However, due to the common popular opinion, a capital of a country is well defined.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":1,\"coherence\":4,\"relevance\":1}\n\nEND OF SYSTEM PROMPT."}, {"role": "user", "content": [{"type": "text", "text": "Question: "}, {"type": "text", "text": "Gold reference 1: \"The color gold appeared on the uniform for the 2012 Olympic Torch carriers and didn't appear on the uniforms for the 2008 carriers.\""}, {"type": "text", "text": "Candidate answer: The color that appeared on the uniform for the 2012 Olympic Torch carriers that didn't appear on the uniforms for the 2008 carriers was white."}, {"type": "text", "text": "Please score the candidate exactly with the five integer ratings in JSON as instructed by the system prompt."}]}]}}
{"custom_id": "d5bf051e0dba11ecb1e81171463288e9_geval", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-mini-2025-04-14", "max_tokens": 200, "temperature": 1, "n": 20, "messages": [{"role": "system", "content": "You are an evaluation assistant. You will be given:\n  - A question Q.\n  - A gold/reference answer (one or more short reference sentences).\n  - A candidate/sample answer produced by a system.\n\nYour job is to **assign integer scores** (1..5) for the following criteria comparing the *candidate* to the *gold/reference*:\n\n1. correctness (1-5): How factually correct is the candidate vs the gold answer? (5 = fully correct, 1 = mostly or fully incorrect).\n2. completeness (1-5): How completely does the candidate cover the key points in the gold answer? (5 = covers all key points; 1 = almost none).\n3. precision (1-5): How concise and focused is the candidate (not too long answer)? (5 = concise & precise; 1 = verbose / many extraneous claims).\n4. coherence (1-5): Is the candidate fluent and well-structured? (5 = natural, coherent; 1 = disfluent or incoherent).\n5. relevance (1-5): Are the statements in the candidate relevant to the question and gold answer (not introducing unrelated claims)? (5 = fully relevant; 1 = mostly irrelevant).\n\nREQUIREMENTS (strict):\n- Output **ONLY** a JSON object EXACTLY of the form:\n  {\"correctness\": <1-5>, \"completeness\": <1-5>, \"precision\": <1-5>, \"coherence\": <1-5>, \"relevance\": <1-5>}\n- No additional text, explanation, or whitespace outside the JSON object.\n\nFEW-SHOT EXAMPLE (this demonstrates the required output; do not include the example in actual responses):\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"No, the capital of Germany is not Paris, the capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":5,\"coherence\":5,\"relevance\":5}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"The capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":3,\"completeness\":2,\"precision\":5,\"coherence\":5,\"relevance\":2}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"If capital stands for the central administrative region of a country, then no, Paris is not the capital of Germany. It's important to note what is the definintion of a 'capital'. However, due to the common popular opinion, a capital of a country is well defined.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":1,\"coherence\":4,\"relevance\":1}\n\nEND OF SYSTEM PROMPT."}, {"role": "user", "content": [{"type": "text", "text": "Question: "}, {"type": "text", "text": "Gold reference 1: \"The pole held by the woman in the Pirámide de Mayo monument extends to a higher height than the hat she is wearing.\""}, {"type": "text", "text": "Candidate answer: Yes, the pole held by the woman in the Pirámide de Mayo monument extends to a higher height than the hat she is wearing."}, {"type": "text", "text": "Please score the candidate exactly with the five integer ratings in JSON as instructed by the system prompt."}]}]}}
{"custom_id": "d5bea3a80dba11ecb1e81171463288e9_geval", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-mini-2025-04-14", "max_tokens": 200, "temperature": 1, "n": 20, "messages": [{"role": "system", "content": "You are an evaluation assistant. You will be given:\n  - A question Q.\n  - A gold/reference answer (one or more short reference sentences).\n  - A candidate/sample answer produced by a system.\n\nYour job is to **assign integer scores** (1..5) for the following criteria comparing the *candidate* to the *gold/reference*:\n\n1. correctness (1-5): How factually correct is the candidate vs the gold answer? (5 = fully correct, 1 = mostly or fully incorrect).\n2. completeness (1-5): How completely does the candidate cover the key points in the gold answer? (5 = covers all key points; 1 = almost none).\n3. precision (1-5): How concise and focused is the candidate (not too long answer)? (5 = concise & precise; 1 = verbose / many extraneous claims).\n4. coherence (1-5): Is the candidate fluent and well-structured? (5 = natural, coherent; 1 = disfluent or incoherent).\n5. relevance (1-5): Are the statements in the candidate relevant to the question and gold answer (not introducing unrelated claims)? (5 = fully relevant; 1 = mostly irrelevant).\n\nREQUIREMENTS (strict):\n- Output **ONLY** a JSON object EXACTLY of the form:\n  {\"correctness\": <1-5>, \"completeness\": <1-5>, \"precision\": <1-5>, \"coherence\": <1-5>, \"relevance\": <1-5>}\n- No additional text, explanation, or whitespace outside the JSON object.\n\nFEW-SHOT EXAMPLE (this demonstrates the required output; do not include the example in actual responses):\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"No, the capital of Germany is not Paris, the capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":5,\"coherence\":5,\"relevance\":5}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"The capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":3,\"completeness\":2,\"precision\":5,\"coherence\":5,\"relevance\":2}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"If capital stands for the central administrative region of a country, then no, Paris is not the capital of Germany. It's important to note what is the definintion of a 'capital'. However, due to the common popular opinion, a capital of a country is well defined.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":1,\"coherence\":4,\"relevance\":1}\n\nEND OF SYSTEM PROMPT."}, {"role": "user", "content": [{"type": "text", "text": "Question: "}, {"type": "text", "text": "Gold reference 1: \"The dresses worn by Indian Giddha dancers don't tend to be mostly black and white in color.\""}, {"type": "text", "text": "Candidate answer: No, the dresses worn by Indian Giddha dancers are typically vibrant and colorful, often featuring shades like red, green, and yellow."}, {"type": "text", "text": "Please score the candidate exactly with the five integer ratings in JSON as instructed by the system prompt."}]}]}}
{"custom_id": "d5bbe7080dba11ecb1e81171463288e9_geval", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-mini-2025-04-14", "max_tokens": 200, "temperature": 1, "n": 20, "messages": [{"role": "system", "content": "You are an evaluation assistant. You will be given:\n  - A question Q.\n  - A gold/reference answer (one or more short reference sentences).\n  - A candidate/sample answer produced by a system.\n\nYour job is to **assign integer scores** (1..5) for the following criteria comparing the *candidate* to the *gold/reference*:\n\n1. correctness (1-5): How factually correct is the candidate vs the gold answer? (5 = fully correct, 1 = mostly or fully incorrect).\n2. completeness (1-5): How completely does the candidate cover the key points in the gold answer? (5 = covers all key points; 1 = almost none).\n3. precision (1-5): How concise and focused is the candidate (not too long answer)? (5 = concise & precise; 1 = verbose / many extraneous claims).\n4. coherence (1-5): Is the candidate fluent and well-structured? (5 = natural, coherent; 1 = disfluent or incoherent).\n5. relevance (1-5): Are the statements in the candidate relevant to the question and gold answer (not introducing unrelated claims)? (5 = fully relevant; 1 = mostly irrelevant).\n\nREQUIREMENTS (strict):\n- Output **ONLY** a JSON object EXACTLY of the form:\n  {\"correctness\": <1-5>, \"completeness\": <1-5>, \"precision\": <1-5>, \"coherence\": <1-5>, \"relevance\": <1-5>}\n- No additional text, explanation, or whitespace outside the JSON object.\n\nFEW-SHOT EXAMPLE (this demonstrates the required output; do not include the example in actual responses):\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"No, the capital of Germany is not Paris, the capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":5,\"coherence\":5,\"relevance\":5}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"The capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":3,\"completeness\":2,\"precision\":5,\"coherence\":5,\"relevance\":2}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"If capital stands for the central administrative region of a country, then no, Paris is not the capital of Germany. It's important to note what is the definintion of a 'capital'. However, due to the common popular opinion, a capital of a country is well defined.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":1,\"coherence\":4,\"relevance\":1}\n\nEND OF SYSTEM PROMPT."}, {"role": "user", "content": [{"type": "text", "text": "Question: "}, {"type": "text", "text": "Gold reference 1: \"The Atrophaneura Alcinous butterfly has the same number of antennaes as the Araschnia Levana butterfly.\""}, {"type": "text", "text": "Candidate answer: Both the Atrophaneura Alcinous and Araschnia Levana butterflies have the same number of antennae, which is two."}, {"type": "text", "text": "Please score the candidate exactly with the five integer ratings in JSON as instructed by the system prompt."}]}]}}
{"custom_id": "d5bfa7800dba11ecb1e81171463288e9_geval", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-mini-2025-04-14", "max_tokens": 200, "temperature": 1, "n": 20, "messages": [{"role": "system", "content": "You are an evaluation assistant. You will be given:\n  - A question Q.\n  - A gold/reference answer (one or more short reference sentences).\n  - A candidate/sample answer produced by a system.\n\nYour job is to **assign integer scores** (1..5) for the following criteria comparing the *candidate* to the *gold/reference*:\n\n1. correctness (1-5): How factually correct is the candidate vs the gold answer? (5 = fully correct, 1 = mostly or fully incorrect).\n2. completeness (1-5): How completely does the candidate cover the key points in the gold answer? (5 = covers all key points; 1 = almost none).\n3. precision (1-5): How concise and focused is the candidate (not too long answer)? (5 = concise & precise; 1 = verbose / many extraneous claims).\n4. coherence (1-5): Is the candidate fluent and well-structured? (5 = natural, coherent; 1 = disfluent or incoherent).\n5. relevance (1-5): Are the statements in the candidate relevant to the question and gold answer (not introducing unrelated claims)? (5 = fully relevant; 1 = mostly irrelevant).\n\nREQUIREMENTS (strict):\n- Output **ONLY** a JSON object EXACTLY of the form:\n  {\"correctness\": <1-5>, \"completeness\": <1-5>, \"precision\": <1-5>, \"coherence\": <1-5>, \"relevance\": <1-5>}\n- No additional text, explanation, or whitespace outside the JSON object.\n\nFEW-SHOT EXAMPLE (this demonstrates the required output; do not include the example in actual responses):\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"No, the capital of Germany is not Paris, the capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":5,\"coherence\":5,\"relevance\":5}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"The capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":3,\"completeness\":2,\"precision\":5,\"coherence\":5,\"relevance\":2}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"If capital stands for the central administrative region of a country, then no, Paris is not the capital of Germany. It's important to note what is the definintion of a 'capital'. However, due to the common popular opinion, a capital of a country is well defined.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":1,\"coherence\":4,\"relevance\":1}\n\nEND OF SYSTEM PROMPT."}, {"role": "user", "content": [{"type": "text", "text": "Question: "}, {"type": "text", "text": "Gold reference 1: \"Yes, both the Chapter House of St. Mary's Abbey and the Chapter House of Lichfield Cathedral use brick as a building material.\""}, {"type": "text", "text": "Candidate answer: Yes, both the Chapter House of St. Mary's Abbey and the Chapter House of Lichfield Cathedral use brick as a building material."}, {"type": "text", "text": "Please score the candidate exactly with the five integer ratings in JSON as instructed by the system prompt."}]}]}}
{"custom_id": "d5bf22880dba11ecb1e81171463288e9_geval", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-mini-2025-04-14", "max_tokens": 200, "temperature": 1, "n": 20, "messages": [{"role": "system", "content": "You are an evaluation assistant. You will be given:\n  - A question Q.\n  - A gold/reference answer (one or more short reference sentences).\n  - A candidate/sample answer produced by a system.\n\nYour job is to **assign integer scores** (1..5) for the following criteria comparing the *candidate* to the *gold/reference*:\n\n1. correctness (1-5): How factually correct is the candidate vs the gold answer? (5 = fully correct, 1 = mostly or fully incorrect).\n2. completeness (1-5): How completely does the candidate cover the key points in the gold answer? (5 = covers all key points; 1 = almost none).\n3. precision (1-5): How concise and focused is the candidate (not too long answer)? (5 = concise & precise; 1 = verbose / many extraneous claims).\n4. coherence (1-5): Is the candidate fluent and well-structured? (5 = natural, coherent; 1 = disfluent or incoherent).\n5. relevance (1-5): Are the statements in the candidate relevant to the question and gold answer (not introducing unrelated claims)? (5 = fully relevant; 1 = mostly irrelevant).\n\nREQUIREMENTS (strict):\n- Output **ONLY** a JSON object EXACTLY of the form:\n  {\"correctness\": <1-5>, \"completeness\": <1-5>, \"precision\": <1-5>, \"coherence\": <1-5>, \"relevance\": <1-5>}\n- No additional text, explanation, or whitespace outside the JSON object.\n\nFEW-SHOT EXAMPLE (this demonstrates the required output; do not include the example in actual responses):\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"No, the capital of Germany is not Paris, the capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":5,\"coherence\":5,\"relevance\":5}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"The capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":3,\"completeness\":2,\"precision\":5,\"coherence\":5,\"relevance\":2}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"If capital stands for the central administrative region of a country, then no, Paris is not the capital of Germany. It's important to note what is the definintion of a 'capital'. However, due to the common popular opinion, a capital of a country is well defined.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":1,\"coherence\":4,\"relevance\":1}\n\nEND OF SYSTEM PROMPT."}, {"role": "user", "content": [{"type": "text", "text": "Question: "}, {"type": "text", "text": "Gold reference 1: \"Not all the streets of SOHO, New York have trees.\""}, {"type": "text", "text": "Candidate answer: No, not all streets in SoHo, New York have trees, as seen in the images."}, {"type": "text", "text": "Please score the candidate exactly with the five integer ratings in JSON as instructed by the system prompt."}]}]}}
{"custom_id": "d5bebe560dba11ecb1e81171463288e9_geval", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-mini-2025-04-14", "max_tokens": 200, "temperature": 1, "n": 20, "messages": [{"role": "system", "content": "You are an evaluation assistant. You will be given:\n  - A question Q.\n  - A gold/reference answer (one or more short reference sentences).\n  - A candidate/sample answer produced by a system.\n\nYour job is to **assign integer scores** (1..5) for the following criteria comparing the *candidate* to the *gold/reference*:\n\n1. correctness (1-5): How factually correct is the candidate vs the gold answer? (5 = fully correct, 1 = mostly or fully incorrect).\n2. completeness (1-5): How completely does the candidate cover the key points in the gold answer? (5 = covers all key points; 1 = almost none).\n3. precision (1-5): How concise and focused is the candidate (not too long answer)? (5 = concise & precise; 1 = verbose / many extraneous claims).\n4. coherence (1-5): Is the candidate fluent and well-structured? (5 = natural, coherent; 1 = disfluent or incoherent).\n5. relevance (1-5): Are the statements in the candidate relevant to the question and gold answer (not introducing unrelated claims)? (5 = fully relevant; 1 = mostly irrelevant).\n\nREQUIREMENTS (strict):\n- Output **ONLY** a JSON object EXACTLY of the form:\n  {\"correctness\": <1-5>, \"completeness\": <1-5>, \"precision\": <1-5>, \"coherence\": <1-5>, \"relevance\": <1-5>}\n- No additional text, explanation, or whitespace outside the JSON object.\n\nFEW-SHOT EXAMPLE (this demonstrates the required output; do not include the example in actual responses):\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"No, the capital of Germany is not Paris, the capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":5,\"coherence\":5,\"relevance\":5}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"The capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":3,\"completeness\":2,\"precision\":5,\"coherence\":5,\"relevance\":2}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"If capital stands for the central administrative region of a country, then no, Paris is not the capital of Germany. It's important to note what is the definintion of a 'capital'. However, due to the common popular opinion, a capital of a country is well defined.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":1,\"coherence\":4,\"relevance\":1}\n\nEND OF SYSTEM PROMPT."}, {"role": "user", "content": [{"type": "text", "text": "Question: "}, {"type": "text", "text": "Gold reference 1: \"Yes, there are two white dots on each of the Erebia oeme's wings.\""}, {"type": "text", "text": "Candidate answer: Yes, Erebia oeme has two white dots on each of its wings."}, {"type": "text", "text": "Please score the candidate exactly with the five integer ratings in JSON as instructed by the system prompt."}]}]}}
{"custom_id": "d5be117c0dba11ecb1e81171463288e9_geval", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-mini-2025-04-14", "max_tokens": 200, "temperature": 1, "n": 20, "messages": [{"role": "system", "content": "You are an evaluation assistant. You will be given:\n  - A question Q.\n  - A gold/reference answer (one or more short reference sentences).\n  - A candidate/sample answer produced by a system.\n\nYour job is to **assign integer scores** (1..5) for the following criteria comparing the *candidate* to the *gold/reference*:\n\n1. correctness (1-5): How factually correct is the candidate vs the gold answer? (5 = fully correct, 1 = mostly or fully incorrect).\n2. completeness (1-5): How completely does the candidate cover the key points in the gold answer? (5 = covers all key points; 1 = almost none).\n3. precision (1-5): How concise and focused is the candidate (not too long answer)? (5 = concise & precise; 1 = verbose / many extraneous claims).\n4. coherence (1-5): Is the candidate fluent and well-structured? (5 = natural, coherent; 1 = disfluent or incoherent).\n5. relevance (1-5): Are the statements in the candidate relevant to the question and gold answer (not introducing unrelated claims)? (5 = fully relevant; 1 = mostly irrelevant).\n\nREQUIREMENTS (strict):\n- Output **ONLY** a JSON object EXACTLY of the form:\n  {\"correctness\": <1-5>, \"completeness\": <1-5>, \"precision\": <1-5>, \"coherence\": <1-5>, \"relevance\": <1-5>}\n- No additional text, explanation, or whitespace outside the JSON object.\n\nFEW-SHOT EXAMPLE (this demonstrates the required output; do not include the example in actual responses):\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"No, the capital of Germany is not Paris, the capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":5,\"coherence\":5,\"relevance\":5}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"The capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":3,\"completeness\":2,\"precision\":5,\"coherence\":5,\"relevance\":2}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"If capital stands for the central administrative region of a country, then no, Paris is not the capital of Germany. It's important to note what is the definintion of a 'capital'. However, due to the common popular opinion, a capital of a country is well defined.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":1,\"coherence\":4,\"relevance\":1}\n\nEND OF SYSTEM PROMPT."}, {"role": "user", "content": [{"type": "text", "text": "Question: "}, {"type": "text", "text": "Gold reference 1: \"The headlights of the 1949 Cadillac Series 62 are round.\""}, {"type": "text", "text": "Candidate answer: The headlights of the 1949 Cadillac Series 62 are rounded."}, {"type": "text", "text": "Please score the candidate exactly with the five integer ratings in JSON as instructed by the system prompt."}]}]}}
{"custom_id": "d5bd85e00dba11ecb1e81171463288e9_geval", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-mini-2025-04-14", "max_tokens": 200, "temperature": 1, "n": 20, "messages": [{"role": "system", "content": "You are an evaluation assistant. You will be given:\n  - A question Q.\n  - A gold/reference answer (one or more short reference sentences).\n  - A candidate/sample answer produced by a system.\n\nYour job is to **assign integer scores** (1..5) for the following criteria comparing the *candidate* to the *gold/reference*:\n\n1. correctness (1-5): How factually correct is the candidate vs the gold answer? (5 = fully correct, 1 = mostly or fully incorrect).\n2. completeness (1-5): How completely does the candidate cover the key points in the gold answer? (5 = covers all key points; 1 = almost none).\n3. precision (1-5): How concise and focused is the candidate (not too long answer)? (5 = concise & precise; 1 = verbose / many extraneous claims).\n4. coherence (1-5): Is the candidate fluent and well-structured? (5 = natural, coherent; 1 = disfluent or incoherent).\n5. relevance (1-5): Are the statements in the candidate relevant to the question and gold answer (not introducing unrelated claims)? (5 = fully relevant; 1 = mostly irrelevant).\n\nREQUIREMENTS (strict):\n- Output **ONLY** a JSON object EXACTLY of the form:\n  {\"correctness\": <1-5>, \"completeness\": <1-5>, \"precision\": <1-5>, \"coherence\": <1-5>, \"relevance\": <1-5>}\n- No additional text, explanation, or whitespace outside the JSON object.\n\nFEW-SHOT EXAMPLE (this demonstrates the required output; do not include the example in actual responses):\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"No, the capital of Germany is not Paris, the capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":5,\"coherence\":5,\"relevance\":5}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"The capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":3,\"completeness\":2,\"precision\":5,\"coherence\":5,\"relevance\":2}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"If capital stands for the central administrative region of a country, then no, Paris is not the capital of Germany. It's important to note what is the definintion of a 'capital'. However, due to the common popular opinion, a capital of a country is well defined.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":1,\"coherence\":4,\"relevance\":1}\n\nEND OF SYSTEM PROMPT."}, {"role": "user", "content": [{"type": "text", "text": "Question: "}, {"type": "text", "text": "Gold reference 1: \"Only one man who carried in the Olympic Flag during the opening ceremony of the 2014 Olympics wore glasses and also had a moustache.\""}, {"type": "text", "text": "Candidate answer: One of the men who carried in the Olympic Flag during the opening ceremony of the 2014 Olympics wore glasses and had a moustache."}, {"type": "text", "text": "Please score the candidate exactly with the five integer ratings in JSON as instructed by the system prompt."}]}]}}
{"custom_id": "d5bf7e5e0dba11ecb1e81171463288e9_geval", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-mini-2025-04-14", "max_tokens": 200, "temperature": 1, "n": 20, "messages": [{"role": "system", "content": "You are an evaluation assistant. You will be given:\n  - A question Q.\n  - A gold/reference answer (one or more short reference sentences).\n  - A candidate/sample answer produced by a system.\n\nYour job is to **assign integer scores** (1..5) for the following criteria comparing the *candidate* to the *gold/reference*:\n\n1. correctness (1-5): How factually correct is the candidate vs the gold answer? (5 = fully correct, 1 = mostly or fully incorrect).\n2. completeness (1-5): How completely does the candidate cover the key points in the gold answer? (5 = covers all key points; 1 = almost none).\n3. precision (1-5): How concise and focused is the candidate (not too long answer)? (5 = concise & precise; 1 = verbose / many extraneous claims).\n4. coherence (1-5): Is the candidate fluent and well-structured? (5 = natural, coherent; 1 = disfluent or incoherent).\n5. relevance (1-5): Are the statements in the candidate relevant to the question and gold answer (not introducing unrelated claims)? (5 = fully relevant; 1 = mostly irrelevant).\n\nREQUIREMENTS (strict):\n- Output **ONLY** a JSON object EXACTLY of the form:\n  {\"correctness\": <1-5>, \"completeness\": <1-5>, \"precision\": <1-5>, \"coherence\": <1-5>, \"relevance\": <1-5>}\n- No additional text, explanation, or whitespace outside the JSON object.\n\nFEW-SHOT EXAMPLE (this demonstrates the required output; do not include the example in actual responses):\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"No, the capital of Germany is not Paris, the capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":5,\"coherence\":5,\"relevance\":5}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"The capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":3,\"completeness\":2,\"precision\":5,\"coherence\":5,\"relevance\":2}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"If capital stands for the central administrative region of a country, then no, Paris is not the capital of Germany. It's important to note what is the definintion of a 'capital'. However, due to the common popular opinion, a capital of a country is well defined.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":1,\"coherence\":4,\"relevance\":1}\n\nEND OF SYSTEM PROMPT."}, {"role": "user", "content": [{"type": "text", "text": "Question: "}, {"type": "text", "text": "Gold reference 1: \"The Geastrum quadrifidum looks more like a small shelter than the Handkea excipuliformis.\""}, {"type": "text", "text": "Candidate answer: Geastrum quadrifidum looks more like a small shelter due to its star-shaped structure, while Handkea excipuliformis has a more rounded, less shelter-like appearance."}, {"type": "text", "text": "Please score the candidate exactly with the five integer ratings in JSON as instructed by the system prompt."}]}]}}
{"custom_id": "d5bf96320dba11ecb1e81171463288e9_geval", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-mini-2025-04-14", "max_tokens": 200, "temperature": 1, "n": 20, "messages": [{"role": "system", "content": "You are an evaluation assistant. You will be given:\n  - A question Q.\n  - A gold/reference answer (one or more short reference sentences).\n  - A candidate/sample answer produced by a system.\n\nYour job is to **assign integer scores** (1..5) for the following criteria comparing the *candidate* to the *gold/reference*:\n\n1. correctness (1-5): How factually correct is the candidate vs the gold answer? (5 = fully correct, 1 = mostly or fully incorrect).\n2. completeness (1-5): How completely does the candidate cover the key points in the gold answer? (5 = covers all key points; 1 = almost none).\n3. precision (1-5): How concise and focused is the candidate (not too long answer)? (5 = concise & precise; 1 = verbose / many extraneous claims).\n4. coherence (1-5): Is the candidate fluent and well-structured? (5 = natural, coherent; 1 = disfluent or incoherent).\n5. relevance (1-5): Are the statements in the candidate relevant to the question and gold answer (not introducing unrelated claims)? (5 = fully relevant; 1 = mostly irrelevant).\n\nREQUIREMENTS (strict):\n- Output **ONLY** a JSON object EXACTLY of the form:\n  {\"correctness\": <1-5>, \"completeness\": <1-5>, \"precision\": <1-5>, \"coherence\": <1-5>, \"relevance\": <1-5>}\n- No additional text, explanation, or whitespace outside the JSON object.\n\nFEW-SHOT EXAMPLE (this demonstrates the required output; do not include the example in actual responses):\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"No, the capital of Germany is not Paris, the capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":5,\"coherence\":5,\"relevance\":5}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"The capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":3,\"completeness\":2,\"precision\":5,\"coherence\":5,\"relevance\":2}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"If capital stands for the central administrative region of a country, then no, Paris is not the capital of Germany. It's important to note what is the definintion of a 'capital'. However, due to the common popular opinion, a capital of a country is well defined.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":1,\"coherence\":4,\"relevance\":1}\n\nEND OF SYSTEM PROMPT."}, {"role": "user", "content": [{"type": "text", "text": "Question: "}, {"type": "text", "text": "Gold reference 1: \"Geranium sanguineum and Echinacea flowers have the same number of petals on them.\""}, {"type": "text", "text": "Candidate answer: Geranium sanguineum has five petals, while Echinacea flowers typically have a varying number of petals, usually around 8 to 13, so they do not have the same number of petals."}, {"type": "text", "text": "Please score the candidate exactly with the five integer ratings in JSON as instructed by the system prompt."}]}]}}
{"custom_id": "d5bd91fc0dba11ecb1e81171463288e9_geval", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-mini-2025-04-14", "max_tokens": 200, "temperature": 1, "n": 20, "messages": [{"role": "system", "content": "You are an evaluation assistant. You will be given:\n  - A question Q.\n  - A gold/reference answer (one or more short reference sentences).\n  - A candidate/sample answer produced by a system.\n\nYour job is to **assign integer scores** (1..5) for the following criteria comparing the *candidate* to the *gold/reference*:\n\n1. correctness (1-5): How factually correct is the candidate vs the gold answer? (5 = fully correct, 1 = mostly or fully incorrect).\n2. completeness (1-5): How completely does the candidate cover the key points in the gold answer? (5 = covers all key points; 1 = almost none).\n3. precision (1-5): How concise and focused is the candidate (not too long answer)? (5 = concise & precise; 1 = verbose / many extraneous claims).\n4. coherence (1-5): Is the candidate fluent and well-structured? (5 = natural, coherent; 1 = disfluent or incoherent).\n5. relevance (1-5): Are the statements in the candidate relevant to the question and gold answer (not introducing unrelated claims)? (5 = fully relevant; 1 = mostly irrelevant).\n\nREQUIREMENTS (strict):\n- Output **ONLY** a JSON object EXACTLY of the form:\n  {\"correctness\": <1-5>, \"completeness\": <1-5>, \"precision\": <1-5>, \"coherence\": <1-5>, \"relevance\": <1-5>}\n- No additional text, explanation, or whitespace outside the JSON object.\n\nFEW-SHOT EXAMPLE (this demonstrates the required output; do not include the example in actual responses):\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"No, the capital of Germany is not Paris, the capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":5,\"coherence\":5,\"relevance\":5}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"The capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":3,\"completeness\":2,\"precision\":5,\"coherence\":5,\"relevance\":2}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"If capital stands for the central administrative region of a country, then no, Paris is not the capital of Germany. It's important to note what is the definintion of a 'capital'. However, due to the common popular opinion, a capital of a country is well defined.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":1,\"coherence\":4,\"relevance\":1}\n\nEND OF SYSTEM PROMPT."}, {"role": "user", "content": [{"type": "text", "text": "Question: "}, {"type": "text", "text": "Gold reference 1: \"The Wells Cathedral's chapter house has the higher proportion of stained to regular glass on its windows.\""}, {"type": "text", "text": "Candidate answer: Wells Cathedral has a higher proportion of stained glass in its chapter house compared to Westminster Abbey."}, {"type": "text", "text": "Please score the candidate exactly with the five integer ratings in JSON as instructed by the system prompt."}]}]}}
{"custom_id": "d5bd857c0dba11ecb1e81171463288e9_geval", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-mini-2025-04-14", "max_tokens": 200, "temperature": 1, "n": 20, "messages": [{"role": "system", "content": "You are an evaluation assistant. You will be given:\n  - A question Q.\n  - A gold/reference answer (one or more short reference sentences).\n  - A candidate/sample answer produced by a system.\n\nYour job is to **assign integer scores** (1..5) for the following criteria comparing the *candidate* to the *gold/reference*:\n\n1. correctness (1-5): How factually correct is the candidate vs the gold answer? (5 = fully correct, 1 = mostly or fully incorrect).\n2. completeness (1-5): How completely does the candidate cover the key points in the gold answer? (5 = covers all key points; 1 = almost none).\n3. precision (1-5): How concise and focused is the candidate (not too long answer)? (5 = concise & precise; 1 = verbose / many extraneous claims).\n4. coherence (1-5): Is the candidate fluent and well-structured? (5 = natural, coherent; 1 = disfluent or incoherent).\n5. relevance (1-5): Are the statements in the candidate relevant to the question and gold answer (not introducing unrelated claims)? (5 = fully relevant; 1 = mostly irrelevant).\n\nREQUIREMENTS (strict):\n- Output **ONLY** a JSON object EXACTLY of the form:\n  {\"correctness\": <1-5>, \"completeness\": <1-5>, \"precision\": <1-5>, \"coherence\": <1-5>, \"relevance\": <1-5>}\n- No additional text, explanation, or whitespace outside the JSON object.\n\nFEW-SHOT EXAMPLE (this demonstrates the required output; do not include the example in actual responses):\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"No, the capital of Germany is not Paris, the capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":5,\"coherence\":5,\"relevance\":5}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"The capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":3,\"completeness\":2,\"precision\":5,\"coherence\":5,\"relevance\":2}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"If capital stands for the central administrative region of a country, then no, Paris is not the capital of Germany. It's important to note what is the definintion of a 'capital'. However, due to the common popular opinion, a capital of a country is well defined.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":1,\"coherence\":4,\"relevance\":1}\n\nEND OF SYSTEM PROMPT."}, {"role": "user", "content": [{"type": "text", "text": "Question: "}, {"type": "text", "text": "Gold reference 1: \"Rep. Joaquin Castro does, in fact, have a tiny mole on the right side of his face.\""}, {"type": "text", "text": "Candidate answer: Yes, Rep. Joaquin Castro has a small mole on the right side of his face."}, {"type": "text", "text": "Please score the candidate exactly with the five integer ratings in JSON as instructed by the system prompt."}]}]}}
{"custom_id": "d5bc77360dba11ecb1e81171463288e9_geval", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-mini-2025-04-14", "max_tokens": 200, "temperature": 1, "n": 20, "messages": [{"role": "system", "content": "You are an evaluation assistant. You will be given:\n  - A question Q.\n  - A gold/reference answer (one or more short reference sentences).\n  - A candidate/sample answer produced by a system.\n\nYour job is to **assign integer scores** (1..5) for the following criteria comparing the *candidate* to the *gold/reference*:\n\n1. correctness (1-5): How factually correct is the candidate vs the gold answer? (5 = fully correct, 1 = mostly or fully incorrect).\n2. completeness (1-5): How completely does the candidate cover the key points in the gold answer? (5 = covers all key points; 1 = almost none).\n3. precision (1-5): How concise and focused is the candidate (not too long answer)? (5 = concise & precise; 1 = verbose / many extraneous claims).\n4. coherence (1-5): Is the candidate fluent and well-structured? (5 = natural, coherent; 1 = disfluent or incoherent).\n5. relevance (1-5): Are the statements in the candidate relevant to the question and gold answer (not introducing unrelated claims)? (5 = fully relevant; 1 = mostly irrelevant).\n\nREQUIREMENTS (strict):\n- Output **ONLY** a JSON object EXACTLY of the form:\n  {\"correctness\": <1-5>, \"completeness\": <1-5>, \"precision\": <1-5>, \"coherence\": <1-5>, \"relevance\": <1-5>}\n- No additional text, explanation, or whitespace outside the JSON object.\n\nFEW-SHOT EXAMPLE (this demonstrates the required output; do not include the example in actual responses):\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"No, the capital of Germany is not Paris, the capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":5,\"coherence\":5,\"relevance\":5}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"The capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":3,\"completeness\":2,\"precision\":5,\"coherence\":5,\"relevance\":2}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"If capital stands for the central administrative region of a country, then no, Paris is not the capital of Germany. It's important to note what is the definintion of a 'capital'. However, due to the common popular opinion, a capital of a country is well defined.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":1,\"coherence\":4,\"relevance\":1}\n\nEND OF SYSTEM PROMPT."}, {"role": "user", "content": [{"type": "text", "text": "Question: "}, {"type": "text", "text": "Gold reference 1: \"Eleven arches are on the facade of the Cabildo in Buenos Aires, Argentina.\""}, {"type": "text", "text": "Candidate answer: The facade of the Cabildo in Buenos Aires features 12 arches."}, {"type": "text", "text": "Please score the candidate exactly with the five integer ratings in JSON as instructed by the system prompt."}]}]}}
{"custom_id": "d5bc3b680dba11ecb1e81171463288e9_geval", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-mini-2025-04-14", "max_tokens": 200, "temperature": 1, "n": 20, "messages": [{"role": "system", "content": "You are an evaluation assistant. You will be given:\n  - A question Q.\n  - A gold/reference answer (one or more short reference sentences).\n  - A candidate/sample answer produced by a system.\n\nYour job is to **assign integer scores** (1..5) for the following criteria comparing the *candidate* to the *gold/reference*:\n\n1. correctness (1-5): How factually correct is the candidate vs the gold answer? (5 = fully correct, 1 = mostly or fully incorrect).\n2. completeness (1-5): How completely does the candidate cover the key points in the gold answer? (5 = covers all key points; 1 = almost none).\n3. precision (1-5): How concise and focused is the candidate (not too long answer)? (5 = concise & precise; 1 = verbose / many extraneous claims).\n4. coherence (1-5): Is the candidate fluent and well-structured? (5 = natural, coherent; 1 = disfluent or incoherent).\n5. relevance (1-5): Are the statements in the candidate relevant to the question and gold answer (not introducing unrelated claims)? (5 = fully relevant; 1 = mostly irrelevant).\n\nREQUIREMENTS (strict):\n- Output **ONLY** a JSON object EXACTLY of the form:\n  {\"correctness\": <1-5>, \"completeness\": <1-5>, \"precision\": <1-5>, \"coherence\": <1-5>, \"relevance\": <1-5>}\n- No additional text, explanation, or whitespace outside the JSON object.\n\nFEW-SHOT EXAMPLE (this demonstrates the required output; do not include the example in actual responses):\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"No, the capital of Germany is not Paris, the capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":5,\"coherence\":5,\"relevance\":5}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"The capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":3,\"completeness\":2,\"precision\":5,\"coherence\":5,\"relevance\":2}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"If capital stands for the central administrative region of a country, then no, Paris is not the capital of Germany. It's important to note what is the definintion of a 'capital'. However, due to the common popular opinion, a capital of a country is well defined.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":1,\"coherence\":4,\"relevance\":1}\n\nEND OF SYSTEM PROMPT."}, {"role": "user", "content": [{"type": "text", "text": "Question: "}, {"type": "text", "text": "Gold reference 1: \"San Miguel Chapel in Santa Fe does not have a roof that is on the same level at all parts of the structure.\""}, {"type": "text", "text": "Candidate answer: No, the roof of San Miguel Chapel is not on the same level at all parts of the structure."}, {"type": "text", "text": "Please score the candidate exactly with the five integer ratings in JSON as instructed by the system prompt."}]}]}}
{"custom_id": "d5bf47b80dba11ecb1e81171463288e9_geval", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-mini-2025-04-14", "max_tokens": 200, "temperature": 1, "n": 20, "messages": [{"role": "system", "content": "You are an evaluation assistant. You will be given:\n  - A question Q.\n  - A gold/reference answer (one or more short reference sentences).\n  - A candidate/sample answer produced by a system.\n\nYour job is to **assign integer scores** (1..5) for the following criteria comparing the *candidate* to the *gold/reference*:\n\n1. correctness (1-5): How factually correct is the candidate vs the gold answer? (5 = fully correct, 1 = mostly or fully incorrect).\n2. completeness (1-5): How completely does the candidate cover the key points in the gold answer? (5 = covers all key points; 1 = almost none).\n3. precision (1-5): How concise and focused is the candidate (not too long answer)? (5 = concise & precise; 1 = verbose / many extraneous claims).\n4. coherence (1-5): Is the candidate fluent and well-structured? (5 = natural, coherent; 1 = disfluent or incoherent).\n5. relevance (1-5): Are the statements in the candidate relevant to the question and gold answer (not introducing unrelated claims)? (5 = fully relevant; 1 = mostly irrelevant).\n\nREQUIREMENTS (strict):\n- Output **ONLY** a JSON object EXACTLY of the form:\n  {\"correctness\": <1-5>, \"completeness\": <1-5>, \"precision\": <1-5>, \"coherence\": <1-5>, \"relevance\": <1-5>}\n- No additional text, explanation, or whitespace outside the JSON object.\n\nFEW-SHOT EXAMPLE (this demonstrates the required output; do not include the example in actual responses):\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"No, the capital of Germany is not Paris, the capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":5,\"coherence\":5,\"relevance\":5}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"The capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":3,\"completeness\":2,\"precision\":5,\"coherence\":5,\"relevance\":2}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"If capital stands for the central administrative region of a country, then no, Paris is not the capital of Germany. It's important to note what is the definintion of a 'capital'. However, due to the common popular opinion, a capital of a country is well defined.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":1,\"coherence\":4,\"relevance\":1}\n\nEND OF SYSTEM PROMPT."}, {"role": "user", "content": [{"type": "text", "text": "Question: "}, {"type": "text", "text": "Gold reference 1: \"No, the colour on the majority of the upper side of the wings of Celastrina ladon is not found anywhere on Deilephila elpenor.\""}, {"type": "text", "text": "Candidate answer: The upper side of the wings of Celastrina ladon is predominantly blue, while Deilephila elpenor features a mix of green and pink, indicating that the colors are not found in the same form on both species."}, {"type": "text", "text": "Please score the candidate exactly with the five integer ratings in JSON as instructed by the system prompt."}]}]}}
{"custom_id": "d5bbd7540dba11ecb1e81171463288e9_geval", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-mini-2025-04-14", "max_tokens": 200, "temperature": 1, "n": 20, "messages": [{"role": "system", "content": "You are an evaluation assistant. You will be given:\n  - A question Q.\n  - A gold/reference answer (one or more short reference sentences).\n  - A candidate/sample answer produced by a system.\n\nYour job is to **assign integer scores** (1..5) for the following criteria comparing the *candidate* to the *gold/reference*:\n\n1. correctness (1-5): How factually correct is the candidate vs the gold answer? (5 = fully correct, 1 = mostly or fully incorrect).\n2. completeness (1-5): How completely does the candidate cover the key points in the gold answer? (5 = covers all key points; 1 = almost none).\n3. precision (1-5): How concise and focused is the candidate (not too long answer)? (5 = concise & precise; 1 = verbose / many extraneous claims).\n4. coherence (1-5): Is the candidate fluent and well-structured? (5 = natural, coherent; 1 = disfluent or incoherent).\n5. relevance (1-5): Are the statements in the candidate relevant to the question and gold answer (not introducing unrelated claims)? (5 = fully relevant; 1 = mostly irrelevant).\n\nREQUIREMENTS (strict):\n- Output **ONLY** a JSON object EXACTLY of the form:\n  {\"correctness\": <1-5>, \"completeness\": <1-5>, \"precision\": <1-5>, \"coherence\": <1-5>, \"relevance\": <1-5>}\n- No additional text, explanation, or whitespace outside the JSON object.\n\nFEW-SHOT EXAMPLE (this demonstrates the required output; do not include the example in actual responses):\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"No, the capital of Germany is not Paris, the capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":5,\"coherence\":5,\"relevance\":5}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"The capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":3,\"completeness\":2,\"precision\":5,\"coherence\":5,\"relevance\":2}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"If capital stands for the central administrative region of a country, then no, Paris is not the capital of Germany. It's important to note what is the definintion of a 'capital'. However, due to the common popular opinion, a capital of a country is well defined.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":1,\"coherence\":4,\"relevance\":1}\n\nEND OF SYSTEM PROMPT."}, {"role": "user", "content": [{"type": "text", "text": "Question: "}, {"type": "text", "text": "Gold reference 1: \"The fence in font of the building is taller than a typical bicycle.\""}, {"type": "text", "text": "Candidate answer: The fence in front of The Glass House in Fulham is shorter than a bicycle."}, {"type": "text", "text": "Please score the candidate exactly with the five integer ratings in JSON as instructed by the system prompt."}]}]}}
{"custom_id": "d5bcdffa0dba11ecb1e81171463288e9_geval", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-mini-2025-04-14", "max_tokens": 200, "temperature": 1, "n": 20, "messages": [{"role": "system", "content": "You are an evaluation assistant. You will be given:\n  - A question Q.\n  - A gold/reference answer (one or more short reference sentences).\n  - A candidate/sample answer produced by a system.\n\nYour job is to **assign integer scores** (1..5) for the following criteria comparing the *candidate* to the *gold/reference*:\n\n1. correctness (1-5): How factually correct is the candidate vs the gold answer? (5 = fully correct, 1 = mostly or fully incorrect).\n2. completeness (1-5): How completely does the candidate cover the key points in the gold answer? (5 = covers all key points; 1 = almost none).\n3. precision (1-5): How concise and focused is the candidate (not too long answer)? (5 = concise & precise; 1 = verbose / many extraneous claims).\n4. coherence (1-5): Is the candidate fluent and well-structured? (5 = natural, coherent; 1 = disfluent or incoherent).\n5. relevance (1-5): Are the statements in the candidate relevant to the question and gold answer (not introducing unrelated claims)? (5 = fully relevant; 1 = mostly irrelevant).\n\nREQUIREMENTS (strict):\n- Output **ONLY** a JSON object EXACTLY of the form:\n  {\"correctness\": <1-5>, \"completeness\": <1-5>, \"precision\": <1-5>, \"coherence\": <1-5>, \"relevance\": <1-5>}\n- No additional text, explanation, or whitespace outside the JSON object.\n\nFEW-SHOT EXAMPLE (this demonstrates the required output; do not include the example in actual responses):\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"No, the capital of Germany is not Paris, the capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":5,\"coherence\":5,\"relevance\":5}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"The capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":3,\"completeness\":2,\"precision\":5,\"coherence\":5,\"relevance\":2}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"If capital stands for the central administrative region of a country, then no, Paris is not the capital of Germany. It's important to note what is the definintion of a 'capital'. However, due to the common popular opinion, a capital of a country is well defined.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":1,\"coherence\":4,\"relevance\":1}\n\nEND OF SYSTEM PROMPT."}, {"role": "user", "content": [{"type": "text", "text": "Question: "}, {"type": "text", "text": "Gold reference 1: \"The white \"I'm a Man\" signs at the \"I'm a Man\" mural in Memphis are rectangular.\""}, {"type": "text", "text": "Candidate answer: The white \"I'm a Man\" signs at the mural in Memphis are rectangular."}, {"type": "text", "text": "Please score the candidate exactly with the five integer ratings in JSON as instructed by the system prompt."}]}]}}
{"custom_id": "d5bbeb7c0dba11ecb1e81171463288e9_geval", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-mini-2025-04-14", "max_tokens": 200, "temperature": 1, "n": 20, "messages": [{"role": "system", "content": "You are an evaluation assistant. You will be given:\n  - A question Q.\n  - A gold/reference answer (one or more short reference sentences).\n  - A candidate/sample answer produced by a system.\n\nYour job is to **assign integer scores** (1..5) for the following criteria comparing the *candidate* to the *gold/reference*:\n\n1. correctness (1-5): How factually correct is the candidate vs the gold answer? (5 = fully correct, 1 = mostly or fully incorrect).\n2. completeness (1-5): How completely does the candidate cover the key points in the gold answer? (5 = covers all key points; 1 = almost none).\n3. precision (1-5): How concise and focused is the candidate (not too long answer)? (5 = concise & precise; 1 = verbose / many extraneous claims).\n4. coherence (1-5): Is the candidate fluent and well-structured? (5 = natural, coherent; 1 = disfluent or incoherent).\n5. relevance (1-5): Are the statements in the candidate relevant to the question and gold answer (not introducing unrelated claims)? (5 = fully relevant; 1 = mostly irrelevant).\n\nREQUIREMENTS (strict):\n- Output **ONLY** a JSON object EXACTLY of the form:\n  {\"correctness\": <1-5>, \"completeness\": <1-5>, \"precision\": <1-5>, \"coherence\": <1-5>, \"relevance\": <1-5>}\n- No additional text, explanation, or whitespace outside the JSON object.\n\nFEW-SHOT EXAMPLE (this demonstrates the required output; do not include the example in actual responses):\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"No, the capital of Germany is not Paris, the capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":5,\"coherence\":5,\"relevance\":5}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"The capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":3,\"completeness\":2,\"precision\":5,\"coherence\":5,\"relevance\":2}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"If capital stands for the central administrative region of a country, then no, Paris is not the capital of Germany. It's important to note what is the definintion of a 'capital'. However, due to the common popular opinion, a capital of a country is well defined.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":1,\"coherence\":4,\"relevance\":1}\n\nEND OF SYSTEM PROMPT."}, {"role": "user", "content": [{"type": "text", "text": "Question: "}, {"type": "text", "text": "Gold reference 1: \"The window awnings of the Kyrkvillan at Stora Gungan have stripes.\""}, {"type": "text", "text": "Candidate answer: The window awnings of the Kyrkvillan at Stora Gungan feature a traditional style with a design that includes stripes."}, {"type": "text", "text": "Please score the candidate exactly with the five integer ratings in JSON as instructed by the system prompt."}]}]}}
{"custom_id": "d5bf899e0dba11ecb1e81171463288e9_geval", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-mini-2025-04-14", "max_tokens": 200, "temperature": 1, "n": 20, "messages": [{"role": "system", "content": "You are an evaluation assistant. You will be given:\n  - A question Q.\n  - A gold/reference answer (one or more short reference sentences).\n  - A candidate/sample answer produced by a system.\n\nYour job is to **assign integer scores** (1..5) for the following criteria comparing the *candidate* to the *gold/reference*:\n\n1. correctness (1-5): How factually correct is the candidate vs the gold answer? (5 = fully correct, 1 = mostly or fully incorrect).\n2. completeness (1-5): How completely does the candidate cover the key points in the gold answer? (5 = covers all key points; 1 = almost none).\n3. precision (1-5): How concise and focused is the candidate (not too long answer)? (5 = concise & precise; 1 = verbose / many extraneous claims).\n4. coherence (1-5): Is the candidate fluent and well-structured? (5 = natural, coherent; 1 = disfluent or incoherent).\n5. relevance (1-5): Are the statements in the candidate relevant to the question and gold answer (not introducing unrelated claims)? (5 = fully relevant; 1 = mostly irrelevant).\n\nREQUIREMENTS (strict):\n- Output **ONLY** a JSON object EXACTLY of the form:\n  {\"correctness\": <1-5>, \"completeness\": <1-5>, \"precision\": <1-5>, \"coherence\": <1-5>, \"relevance\": <1-5>}\n- No additional text, explanation, or whitespace outside the JSON object.\n\nFEW-SHOT EXAMPLE (this demonstrates the required output; do not include the example in actual responses):\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"No, the capital of Germany is not Paris, the capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":5,\"coherence\":5,\"relevance\":5}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"The capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":3,\"completeness\":2,\"precision\":5,\"coherence\":5,\"relevance\":2}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"If capital stands for the central administrative region of a country, then no, Paris is not the capital of Germany. It's important to note what is the definintion of a 'capital'. However, due to the common popular opinion, a capital of a country is well defined.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":1,\"coherence\":4,\"relevance\":1}\n\nEND OF SYSTEM PROMPT."}, {"role": "user", "content": [{"type": "text", "text": "Question: "}, {"type": "text", "text": "Gold reference 1: \"No, neither painting has definite shapes.\""}, {"type": "text", "text": "Candidate answer: Both paintings by Ravi Mandlik and Carle Hessay contain abstract elements, with Hessay's work featuring strongly contrasting shapes and angles."}, {"type": "text", "text": "Please score the candidate exactly with the five integer ratings in JSON as instructed by the system prompt."}]}]}}
{"custom_id": "d5be0bdc0dba11ecb1e81171463288e9_geval", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-mini-2025-04-14", "max_tokens": 200, "temperature": 1, "n": 20, "messages": [{"role": "system", "content": "You are an evaluation assistant. You will be given:\n  - A question Q.\n  - A gold/reference answer (one or more short reference sentences).\n  - A candidate/sample answer produced by a system.\n\nYour job is to **assign integer scores** (1..5) for the following criteria comparing the *candidate* to the *gold/reference*:\n\n1. correctness (1-5): How factually correct is the candidate vs the gold answer? (5 = fully correct, 1 = mostly or fully incorrect).\n2. completeness (1-5): How completely does the candidate cover the key points in the gold answer? (5 = covers all key points; 1 = almost none).\n3. precision (1-5): How concise and focused is the candidate (not too long answer)? (5 = concise & precise; 1 = verbose / many extraneous claims).\n4. coherence (1-5): Is the candidate fluent and well-structured? (5 = natural, coherent; 1 = disfluent or incoherent).\n5. relevance (1-5): Are the statements in the candidate relevant to the question and gold answer (not introducing unrelated claims)? (5 = fully relevant; 1 = mostly irrelevant).\n\nREQUIREMENTS (strict):\n- Output **ONLY** a JSON object EXACTLY of the form:\n  {\"correctness\": <1-5>, \"completeness\": <1-5>, \"precision\": <1-5>, \"coherence\": <1-5>, \"relevance\": <1-5>}\n- No additional text, explanation, or whitespace outside the JSON object.\n\nFEW-SHOT EXAMPLE (this demonstrates the required output; do not include the example in actual responses):\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"No, the capital of Germany is not Paris, the capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":5,\"coherence\":5,\"relevance\":5}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"The capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":3,\"completeness\":2,\"precision\":5,\"coherence\":5,\"relevance\":2}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"If capital stands for the central administrative region of a country, then no, Paris is not the capital of Germany. It's important to note what is the definintion of a 'capital'. However, due to the common popular opinion, a capital of a country is well defined.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":1,\"coherence\":4,\"relevance\":1}\n\nEND OF SYSTEM PROMPT."}, {"role": "user", "content": [{"type": "text", "text": "Question: "}, {"type": "text", "text": "Gold reference 1: \"The artist is using a ribbon that is attached to the hat and tied around her neck to keep it in place.\""}, {"type": "text", "text": "Candidate answer: The artist is using a ribbon tied under her chin to keep her hat in place in the Portrait of the Artist."}, {"type": "text", "text": "Please score the candidate exactly with the five integer ratings in JSON as instructed by the system prompt."}]}]}}
{"custom_id": "d5bee55c0dba11ecb1e81171463288e9_geval", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-mini-2025-04-14", "max_tokens": 200, "temperature": 1, "n": 20, "messages": [{"role": "system", "content": "You are an evaluation assistant. You will be given:\n  - A question Q.\n  - A gold/reference answer (one or more short reference sentences).\n  - A candidate/sample answer produced by a system.\n\nYour job is to **assign integer scores** (1..5) for the following criteria comparing the *candidate* to the *gold/reference*:\n\n1. correctness (1-5): How factually correct is the candidate vs the gold answer? (5 = fully correct, 1 = mostly or fully incorrect).\n2. completeness (1-5): How completely does the candidate cover the key points in the gold answer? (5 = covers all key points; 1 = almost none).\n3. precision (1-5): How concise and focused is the candidate (not too long answer)? (5 = concise & precise; 1 = verbose / many extraneous claims).\n4. coherence (1-5): Is the candidate fluent and well-structured? (5 = natural, coherent; 1 = disfluent or incoherent).\n5. relevance (1-5): Are the statements in the candidate relevant to the question and gold answer (not introducing unrelated claims)? (5 = fully relevant; 1 = mostly irrelevant).\n\nREQUIREMENTS (strict):\n- Output **ONLY** a JSON object EXACTLY of the form:\n  {\"correctness\": <1-5>, \"completeness\": <1-5>, \"precision\": <1-5>, \"coherence\": <1-5>, \"relevance\": <1-5>}\n- No additional text, explanation, or whitespace outside the JSON object.\n\nFEW-SHOT EXAMPLE (this demonstrates the required output; do not include the example in actual responses):\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"No, the capital of Germany is not Paris, the capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":5,\"coherence\":5,\"relevance\":5}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"The capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":3,\"completeness\":2,\"precision\":5,\"coherence\":5,\"relevance\":2}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"If capital stands for the central administrative region of a country, then no, Paris is not the capital of Germany. It's important to note what is the definintion of a 'capital'. However, due to the common popular opinion, a capital of a country is well defined.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":1,\"coherence\":4,\"relevance\":1}\n\nEND OF SYSTEM PROMPT."}, {"role": "user", "content": [{"type": "text", "text": "Question: "}, {"type": "text", "text": "Gold reference 1: \"One of the medalists in the Men's Snowboard Cross event at the 2010 Olympics had a small patch of hair below their lower lip.\""}, {"type": "text", "text": "Candidate answer: One of the medalists in the Men's Snowboard Cross event at the 2010 Olympics had a small patch of hair below their lower lip."}, {"type": "text", "text": "Please score the candidate exactly with the five integer ratings in JSON as instructed by the system prompt."}]}]}}
{"custom_id": "d5bda9c60dba11ecb1e81171463288e9_geval", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-mini-2025-04-14", "max_tokens": 200, "temperature": 1, "n": 20, "messages": [{"role": "system", "content": "You are an evaluation assistant. You will be given:\n  - A question Q.\n  - A gold/reference answer (one or more short reference sentences).\n  - A candidate/sample answer produced by a system.\n\nYour job is to **assign integer scores** (1..5) for the following criteria comparing the *candidate* to the *gold/reference*:\n\n1. correctness (1-5): How factually correct is the candidate vs the gold answer? (5 = fully correct, 1 = mostly or fully incorrect).\n2. completeness (1-5): How completely does the candidate cover the key points in the gold answer? (5 = covers all key points; 1 = almost none).\n3. precision (1-5): How concise and focused is the candidate (not too long answer)? (5 = concise & precise; 1 = verbose / many extraneous claims).\n4. coherence (1-5): Is the candidate fluent and well-structured? (5 = natural, coherent; 1 = disfluent or incoherent).\n5. relevance (1-5): Are the statements in the candidate relevant to the question and gold answer (not introducing unrelated claims)? (5 = fully relevant; 1 = mostly irrelevant).\n\nREQUIREMENTS (strict):\n- Output **ONLY** a JSON object EXACTLY of the form:\n  {\"correctness\": <1-5>, \"completeness\": <1-5>, \"precision\": <1-5>, \"coherence\": <1-5>, \"relevance\": <1-5>}\n- No additional text, explanation, or whitespace outside the JSON object.\n\nFEW-SHOT EXAMPLE (this demonstrates the required output; do not include the example in actual responses):\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"No, the capital of Germany is not Paris, the capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":5,\"coherence\":5,\"relevance\":5}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"The capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":3,\"completeness\":2,\"precision\":5,\"coherence\":5,\"relevance\":2}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"If capital stands for the central administrative region of a country, then no, Paris is not the capital of Germany. It's important to note what is the definintion of a 'capital'. However, due to the common popular opinion, a capital of a country is well defined.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":1,\"coherence\":4,\"relevance\":1}\n\nEND OF SYSTEM PROMPT."}, {"role": "user", "content": [{"type": "text", "text": "Question: "}, {"type": "text", "text": "Gold reference 1: \"They are constructed from red bricks.\""}, {"type": "text", "text": "Candidate answer: Both the Columbus State University College of the Arts Uptown and the UNCG School of Music, Theatre and Dance buildings are constructed from brick."}, {"type": "text", "text": "Please score the candidate exactly with the five integer ratings in JSON as instructed by the system prompt."}]}]}}
{"custom_id": "d5bdae760dba11ecb1e81171463288e9_geval", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-mini-2025-04-14", "max_tokens": 200, "temperature": 1, "n": 20, "messages": [{"role": "system", "content": "You are an evaluation assistant. You will be given:\n  - A question Q.\n  - A gold/reference answer (one or more short reference sentences).\n  - A candidate/sample answer produced by a system.\n\nYour job is to **assign integer scores** (1..5) for the following criteria comparing the *candidate* to the *gold/reference*:\n\n1. correctness (1-5): How factually correct is the candidate vs the gold answer? (5 = fully correct, 1 = mostly or fully incorrect).\n2. completeness (1-5): How completely does the candidate cover the key points in the gold answer? (5 = covers all key points; 1 = almost none).\n3. precision (1-5): How concise and focused is the candidate (not too long answer)? (5 = concise & precise; 1 = verbose / many extraneous claims).\n4. coherence (1-5): Is the candidate fluent and well-structured? (5 = natural, coherent; 1 = disfluent or incoherent).\n5. relevance (1-5): Are the statements in the candidate relevant to the question and gold answer (not introducing unrelated claims)? (5 = fully relevant; 1 = mostly irrelevant).\n\nREQUIREMENTS (strict):\n- Output **ONLY** a JSON object EXACTLY of the form:\n  {\"correctness\": <1-5>, \"completeness\": <1-5>, \"precision\": <1-5>, \"coherence\": <1-5>, \"relevance\": <1-5>}\n- No additional text, explanation, or whitespace outside the JSON object.\n\nFEW-SHOT EXAMPLE (this demonstrates the required output; do not include the example in actual responses):\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"No, the capital of Germany is not Paris, the capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":5,\"coherence\":5,\"relevance\":5}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"The capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":3,\"completeness\":2,\"precision\":5,\"coherence\":5,\"relevance\":2}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"If capital stands for the central administrative region of a country, then no, Paris is not the capital of Germany. It's important to note what is the definintion of a 'capital'. However, due to the common popular opinion, a capital of a country is well defined.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":1,\"coherence\":4,\"relevance\":1}\n\nEND OF SYSTEM PROMPT."}, {"role": "user", "content": [{"type": "text", "text": "Question: "}, {"type": "text", "text": "Gold reference 1: \"You can buy a USA Today newspaper near the building with green shutters in the French Quarter.\""}, {"type": "text", "text": "Candidate answer: You can buy the 'New Orleans Advocate' near the building with green shutters in the French Quarter."}, {"type": "text", "text": "Please score the candidate exactly with the five integer ratings in JSON as instructed by the system prompt."}]}]}}
{"custom_id": "d5be48ae0dba11ecb1e81171463288e9_geval", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-mini-2025-04-14", "max_tokens": 200, "temperature": 1, "n": 20, "messages": [{"role": "system", "content": "You are an evaluation assistant. You will be given:\n  - A question Q.\n  - A gold/reference answer (one or more short reference sentences).\n  - A candidate/sample answer produced by a system.\n\nYour job is to **assign integer scores** (1..5) for the following criteria comparing the *candidate* to the *gold/reference*:\n\n1. correctness (1-5): How factually correct is the candidate vs the gold answer? (5 = fully correct, 1 = mostly or fully incorrect).\n2. completeness (1-5): How completely does the candidate cover the key points in the gold answer? (5 = covers all key points; 1 = almost none).\n3. precision (1-5): How concise and focused is the candidate (not too long answer)? (5 = concise & precise; 1 = verbose / many extraneous claims).\n4. coherence (1-5): Is the candidate fluent and well-structured? (5 = natural, coherent; 1 = disfluent or incoherent).\n5. relevance (1-5): Are the statements in the candidate relevant to the question and gold answer (not introducing unrelated claims)? (5 = fully relevant; 1 = mostly irrelevant).\n\nREQUIREMENTS (strict):\n- Output **ONLY** a JSON object EXACTLY of the form:\n  {\"correctness\": <1-5>, \"completeness\": <1-5>, \"precision\": <1-5>, \"coherence\": <1-5>, \"relevance\": <1-5>}\n- No additional text, explanation, or whitespace outside the JSON object.\n\nFEW-SHOT EXAMPLE (this demonstrates the required output; do not include the example in actual responses):\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"No, the capital of Germany is not Paris, the capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":5,\"coherence\":5,\"relevance\":5}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"The capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":3,\"completeness\":2,\"precision\":5,\"coherence\":5,\"relevance\":2}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"If capital stands for the central administrative region of a country, then no, Paris is not the capital of Germany. It's important to note what is the definintion of a 'capital'. However, due to the common popular opinion, a capital of a country is well defined.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":1,\"coherence\":4,\"relevance\":1}\n\nEND OF SYSTEM PROMPT."}, {"role": "user", "content": [{"type": "text", "text": "Question: "}, {"type": "text", "text": "Gold reference 1: \"There are two different staircases necessary.\""}, {"type": "text", "text": "Candidate answer: Two different staircases are necessary to access the Kua Aina entrance with a maroon awning from the street below."}, {"type": "text", "text": "Please score the candidate exactly with the five integer ratings in JSON as instructed by the system prompt."}]}]}}
{"custom_id": "d5bf43d00dba11ecb1e81171463288e9_geval", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-mini-2025-04-14", "max_tokens": 200, "temperature": 1, "n": 20, "messages": [{"role": "system", "content": "You are an evaluation assistant. You will be given:\n  - A question Q.\n  - A gold/reference answer (one or more short reference sentences).\n  - A candidate/sample answer produced by a system.\n\nYour job is to **assign integer scores** (1..5) for the following criteria comparing the *candidate* to the *gold/reference*:\n\n1. correctness (1-5): How factually correct is the candidate vs the gold answer? (5 = fully correct, 1 = mostly or fully incorrect).\n2. completeness (1-5): How completely does the candidate cover the key points in the gold answer? (5 = covers all key points; 1 = almost none).\n3. precision (1-5): How concise and focused is the candidate (not too long answer)? (5 = concise & precise; 1 = verbose / many extraneous claims).\n4. coherence (1-5): Is the candidate fluent and well-structured? (5 = natural, coherent; 1 = disfluent or incoherent).\n5. relevance (1-5): Are the statements in the candidate relevant to the question and gold answer (not introducing unrelated claims)? (5 = fully relevant; 1 = mostly irrelevant).\n\nREQUIREMENTS (strict):\n- Output **ONLY** a JSON object EXACTLY of the form:\n  {\"correctness\": <1-5>, \"completeness\": <1-5>, \"precision\": <1-5>, \"coherence\": <1-5>, \"relevance\": <1-5>}\n- No additional text, explanation, or whitespace outside the JSON object.\n\nFEW-SHOT EXAMPLE (this demonstrates the required output; do not include the example in actual responses):\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"No, the capital of Germany is not Paris, the capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":5,\"coherence\":5,\"relevance\":5}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"The capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":3,\"completeness\":2,\"precision\":5,\"coherence\":5,\"relevance\":2}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"If capital stands for the central administrative region of a country, then no, Paris is not the capital of Germany. It's important to note what is the definintion of a 'capital'. However, due to the common popular opinion, a capital of a country is well defined.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":1,\"coherence\":4,\"relevance\":1}\n\nEND OF SYSTEM PROMPT."}, {"role": "user", "content": [{"type": "text", "text": "Question: "}, {"type": "text", "text": "Gold reference 1: \"The disability sign in the middle is the most slanted at the Health Education Center in Chattahoochee Technical College.\""}, {"type": "text", "text": "Candidate answer: The slanted disability sign is located at the Health Education Center, Chattahoochee Technical College, North Metro Campus."}, {"type": "text", "text": "Please score the candidate exactly with the five integer ratings in JSON as instructed by the system prompt."}]}]}}
{"custom_id": "d5bf71020dba11ecb1e81171463288e9_geval", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-mini-2025-04-14", "max_tokens": 200, "temperature": 1, "n": 20, "messages": [{"role": "system", "content": "You are an evaluation assistant. You will be given:\n  - A question Q.\n  - A gold/reference answer (one or more short reference sentences).\n  - A candidate/sample answer produced by a system.\n\nYour job is to **assign integer scores** (1..5) for the following criteria comparing the *candidate* to the *gold/reference*:\n\n1. correctness (1-5): How factually correct is the candidate vs the gold answer? (5 = fully correct, 1 = mostly or fully incorrect).\n2. completeness (1-5): How completely does the candidate cover the key points in the gold answer? (5 = covers all key points; 1 = almost none).\n3. precision (1-5): How concise and focused is the candidate (not too long answer)? (5 = concise & precise; 1 = verbose / many extraneous claims).\n4. coherence (1-5): Is the candidate fluent and well-structured? (5 = natural, coherent; 1 = disfluent or incoherent).\n5. relevance (1-5): Are the statements in the candidate relevant to the question and gold answer (not introducing unrelated claims)? (5 = fully relevant; 1 = mostly irrelevant).\n\nREQUIREMENTS (strict):\n- Output **ONLY** a JSON object EXACTLY of the form:\n  {\"correctness\": <1-5>, \"completeness\": <1-5>, \"precision\": <1-5>, \"coherence\": <1-5>, \"relevance\": <1-5>}\n- No additional text, explanation, or whitespace outside the JSON object.\n\nFEW-SHOT EXAMPLE (this demonstrates the required output; do not include the example in actual responses):\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"No, the capital of Germany is not Paris, the capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":5,\"coherence\":5,\"relevance\":5}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"The capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":3,\"completeness\":2,\"precision\":5,\"coherence\":5,\"relevance\":2}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"If capital stands for the central administrative region of a country, then no, Paris is not the capital of Germany. It's important to note what is the definintion of a 'capital'. However, due to the common popular opinion, a capital of a country is well defined.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":1,\"coherence\":4,\"relevance\":1}\n\nEND OF SYSTEM PROMPT."}, {"role": "user", "content": [{"type": "text", "text": "Question: "}, {"type": "text", "text": "Gold reference 1: \"The front row of people during dancing in Zulu culture sits.\""}, {"type": "text", "text": "Candidate answer: During dancing in Zulu culture, the front row of people watching typically claps and cheers to encourage the performers."}, {"type": "text", "text": "Please score the candidate exactly with the five integer ratings in JSON as instructed by the system prompt."}]}]}}
{"custom_id": "d5bd971a0dba11ecb1e81171463288e9_geval", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-mini-2025-04-14", "max_tokens": 200, "temperature": 1, "n": 20, "messages": [{"role": "system", "content": "You are an evaluation assistant. You will be given:\n  - A question Q.\n  - A gold/reference answer (one or more short reference sentences).\n  - A candidate/sample answer produced by a system.\n\nYour job is to **assign integer scores** (1..5) for the following criteria comparing the *candidate* to the *gold/reference*:\n\n1. correctness (1-5): How factually correct is the candidate vs the gold answer? (5 = fully correct, 1 = mostly or fully incorrect).\n2. completeness (1-5): How completely does the candidate cover the key points in the gold answer? (5 = covers all key points; 1 = almost none).\n3. precision (1-5): How concise and focused is the candidate (not too long answer)? (5 = concise & precise; 1 = verbose / many extraneous claims).\n4. coherence (1-5): Is the candidate fluent and well-structured? (5 = natural, coherent; 1 = disfluent or incoherent).\n5. relevance (1-5): Are the statements in the candidate relevant to the question and gold answer (not introducing unrelated claims)? (5 = fully relevant; 1 = mostly irrelevant).\n\nREQUIREMENTS (strict):\n- Output **ONLY** a JSON object EXACTLY of the form:\n  {\"correctness\": <1-5>, \"completeness\": <1-5>, \"precision\": <1-5>, \"coherence\": <1-5>, \"relevance\": <1-5>}\n- No additional text, explanation, or whitespace outside the JSON object.\n\nFEW-SHOT EXAMPLE (this demonstrates the required output; do not include the example in actual responses):\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"No, the capital of Germany is not Paris, the capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":5,\"coherence\":5,\"relevance\":5}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"The capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":3,\"completeness\":2,\"precision\":5,\"coherence\":5,\"relevance\":2}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"If capital stands for the central administrative region of a country, then no, Paris is not the capital of Germany. It's important to note what is the definintion of a 'capital'. However, due to the common popular opinion, a capital of a country is well defined.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":1,\"coherence\":4,\"relevance\":1}\n\nEND OF SYSTEM PROMPT."}, {"role": "user", "content": [{"type": "text", "text": "Question: "}, {"type": "text", "text": "Gold reference 1: \"The most common color for doors in Melbourne Trams is yellow.\""}, {"type": "text", "text": "Candidate answer: The most common color for doors in Melbourne trams is yellow."}, {"type": "text", "text": "Please score the candidate exactly with the five integer ratings in JSON as instructed by the system prompt."}]}]}}
{"custom_id": "d5bf42ae0dba11ecb1e81171463288e9_geval", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-mini-2025-04-14", "max_tokens": 200, "temperature": 1, "n": 20, "messages": [{"role": "system", "content": "You are an evaluation assistant. You will be given:\n  - A question Q.\n  - A gold/reference answer (one or more short reference sentences).\n  - A candidate/sample answer produced by a system.\n\nYour job is to **assign integer scores** (1..5) for the following criteria comparing the *candidate* to the *gold/reference*:\n\n1. correctness (1-5): How factually correct is the candidate vs the gold answer? (5 = fully correct, 1 = mostly or fully incorrect).\n2. completeness (1-5): How completely does the candidate cover the key points in the gold answer? (5 = covers all key points; 1 = almost none).\n3. precision (1-5): How concise and focused is the candidate (not too long answer)? (5 = concise & precise; 1 = verbose / many extraneous claims).\n4. coherence (1-5): Is the candidate fluent and well-structured? (5 = natural, coherent; 1 = disfluent or incoherent).\n5. relevance (1-5): Are the statements in the candidate relevant to the question and gold answer (not introducing unrelated claims)? (5 = fully relevant; 1 = mostly irrelevant).\n\nREQUIREMENTS (strict):\n- Output **ONLY** a JSON object EXACTLY of the form:\n  {\"correctness\": <1-5>, \"completeness\": <1-5>, \"precision\": <1-5>, \"coherence\": <1-5>, \"relevance\": <1-5>}\n- No additional text, explanation, or whitespace outside the JSON object.\n\nFEW-SHOT EXAMPLE (this demonstrates the required output; do not include the example in actual responses):\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"No, the capital of Germany is not Paris, the capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":5,\"coherence\":5,\"relevance\":5}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"The capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":3,\"completeness\":2,\"precision\":5,\"coherence\":5,\"relevance\":2}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"If capital stands for the central administrative region of a country, then no, Paris is not the capital of Germany. It's important to note what is the definintion of a 'capital'. However, due to the common popular opinion, a capital of a country is well defined.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":1,\"coherence\":4,\"relevance\":1}\n\nEND OF SYSTEM PROMPT."}, {"role": "user", "content": [{"type": "text", "text": "Question: "}, {"type": "text", "text": "Gold reference 1: \"The tail of the stylized P runs between the P and the A on the Siam Paragon logo.\""}, {"type": "text", "text": "Candidate answer: The tail of the stylized P in the Siam Paragon logo runs between the letters 'S' and 'I'."}, {"type": "text", "text": "Please score the candidate exactly with the five integer ratings in JSON as instructed by the system prompt."}]}]}}
{"custom_id": "d5bf2f8a0dba11ecb1e81171463288e9_geval", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-mini-2025-04-14", "max_tokens": 200, "temperature": 1, "n": 20, "messages": [{"role": "system", "content": "You are an evaluation assistant. You will be given:\n  - A question Q.\n  - A gold/reference answer (one or more short reference sentences).\n  - A candidate/sample answer produced by a system.\n\nYour job is to **assign integer scores** (1..5) for the following criteria comparing the *candidate* to the *gold/reference*:\n\n1. correctness (1-5): How factually correct is the candidate vs the gold answer? (5 = fully correct, 1 = mostly or fully incorrect).\n2. completeness (1-5): How completely does the candidate cover the key points in the gold answer? (5 = covers all key points; 1 = almost none).\n3. precision (1-5): How concise and focused is the candidate (not too long answer)? (5 = concise & precise; 1 = verbose / many extraneous claims).\n4. coherence (1-5): Is the candidate fluent and well-structured? (5 = natural, coherent; 1 = disfluent or incoherent).\n5. relevance (1-5): Are the statements in the candidate relevant to the question and gold answer (not introducing unrelated claims)? (5 = fully relevant; 1 = mostly irrelevant).\n\nREQUIREMENTS (strict):\n- Output **ONLY** a JSON object EXACTLY of the form:\n  {\"correctness\": <1-5>, \"completeness\": <1-5>, \"precision\": <1-5>, \"coherence\": <1-5>, \"relevance\": <1-5>}\n- No additional text, explanation, or whitespace outside the JSON object.\n\nFEW-SHOT EXAMPLE (this demonstrates the required output; do not include the example in actual responses):\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"No, the capital of Germany is not Paris, the capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":5,\"coherence\":5,\"relevance\":5}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"The capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":3,\"completeness\":2,\"precision\":5,\"coherence\":5,\"relevance\":2}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"If capital stands for the central administrative region of a country, then no, Paris is not the capital of Germany. It's important to note what is the definintion of a 'capital'. However, due to the common popular opinion, a capital of a country is well defined.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":1,\"coherence\":4,\"relevance\":1}\n\nEND OF SYSTEM PROMPT."}, {"role": "user", "content": [{"type": "text", "text": "Question: "}, {"type": "text", "text": "Gold reference 1: \"Inonotus dryadeus appears to be oozing more.\""}, {"type": "text", "text": "Candidate answer: Inonotus dryadeus appears to be oozing more, as evidenced by images showing its fruiting body with droplets of liquid on its surface."}, {"type": "text", "text": "Please score the candidate exactly with the five integer ratings in JSON as instructed by the system prompt."}]}]}}
{"custom_id": "d5bf53700dba11ecb1e81171463288e9_geval", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-mini-2025-04-14", "max_tokens": 200, "temperature": 1, "n": 20, "messages": [{"role": "system", "content": "You are an evaluation assistant. You will be given:\n  - A question Q.\n  - A gold/reference answer (one or more short reference sentences).\n  - A candidate/sample answer produced by a system.\n\nYour job is to **assign integer scores** (1..5) for the following criteria comparing the *candidate* to the *gold/reference*:\n\n1. correctness (1-5): How factually correct is the candidate vs the gold answer? (5 = fully correct, 1 = mostly or fully incorrect).\n2. completeness (1-5): How completely does the candidate cover the key points in the gold answer? (5 = covers all key points; 1 = almost none).\n3. precision (1-5): How concise and focused is the candidate (not too long answer)? (5 = concise & precise; 1 = verbose / many extraneous claims).\n4. coherence (1-5): Is the candidate fluent and well-structured? (5 = natural, coherent; 1 = disfluent or incoherent).\n5. relevance (1-5): Are the statements in the candidate relevant to the question and gold answer (not introducing unrelated claims)? (5 = fully relevant; 1 = mostly irrelevant).\n\nREQUIREMENTS (strict):\n- Output **ONLY** a JSON object EXACTLY of the form:\n  {\"correctness\": <1-5>, \"completeness\": <1-5>, \"precision\": <1-5>, \"coherence\": <1-5>, \"relevance\": <1-5>}\n- No additional text, explanation, or whitespace outside the JSON object.\n\nFEW-SHOT EXAMPLE (this demonstrates the required output; do not include the example in actual responses):\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"No, the capital of Germany is not Paris, the capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":5,\"coherence\":5,\"relevance\":5}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"The capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":3,\"completeness\":2,\"precision\":5,\"coherence\":5,\"relevance\":2}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"If capital stands for the central administrative region of a country, then no, Paris is not the capital of Germany. It's important to note what is the definintion of a 'capital'. However, due to the common popular opinion, a capital of a country is well defined.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":1,\"coherence\":4,\"relevance\":1}\n\nEND OF SYSTEM PROMPT."}, {"role": "user", "content": [{"type": "text", "text": "Question: "}, {"type": "text", "text": "Gold reference 1: \"The 2017 Lexus CT has a more prominent front grill.\""}, {"type": "text", "text": "Candidate answer: The 2017 Lexus CT has a more prominent front grill compared to the Suzuki S-presso."}, {"type": "text", "text": "Please score the candidate exactly with the five integer ratings in JSON as instructed by the system prompt."}]}]}}
{"custom_id": "d5bf91fa0dba11ecb1e81171463288e9_geval", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-mini-2025-04-14", "max_tokens": 200, "temperature": 1, "n": 20, "messages": [{"role": "system", "content": "You are an evaluation assistant. You will be given:\n  - A question Q.\n  - A gold/reference answer (one or more short reference sentences).\n  - A candidate/sample answer produced by a system.\n\nYour job is to **assign integer scores** (1..5) for the following criteria comparing the *candidate* to the *gold/reference*:\n\n1. correctness (1-5): How factually correct is the candidate vs the gold answer? (5 = fully correct, 1 = mostly or fully incorrect).\n2. completeness (1-5): How completely does the candidate cover the key points in the gold answer? (5 = covers all key points; 1 = almost none).\n3. precision (1-5): How concise and focused is the candidate (not too long answer)? (5 = concise & precise; 1 = verbose / many extraneous claims).\n4. coherence (1-5): Is the candidate fluent and well-structured? (5 = natural, coherent; 1 = disfluent or incoherent).\n5. relevance (1-5): Are the statements in the candidate relevant to the question and gold answer (not introducing unrelated claims)? (5 = fully relevant; 1 = mostly irrelevant).\n\nREQUIREMENTS (strict):\n- Output **ONLY** a JSON object EXACTLY of the form:\n  {\"correctness\": <1-5>, \"completeness\": <1-5>, \"precision\": <1-5>, \"coherence\": <1-5>, \"relevance\": <1-5>}\n- No additional text, explanation, or whitespace outside the JSON object.\n\nFEW-SHOT EXAMPLE (this demonstrates the required output; do not include the example in actual responses):\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"No, the capital of Germany is not Paris, the capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":5,\"coherence\":5,\"relevance\":5}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"The capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":3,\"completeness\":2,\"precision\":5,\"coherence\":5,\"relevance\":2}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"If capital stands for the central administrative region of a country, then no, Paris is not the capital of Germany. It's important to note what is the definintion of a 'capital'. However, due to the common popular opinion, a capital of a country is well defined.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":1,\"coherence\":4,\"relevance\":1}\n\nEND OF SYSTEM PROMPT."}, {"role": "user", "content": [{"type": "text", "text": "Question: "}, {"type": "text", "text": "Gold reference 1: \"The rounded section is grey.\""}, {"type": "text", "text": "Candidate answer: The color grey is found on the cylindrical segment of the Holon Institute of Technology building."}, {"type": "text", "text": "Please score the candidate exactly with the five integer ratings in JSON as instructed by the system prompt."}]}]}}
{"custom_id": "d5be64560dba11ecb1e81171463288e9_geval", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-mini-2025-04-14", "max_tokens": 200, "temperature": 1, "n": 20, "messages": [{"role": "system", "content": "You are an evaluation assistant. You will be given:\n  - A question Q.\n  - A gold/reference answer (one or more short reference sentences).\n  - A candidate/sample answer produced by a system.\n\nYour job is to **assign integer scores** (1..5) for the following criteria comparing the *candidate* to the *gold/reference*:\n\n1. correctness (1-5): How factually correct is the candidate vs the gold answer? (5 = fully correct, 1 = mostly or fully incorrect).\n2. completeness (1-5): How completely does the candidate cover the key points in the gold answer? (5 = covers all key points; 1 = almost none).\n3. precision (1-5): How concise and focused is the candidate (not too long answer)? (5 = concise & precise; 1 = verbose / many extraneous claims).\n4. coherence (1-5): Is the candidate fluent and well-structured? (5 = natural, coherent; 1 = disfluent or incoherent).\n5. relevance (1-5): Are the statements in the candidate relevant to the question and gold answer (not introducing unrelated claims)? (5 = fully relevant; 1 = mostly irrelevant).\n\nREQUIREMENTS (strict):\n- Output **ONLY** a JSON object EXACTLY of the form:\n  {\"correctness\": <1-5>, \"completeness\": <1-5>, \"precision\": <1-5>, \"coherence\": <1-5>, \"relevance\": <1-5>}\n- No additional text, explanation, or whitespace outside the JSON object.\n\nFEW-SHOT EXAMPLE (this demonstrates the required output; do not include the example in actual responses):\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"No, the capital of Germany is not Paris, the capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":5,\"coherence\":5,\"relevance\":5}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"The capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":3,\"completeness\":2,\"precision\":5,\"coherence\":5,\"relevance\":2}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"If capital stands for the central administrative region of a country, then no, Paris is not the capital of Germany. It's important to note what is the definintion of a 'capital'. However, due to the common popular opinion, a capital of a country is well defined.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":1,\"coherence\":4,\"relevance\":1}\n\nEND OF SYSTEM PROMPT."}, {"role": "user", "content": [{"type": "text", "text": "Question: "}, {"type": "text", "text": "Gold reference 1: \"The Tokyo Station is wider than the Marunouchi building in Tokyo.\""}, {"type": "text", "text": "Candidate answer: The Tokyo Station building is wider than the Marunouchi building."}, {"type": "text", "text": "Please score the candidate exactly with the five integer ratings in JSON as instructed by the system prompt."}]}]}}
{"custom_id": "d5bbd1820dba11ecb1e81171463288e9_geval", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-mini-2025-04-14", "max_tokens": 200, "temperature": 1, "n": 20, "messages": [{"role": "system", "content": "You are an evaluation assistant. You will be given:\n  - A question Q.\n  - A gold/reference answer (one or more short reference sentences).\n  - A candidate/sample answer produced by a system.\n\nYour job is to **assign integer scores** (1..5) for the following criteria comparing the *candidate* to the *gold/reference*:\n\n1. correctness (1-5): How factually correct is the candidate vs the gold answer? (5 = fully correct, 1 = mostly or fully incorrect).\n2. completeness (1-5): How completely does the candidate cover the key points in the gold answer? (5 = covers all key points; 1 = almost none).\n3. precision (1-5): How concise and focused is the candidate (not too long answer)? (5 = concise & precise; 1 = verbose / many extraneous claims).\n4. coherence (1-5): Is the candidate fluent and well-structured? (5 = natural, coherent; 1 = disfluent or incoherent).\n5. relevance (1-5): Are the statements in the candidate relevant to the question and gold answer (not introducing unrelated claims)? (5 = fully relevant; 1 = mostly irrelevant).\n\nREQUIREMENTS (strict):\n- Output **ONLY** a JSON object EXACTLY of the form:\n  {\"correctness\": <1-5>, \"completeness\": <1-5>, \"precision\": <1-5>, \"coherence\": <1-5>, \"relevance\": <1-5>}\n- No additional text, explanation, or whitespace outside the JSON object.\n\nFEW-SHOT EXAMPLE (this demonstrates the required output; do not include the example in actual responses):\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"No, the capital of Germany is not Paris, the capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":5,\"coherence\":5,\"relevance\":5}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"The capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":3,\"completeness\":2,\"precision\":5,\"coherence\":5,\"relevance\":2}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"If capital stands for the central administrative region of a country, then no, Paris is not the capital of Germany. It's important to note what is the definintion of a 'capital'. However, due to the common popular opinion, a capital of a country is well defined.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":1,\"coherence\":4,\"relevance\":1}\n\nEND OF SYSTEM PROMPT."}, {"role": "user", "content": [{"type": "text", "text": "Question: "}, {"type": "text", "text": "Gold reference 1: \"The base of the Olympic cauldron that Paavo Nurmi lit at the 1952 Olympics in Helsinki is a circle.\""}, {"type": "text", "text": "Candidate answer: The base of the Olympic cauldron that Paavo Nurmi lit at the 1952 Olympics in Helsinki is circular."}, {"type": "text", "text": "Please score the candidate exactly with the five integer ratings in JSON as instructed by the system prompt."}]}]}}
{"custom_id": "d5bf30200dba11ecb1e81171463288e9_geval", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-mini-2025-04-14", "max_tokens": 200, "temperature": 1, "n": 20, "messages": [{"role": "system", "content": "You are an evaluation assistant. You will be given:\n  - A question Q.\n  - A gold/reference answer (one or more short reference sentences).\n  - A candidate/sample answer produced by a system.\n\nYour job is to **assign integer scores** (1..5) for the following criteria comparing the *candidate* to the *gold/reference*:\n\n1. correctness (1-5): How factually correct is the candidate vs the gold answer? (5 = fully correct, 1 = mostly or fully incorrect).\n2. completeness (1-5): How completely does the candidate cover the key points in the gold answer? (5 = covers all key points; 1 = almost none).\n3. precision (1-5): How concise and focused is the candidate (not too long answer)? (5 = concise & precise; 1 = verbose / many extraneous claims).\n4. coherence (1-5): Is the candidate fluent and well-structured? (5 = natural, coherent; 1 = disfluent or incoherent).\n5. relevance (1-5): Are the statements in the candidate relevant to the question and gold answer (not introducing unrelated claims)? (5 = fully relevant; 1 = mostly irrelevant).\n\nREQUIREMENTS (strict):\n- Output **ONLY** a JSON object EXACTLY of the form:\n  {\"correctness\": <1-5>, \"completeness\": <1-5>, \"precision\": <1-5>, \"coherence\": <1-5>, \"relevance\": <1-5>}\n- No additional text, explanation, or whitespace outside the JSON object.\n\nFEW-SHOT EXAMPLE (this demonstrates the required output; do not include the example in actual responses):\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"No, the capital of Germany is not Paris, the capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":5,\"coherence\":5,\"relevance\":5}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"The capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":3,\"completeness\":2,\"precision\":5,\"coherence\":5,\"relevance\":2}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"If capital stands for the central administrative region of a country, then no, Paris is not the capital of Germany. It's important to note what is the definintion of a 'capital'. However, due to the common popular opinion, a capital of a country is well defined.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":1,\"coherence\":4,\"relevance\":1}\n\nEND OF SYSTEM PROMPT."}, {"role": "user", "content": [{"type": "text", "text": "Question: "}, {"type": "text", "text": "Gold reference 1: \"When looking at the Blacksburg, VA post office from N. Main Street, the flagpole is to the left of the entrance.\""}, {"type": "text", "text": "Candidate answer: The flagpole is to the right of the entrance of the Blacksburg, VA post office."}, {"type": "text", "text": "Please score the candidate exactly with the five integer ratings in JSON as instructed by the system prompt."}]}]}}
{"custom_id": "d5bf9c360dba11ecb1e81171463288e9_geval", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-mini-2025-04-14", "max_tokens": 200, "temperature": 1, "n": 20, "messages": [{"role": "system", "content": "You are an evaluation assistant. You will be given:\n  - A question Q.\n  - A gold/reference answer (one or more short reference sentences).\n  - A candidate/sample answer produced by a system.\n\nYour job is to **assign integer scores** (1..5) for the following criteria comparing the *candidate* to the *gold/reference*:\n\n1. correctness (1-5): How factually correct is the candidate vs the gold answer? (5 = fully correct, 1 = mostly or fully incorrect).\n2. completeness (1-5): How completely does the candidate cover the key points in the gold answer? (5 = covers all key points; 1 = almost none).\n3. precision (1-5): How concise and focused is the candidate (not too long answer)? (5 = concise & precise; 1 = verbose / many extraneous claims).\n4. coherence (1-5): Is the candidate fluent and well-structured? (5 = natural, coherent; 1 = disfluent or incoherent).\n5. relevance (1-5): Are the statements in the candidate relevant to the question and gold answer (not introducing unrelated claims)? (5 = fully relevant; 1 = mostly irrelevant).\n\nREQUIREMENTS (strict):\n- Output **ONLY** a JSON object EXACTLY of the form:\n  {\"correctness\": <1-5>, \"completeness\": <1-5>, \"precision\": <1-5>, \"coherence\": <1-5>, \"relevance\": <1-5>}\n- No additional text, explanation, or whitespace outside the JSON object.\n\nFEW-SHOT EXAMPLE (this demonstrates the required output; do not include the example in actual responses):\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"No, the capital of Germany is not Paris, the capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":5,\"coherence\":5,\"relevance\":5}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"The capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":3,\"completeness\":2,\"precision\":5,\"coherence\":5,\"relevance\":2}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"If capital stands for the central administrative region of a country, then no, Paris is not the capital of Germany. It's important to note what is the definintion of a 'capital'. However, due to the common popular opinion, a capital of a country is well defined.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":1,\"coherence\":4,\"relevance\":1}\n\nEND OF SYSTEM PROMPT."}, {"role": "user", "content": [{"type": "text", "text": "Question: "}, {"type": "text", "text": "Gold reference 1: \"There is a Barnes & Noble near the Oak Park Mall Entrance.\""}, {"type": "text", "text": "Candidate answer: You can go to Nordstrom or Payless Shoe Source near the Oak Park Mall Entrance."}, {"type": "text", "text": "Please score the candidate exactly with the five integer ratings in JSON as instructed by the system prompt."}]}]}}
{"custom_id": "d5bfb3920dba11ecb1e81171463288e9_geval", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-mini-2025-04-14", "max_tokens": 200, "temperature": 1, "n": 20, "messages": [{"role": "system", "content": "You are an evaluation assistant. You will be given:\n  - A question Q.\n  - A gold/reference answer (one or more short reference sentences).\n  - A candidate/sample answer produced by a system.\n\nYour job is to **assign integer scores** (1..5) for the following criteria comparing the *candidate* to the *gold/reference*:\n\n1. correctness (1-5): How factually correct is the candidate vs the gold answer? (5 = fully correct, 1 = mostly or fully incorrect).\n2. completeness (1-5): How completely does the candidate cover the key points in the gold answer? (5 = covers all key points; 1 = almost none).\n3. precision (1-5): How concise and focused is the candidate (not too long answer)? (5 = concise & precise; 1 = verbose / many extraneous claims).\n4. coherence (1-5): Is the candidate fluent and well-structured? (5 = natural, coherent; 1 = disfluent or incoherent).\n5. relevance (1-5): Are the statements in the candidate relevant to the question and gold answer (not introducing unrelated claims)? (5 = fully relevant; 1 = mostly irrelevant).\n\nREQUIREMENTS (strict):\n- Output **ONLY** a JSON object EXACTLY of the form:\n  {\"correctness\": <1-5>, \"completeness\": <1-5>, \"precision\": <1-5>, \"coherence\": <1-5>, \"relevance\": <1-5>}\n- No additional text, explanation, or whitespace outside the JSON object.\n\nFEW-SHOT EXAMPLE (this demonstrates the required output; do not include the example in actual responses):\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"No, the capital of Germany is not Paris, the capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":5,\"coherence\":5,\"relevance\":5}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"The capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":3,\"completeness\":2,\"precision\":5,\"coherence\":5,\"relevance\":2}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"If capital stands for the central administrative region of a country, then no, Paris is not the capital of Germany. It's important to note what is the definintion of a 'capital'. However, due to the common popular opinion, a capital of a country is well defined.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":1,\"coherence\":4,\"relevance\":1}\n\nEND OF SYSTEM PROMPT."}, {"role": "user", "content": [{"type": "text", "text": "Question: "}, {"type": "text", "text": "Gold reference 1: \"The shirts and shorts of the Laker's uniform are Nike.\""}, {"type": "text", "text": "Candidate answer: The brand of the Lakers' uniform shirts and shorts is Nike."}, {"type": "text", "text": "Please score the candidate exactly with the five integer ratings in JSON as instructed by the system prompt."}]}]}}
{"custom_id": "d5bedd460dba11ecb1e81171463288e9_geval", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-mini-2025-04-14", "max_tokens": 200, "temperature": 1, "n": 20, "messages": [{"role": "system", "content": "You are an evaluation assistant. You will be given:\n  - A question Q.\n  - A gold/reference answer (one or more short reference sentences).\n  - A candidate/sample answer produced by a system.\n\nYour job is to **assign integer scores** (1..5) for the following criteria comparing the *candidate* to the *gold/reference*:\n\n1. correctness (1-5): How factually correct is the candidate vs the gold answer? (5 = fully correct, 1 = mostly or fully incorrect).\n2. completeness (1-5): How completely does the candidate cover the key points in the gold answer? (5 = covers all key points; 1 = almost none).\n3. precision (1-5): How concise and focused is the candidate (not too long answer)? (5 = concise & precise; 1 = verbose / many extraneous claims).\n4. coherence (1-5): Is the candidate fluent and well-structured? (5 = natural, coherent; 1 = disfluent or incoherent).\n5. relevance (1-5): Are the statements in the candidate relevant to the question and gold answer (not introducing unrelated claims)? (5 = fully relevant; 1 = mostly irrelevant).\n\nREQUIREMENTS (strict):\n- Output **ONLY** a JSON object EXACTLY of the form:\n  {\"correctness\": <1-5>, \"completeness\": <1-5>, \"precision\": <1-5>, \"coherence\": <1-5>, \"relevance\": <1-5>}\n- No additional text, explanation, or whitespace outside the JSON object.\n\nFEW-SHOT EXAMPLE (this demonstrates the required output; do not include the example in actual responses):\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"No, the capital of Germany is not Paris, the capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":5,\"coherence\":5,\"relevance\":5}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"The capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":3,\"completeness\":2,\"precision\":5,\"coherence\":5,\"relevance\":2}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"If capital stands for the central administrative region of a country, then no, Paris is not the capital of Germany. It's important to note what is the definintion of a 'capital'. However, due to the common popular opinion, a capital of a country is well defined.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":1,\"coherence\":4,\"relevance\":1}\n\nEND OF SYSTEM PROMPT."}, {"role": "user", "content": [{"type": "text", "text": "Question: "}, {"type": "text", "text": "Gold reference 1: \"A fountain is in the center of the Interior of the National Building Museum.\""}, {"type": "text", "text": "Candidate answer: The object in the center of the National Building Museum is a circular fountain surrounded by columns."}, {"type": "text", "text": "Please score the candidate exactly with the five integer ratings in JSON as instructed by the system prompt."}]}]}}
{"custom_id": "d5bca1520dba11ecb1e81171463288e9_geval", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-mini-2025-04-14", "max_tokens": 200, "temperature": 1, "n": 20, "messages": [{"role": "system", "content": "You are an evaluation assistant. You will be given:\n  - A question Q.\n  - A gold/reference answer (one or more short reference sentences).\n  - A candidate/sample answer produced by a system.\n\nYour job is to **assign integer scores** (1..5) for the following criteria comparing the *candidate* to the *gold/reference*:\n\n1. correctness (1-5): How factually correct is the candidate vs the gold answer? (5 = fully correct, 1 = mostly or fully incorrect).\n2. completeness (1-5): How completely does the candidate cover the key points in the gold answer? (5 = covers all key points; 1 = almost none).\n3. precision (1-5): How concise and focused is the candidate (not too long answer)? (5 = concise & precise; 1 = verbose / many extraneous claims).\n4. coherence (1-5): Is the candidate fluent and well-structured? (5 = natural, coherent; 1 = disfluent or incoherent).\n5. relevance (1-5): Are the statements in the candidate relevant to the question and gold answer (not introducing unrelated claims)? (5 = fully relevant; 1 = mostly irrelevant).\n\nREQUIREMENTS (strict):\n- Output **ONLY** a JSON object EXACTLY of the form:\n  {\"correctness\": <1-5>, \"completeness\": <1-5>, \"precision\": <1-5>, \"coherence\": <1-5>, \"relevance\": <1-5>}\n- No additional text, explanation, or whitespace outside the JSON object.\n\nFEW-SHOT EXAMPLE (this demonstrates the required output; do not include the example in actual responses):\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"No, the capital of Germany is not Paris, the capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":5,\"coherence\":5,\"relevance\":5}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"The capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":3,\"completeness\":2,\"precision\":5,\"coherence\":5,\"relevance\":2}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"If capital stands for the central administrative region of a country, then no, Paris is not the capital of Germany. It's important to note what is the definintion of a 'capital'. However, due to the common popular opinion, a capital of a country is well defined.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":1,\"coherence\":4,\"relevance\":1}\n\nEND OF SYSTEM PROMPT."}, {"role": "user", "content": [{"type": "text", "text": "Question: "}, {"type": "text", "text": "Gold reference 1: \"No, the same jumbotron was not in place at Madison Square Garden on October 27, 2011 and January 23, 2014\""}, {"type": "text", "text": "Candidate answer: No, the jumbotron was different; the transformation of Madison Square Garden was completed by January 23, 2014."}, {"type": "text", "text": "Please score the candidate exactly with the five integer ratings in JSON as instructed by the system prompt."}]}]}}
{"custom_id": "d5bc5c740dba11ecb1e81171463288e9_geval", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-mini-2025-04-14", "max_tokens": 200, "temperature": 1, "n": 20, "messages": [{"role": "system", "content": "You are an evaluation assistant. You will be given:\n  - A question Q.\n  - A gold/reference answer (one or more short reference sentences).\n  - A candidate/sample answer produced by a system.\n\nYour job is to **assign integer scores** (1..5) for the following criteria comparing the *candidate* to the *gold/reference*:\n\n1. correctness (1-5): How factually correct is the candidate vs the gold answer? (5 = fully correct, 1 = mostly or fully incorrect).\n2. completeness (1-5): How completely does the candidate cover the key points in the gold answer? (5 = covers all key points; 1 = almost none).\n3. precision (1-5): How concise and focused is the candidate (not too long answer)? (5 = concise & precise; 1 = verbose / many extraneous claims).\n4. coherence (1-5): Is the candidate fluent and well-structured? (5 = natural, coherent; 1 = disfluent or incoherent).\n5. relevance (1-5): Are the statements in the candidate relevant to the question and gold answer (not introducing unrelated claims)? (5 = fully relevant; 1 = mostly irrelevant).\n\nREQUIREMENTS (strict):\n- Output **ONLY** a JSON object EXACTLY of the form:\n  {\"correctness\": <1-5>, \"completeness\": <1-5>, \"precision\": <1-5>, \"coherence\": <1-5>, \"relevance\": <1-5>}\n- No additional text, explanation, or whitespace outside the JSON object.\n\nFEW-SHOT EXAMPLE (this demonstrates the required output; do not include the example in actual responses):\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"No, the capital of Germany is not Paris, the capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":5,\"coherence\":5,\"relevance\":5}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"The capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":3,\"completeness\":2,\"precision\":5,\"coherence\":5,\"relevance\":2}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"If capital stands for the central administrative region of a country, then no, Paris is not the capital of Germany. It's important to note what is the definintion of a 'capital'. However, due to the common popular opinion, a capital of a country is well defined.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":1,\"coherence\":4,\"relevance\":1}\n\nEND OF SYSTEM PROMPT."}, {"role": "user", "content": [{"type": "text", "text": "Question: "}, {"type": "text", "text": "Gold reference 1: \"The smaller of the two video screens at Safeco Field is on left field.\""}, {"type": "text", "text": "Candidate answer: The smaller of the two video screens at Safeco Field is located in the center field scoreboard area."}, {"type": "text", "text": "Please score the candidate exactly with the five integer ratings in JSON as instructed by the system prompt."}]}]}}
{"custom_id": "d5bd6e840dba11ecb1e81171463288e9_geval", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-mini-2025-04-14", "max_tokens": 200, "temperature": 1, "n": 20, "messages": [{"role": "system", "content": "You are an evaluation assistant. You will be given:\n  - A question Q.\n  - A gold/reference answer (one or more short reference sentences).\n  - A candidate/sample answer produced by a system.\n\nYour job is to **assign integer scores** (1..5) for the following criteria comparing the *candidate* to the *gold/reference*:\n\n1. correctness (1-5): How factually correct is the candidate vs the gold answer? (5 = fully correct, 1 = mostly or fully incorrect).\n2. completeness (1-5): How completely does the candidate cover the key points in the gold answer? (5 = covers all key points; 1 = almost none).\n3. precision (1-5): How concise and focused is the candidate (not too long answer)? (5 = concise & precise; 1 = verbose / many extraneous claims).\n4. coherence (1-5): Is the candidate fluent and well-structured? (5 = natural, coherent; 1 = disfluent or incoherent).\n5. relevance (1-5): Are the statements in the candidate relevant to the question and gold answer (not introducing unrelated claims)? (5 = fully relevant; 1 = mostly irrelevant).\n\nREQUIREMENTS (strict):\n- Output **ONLY** a JSON object EXACTLY of the form:\n  {\"correctness\": <1-5>, \"completeness\": <1-5>, \"precision\": <1-5>, \"coherence\": <1-5>, \"relevance\": <1-5>}\n- No additional text, explanation, or whitespace outside the JSON object.\n\nFEW-SHOT EXAMPLE (this demonstrates the required output; do not include the example in actual responses):\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"No, the capital of Germany is not Paris, the capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":5,\"coherence\":5,\"relevance\":5}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"The capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":3,\"completeness\":2,\"precision\":5,\"coherence\":5,\"relevance\":2}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"If capital stands for the central administrative region of a country, then no, Paris is not the capital of Germany. It's important to note what is the definintion of a 'capital'. However, due to the common popular opinion, a capital of a country is well defined.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":1,\"coherence\":4,\"relevance\":1}\n\nEND OF SYSTEM PROMPT."}, {"role": "user", "content": [{"type": "text", "text": "Question: "}, {"type": "text", "text": "Gold reference 1: \"The Hotel del Ming has a vertical sign in front of it.\""}, {"type": "text", "text": "Candidate answer: The building with a vertical sign advertising its use is the Hotel del Ming, also known as Hotel del Sol, located in Yuma, Arizona."}, {"type": "text", "text": "Please score the candidate exactly with the five integer ratings in JSON as instructed by the system prompt."}]}]}}
{"custom_id": "d5bc33ac0dba11ecb1e81171463288e9_geval", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-mini-2025-04-14", "max_tokens": 200, "temperature": 1, "n": 20, "messages": [{"role": "system", "content": "You are an evaluation assistant. You will be given:\n  - A question Q.\n  - A gold/reference answer (one or more short reference sentences).\n  - A candidate/sample answer produced by a system.\n\nYour job is to **assign integer scores** (1..5) for the following criteria comparing the *candidate* to the *gold/reference*:\n\n1. correctness (1-5): How factually correct is the candidate vs the gold answer? (5 = fully correct, 1 = mostly or fully incorrect).\n2. completeness (1-5): How completely does the candidate cover the key points in the gold answer? (5 = covers all key points; 1 = almost none).\n3. precision (1-5): How concise and focused is the candidate (not too long answer)? (5 = concise & precise; 1 = verbose / many extraneous claims).\n4. coherence (1-5): Is the candidate fluent and well-structured? (5 = natural, coherent; 1 = disfluent or incoherent).\n5. relevance (1-5): Are the statements in the candidate relevant to the question and gold answer (not introducing unrelated claims)? (5 = fully relevant; 1 = mostly irrelevant).\n\nREQUIREMENTS (strict):\n- Output **ONLY** a JSON object EXACTLY of the form:\n  {\"correctness\": <1-5>, \"completeness\": <1-5>, \"precision\": <1-5>, \"coherence\": <1-5>, \"relevance\": <1-5>}\n- No additional text, explanation, or whitespace outside the JSON object.\n\nFEW-SHOT EXAMPLE (this demonstrates the required output; do not include the example in actual responses):\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"No, the capital of Germany is not Paris, the capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":5,\"coherence\":5,\"relevance\":5}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"The capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":3,\"completeness\":2,\"precision\":5,\"coherence\":5,\"relevance\":2}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"If capital stands for the central administrative region of a country, then no, Paris is not the capital of Germany. It's important to note what is the definintion of a 'capital'. However, due to the common popular opinion, a capital of a country is well defined.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":1,\"coherence\":4,\"relevance\":1}\n\nEND OF SYSTEM PROMPT."}, {"role": "user", "content": [{"type": "text", "text": "Question: "}, {"type": "text", "text": "Gold reference 1: \"The Christ Church Cathedral in Nashville, Tennessee has its multiple entrances more widely spaced apart.\""}, {"type": "text", "text": "Candidate answer: Christ Church Cathedral in Nashville, Tennessee has its multiple entrances more widely spaced apart compared to First Baptist Church in Knoxville, Tennessee."}, {"type": "text", "text": "Please score the candidate exactly with the five integer ratings in JSON as instructed by the system prompt."}]}]}}
{"custom_id": "d5bc961c0dba11ecb1e81171463288e9_geval", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-mini-2025-04-14", "max_tokens": 200, "temperature": 1, "n": 20, "messages": [{"role": "system", "content": "You are an evaluation assistant. You will be given:\n  - A question Q.\n  - A gold/reference answer (one or more short reference sentences).\n  - A candidate/sample answer produced by a system.\n\nYour job is to **assign integer scores** (1..5) for the following criteria comparing the *candidate* to the *gold/reference*:\n\n1. correctness (1-5): How factually correct is the candidate vs the gold answer? (5 = fully correct, 1 = mostly or fully incorrect).\n2. completeness (1-5): How completely does the candidate cover the key points in the gold answer? (5 = covers all key points; 1 = almost none).\n3. precision (1-5): How concise and focused is the candidate (not too long answer)? (5 = concise & precise; 1 = verbose / many extraneous claims).\n4. coherence (1-5): Is the candidate fluent and well-structured? (5 = natural, coherent; 1 = disfluent or incoherent).\n5. relevance (1-5): Are the statements in the candidate relevant to the question and gold answer (not introducing unrelated claims)? (5 = fully relevant; 1 = mostly irrelevant).\n\nREQUIREMENTS (strict):\n- Output **ONLY** a JSON object EXACTLY of the form:\n  {\"correctness\": <1-5>, \"completeness\": <1-5>, \"precision\": <1-5>, \"coherence\": <1-5>, \"relevance\": <1-5>}\n- No additional text, explanation, or whitespace outside the JSON object.\n\nFEW-SHOT EXAMPLE (this demonstrates the required output; do not include the example in actual responses):\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"No, the capital of Germany is not Paris, the capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":5,\"coherence\":5,\"relevance\":5}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"The capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":3,\"completeness\":2,\"precision\":5,\"coherence\":5,\"relevance\":2}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"If capital stands for the central administrative region of a country, then no, Paris is not the capital of Germany. It's important to note what is the definintion of a 'capital'. However, due to the common popular opinion, a capital of a country is well defined.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":1,\"coherence\":4,\"relevance\":1}\n\nEND OF SYSTEM PROMPT."}, {"role": "user", "content": [{"type": "text", "text": "Question: "}, {"type": "text", "text": "Gold reference 1: \"Kobe Bryant wore a band around his arm during a pre-season game at the University of Hawaii.\""}, {"type": "text", "text": "Candidate answer: Kobe Bryant wore a shooting sleeve around his arm during a pre-season game at the University of Hawaii."}, {"type": "text", "text": "Please score the candidate exactly with the five integer ratings in JSON as instructed by the system prompt."}]}]}}
{"custom_id": "d5bf713e0dba11ecb1e81171463288e9_geval", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-mini-2025-04-14", "max_tokens": 200, "temperature": 1, "n": 20, "messages": [{"role": "system", "content": "You are an evaluation assistant. You will be given:\n  - A question Q.\n  - A gold/reference answer (one or more short reference sentences).\n  - A candidate/sample answer produced by a system.\n\nYour job is to **assign integer scores** (1..5) for the following criteria comparing the *candidate* to the *gold/reference*:\n\n1. correctness (1-5): How factually correct is the candidate vs the gold answer? (5 = fully correct, 1 = mostly or fully incorrect).\n2. completeness (1-5): How completely does the candidate cover the key points in the gold answer? (5 = covers all key points; 1 = almost none).\n3. precision (1-5): How concise and focused is the candidate (not too long answer)? (5 = concise & precise; 1 = verbose / many extraneous claims).\n4. coherence (1-5): Is the candidate fluent and well-structured? (5 = natural, coherent; 1 = disfluent or incoherent).\n5. relevance (1-5): Are the statements in the candidate relevant to the question and gold answer (not introducing unrelated claims)? (5 = fully relevant; 1 = mostly irrelevant).\n\nREQUIREMENTS (strict):\n- Output **ONLY** a JSON object EXACTLY of the form:\n  {\"correctness\": <1-5>, \"completeness\": <1-5>, \"precision\": <1-5>, \"coherence\": <1-5>, \"relevance\": <1-5>}\n- No additional text, explanation, or whitespace outside the JSON object.\n\nFEW-SHOT EXAMPLE (this demonstrates the required output; do not include the example in actual responses):\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"No, the capital of Germany is not Paris, the capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":5,\"coherence\":5,\"relevance\":5}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"The capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":3,\"completeness\":2,\"precision\":5,\"coherence\":5,\"relevance\":2}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"If capital stands for the central administrative region of a country, then no, Paris is not the capital of Germany. It's important to note what is the definintion of a 'capital'. However, due to the common popular opinion, a capital of a country is well defined.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":1,\"coherence\":4,\"relevance\":1}\n\nEND OF SYSTEM PROMPT."}, {"role": "user", "content": [{"type": "text", "text": "Question: "}, {"type": "text", "text": "Gold reference 1: \"At Upminster Station District line platform 3, the white line is closer to the tracks than the yellow one.\""}, {"type": "text", "text": "Candidate answer: The yellow line is closer to the train tracks at Upminster station District line platform 3."}, {"type": "text", "text": "Please score the candidate exactly with the five integer ratings in JSON as instructed by the system prompt."}]}]}}
{"custom_id": "d5be8ba20dba11ecb1e81171463288e9_geval", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-mini-2025-04-14", "max_tokens": 200, "temperature": 1, "n": 20, "messages": [{"role": "system", "content": "You are an evaluation assistant. You will be given:\n  - A question Q.\n  - A gold/reference answer (one or more short reference sentences).\n  - A candidate/sample answer produced by a system.\n\nYour job is to **assign integer scores** (1..5) for the following criteria comparing the *candidate* to the *gold/reference*:\n\n1. correctness (1-5): How factually correct is the candidate vs the gold answer? (5 = fully correct, 1 = mostly or fully incorrect).\n2. completeness (1-5): How completely does the candidate cover the key points in the gold answer? (5 = covers all key points; 1 = almost none).\n3. precision (1-5): How concise and focused is the candidate (not too long answer)? (5 = concise & precise; 1 = verbose / many extraneous claims).\n4. coherence (1-5): Is the candidate fluent and well-structured? (5 = natural, coherent; 1 = disfluent or incoherent).\n5. relevance (1-5): Are the statements in the candidate relevant to the question and gold answer (not introducing unrelated claims)? (5 = fully relevant; 1 = mostly irrelevant).\n\nREQUIREMENTS (strict):\n- Output **ONLY** a JSON object EXACTLY of the form:\n  {\"correctness\": <1-5>, \"completeness\": <1-5>, \"precision\": <1-5>, \"coherence\": <1-5>, \"relevance\": <1-5>}\n- No additional text, explanation, or whitespace outside the JSON object.\n\nFEW-SHOT EXAMPLE (this demonstrates the required output; do not include the example in actual responses):\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"No, the capital of Germany is not Paris, the capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":5,\"coherence\":5,\"relevance\":5}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"The capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":3,\"completeness\":2,\"precision\":5,\"coherence\":5,\"relevance\":2}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"If capital stands for the central administrative region of a country, then no, Paris is not the capital of Germany. It's important to note what is the definintion of a 'capital'. However, due to the common popular opinion, a capital of a country is well defined.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":1,\"coherence\":4,\"relevance\":1}\n\nEND OF SYSTEM PROMPT."}, {"role": "user", "content": [{"type": "text", "text": "Question: "}, {"type": "text", "text": "Gold reference 1: \"The rear bumper of a 1950 Chevrolet Fastback has 2 upright protuberances.\""}, {"type": "text", "text": "Candidate answer: The rear bumper of a 1950 Chevrolet Fastback had two upright protuberances."}, {"type": "text", "text": "Please score the candidate exactly with the five integer ratings in JSON as instructed by the system prompt."}]}]}}
{"custom_id": "d5bc323a0dba11ecb1e81171463288e9_geval", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-mini-2025-04-14", "max_tokens": 200, "temperature": 1, "n": 20, "messages": [{"role": "system", "content": "You are an evaluation assistant. You will be given:\n  - A question Q.\n  - A gold/reference answer (one or more short reference sentences).\n  - A candidate/sample answer produced by a system.\n\nYour job is to **assign integer scores** (1..5) for the following criteria comparing the *candidate* to the *gold/reference*:\n\n1. correctness (1-5): How factually correct is the candidate vs the gold answer? (5 = fully correct, 1 = mostly or fully incorrect).\n2. completeness (1-5): How completely does the candidate cover the key points in the gold answer? (5 = covers all key points; 1 = almost none).\n3. precision (1-5): How concise and focused is the candidate (not too long answer)? (5 = concise & precise; 1 = verbose / many extraneous claims).\n4. coherence (1-5): Is the candidate fluent and well-structured? (5 = natural, coherent; 1 = disfluent or incoherent).\n5. relevance (1-5): Are the statements in the candidate relevant to the question and gold answer (not introducing unrelated claims)? (5 = fully relevant; 1 = mostly irrelevant).\n\nREQUIREMENTS (strict):\n- Output **ONLY** a JSON object EXACTLY of the form:\n  {\"correctness\": <1-5>, \"completeness\": <1-5>, \"precision\": <1-5>, \"coherence\": <1-5>, \"relevance\": <1-5>}\n- No additional text, explanation, or whitespace outside the JSON object.\n\nFEW-SHOT EXAMPLE (this demonstrates the required output; do not include the example in actual responses):\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"No, the capital of Germany is not Paris, the capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":5,\"coherence\":5,\"relevance\":5}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"The capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":3,\"completeness\":2,\"precision\":5,\"coherence\":5,\"relevance\":2}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"If capital stands for the central administrative region of a country, then no, Paris is not the capital of Germany. It's important to note what is the definintion of a 'capital'. However, due to the common popular opinion, a capital of a country is well defined.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":1,\"coherence\":4,\"relevance\":1}\n\nEND OF SYSTEM PROMPT."}, {"role": "user", "content": [{"type": "text", "text": "Question: "}, {"type": "text", "text": "Gold reference 1: \"The lettering on the sign for the Royal College of Art is white.\""}, {"type": "text", "text": "Candidate answer: The lettering on the sign for the Royal College of Art is white."}, {"type": "text", "text": "Please score the candidate exactly with the five integer ratings in JSON as instructed by the system prompt."}]}]}}
{"custom_id": "d5bc78300dba11ecb1e81171463288e9_geval", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-mini-2025-04-14", "max_tokens": 200, "temperature": 1, "n": 20, "messages": [{"role": "system", "content": "You are an evaluation assistant. You will be given:\n  - A question Q.\n  - A gold/reference answer (one or more short reference sentences).\n  - A candidate/sample answer produced by a system.\n\nYour job is to **assign integer scores** (1..5) for the following criteria comparing the *candidate* to the *gold/reference*:\n\n1. correctness (1-5): How factually correct is the candidate vs the gold answer? (5 = fully correct, 1 = mostly or fully incorrect).\n2. completeness (1-5): How completely does the candidate cover the key points in the gold answer? (5 = covers all key points; 1 = almost none).\n3. precision (1-5): How concise and focused is the candidate (not too long answer)? (5 = concise & precise; 1 = verbose / many extraneous claims).\n4. coherence (1-5): Is the candidate fluent and well-structured? (5 = natural, coherent; 1 = disfluent or incoherent).\n5. relevance (1-5): Are the statements in the candidate relevant to the question and gold answer (not introducing unrelated claims)? (5 = fully relevant; 1 = mostly irrelevant).\n\nREQUIREMENTS (strict):\n- Output **ONLY** a JSON object EXACTLY of the form:\n  {\"correctness\": <1-5>, \"completeness\": <1-5>, \"precision\": <1-5>, \"coherence\": <1-5>, \"relevance\": <1-5>}\n- No additional text, explanation, or whitespace outside the JSON object.\n\nFEW-SHOT EXAMPLE (this demonstrates the required output; do not include the example in actual responses):\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"No, the capital of Germany is not Paris, the capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":5,\"coherence\":5,\"relevance\":5}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"The capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":3,\"completeness\":2,\"precision\":5,\"coherence\":5,\"relevance\":2}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"If capital stands for the central administrative region of a country, then no, Paris is not the capital of Germany. It's important to note what is the definintion of a 'capital'. However, due to the common popular opinion, a capital of a country is well defined.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":1,\"coherence\":4,\"relevance\":1}\n\nEND OF SYSTEM PROMPT."}, {"role": "user", "content": [{"type": "text", "text": "Question: "}, {"type": "text", "text": "Gold reference 1: \"The exterior of the Bird's Nest at the Olympic Stadium in Bejing, China is made of metal.\""}, {"type": "text", "text": "Candidate answer: The exterior of the Bird's Nest at the Olympic Stadium in Beijing is made of a steel structure."}, {"type": "text", "text": "Please score the candidate exactly with the five integer ratings in JSON as instructed by the system prompt."}]}]}}
{"custom_id": "d5bdc3160dba11ecb1e81171463288e9_geval", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-mini-2025-04-14", "max_tokens": 200, "temperature": 1, "n": 20, "messages": [{"role": "system", "content": "You are an evaluation assistant. You will be given:\n  - A question Q.\n  - A gold/reference answer (one or more short reference sentences).\n  - A candidate/sample answer produced by a system.\n\nYour job is to **assign integer scores** (1..5) for the following criteria comparing the *candidate* to the *gold/reference*:\n\n1. correctness (1-5): How factually correct is the candidate vs the gold answer? (5 = fully correct, 1 = mostly or fully incorrect).\n2. completeness (1-5): How completely does the candidate cover the key points in the gold answer? (5 = covers all key points; 1 = almost none).\n3. precision (1-5): How concise and focused is the candidate (not too long answer)? (5 = concise & precise; 1 = verbose / many extraneous claims).\n4. coherence (1-5): Is the candidate fluent and well-structured? (5 = natural, coherent; 1 = disfluent or incoherent).\n5. relevance (1-5): Are the statements in the candidate relevant to the question and gold answer (not introducing unrelated claims)? (5 = fully relevant; 1 = mostly irrelevant).\n\nREQUIREMENTS (strict):\n- Output **ONLY** a JSON object EXACTLY of the form:\n  {\"correctness\": <1-5>, \"completeness\": <1-5>, \"precision\": <1-5>, \"coherence\": <1-5>, \"relevance\": <1-5>}\n- No additional text, explanation, or whitespace outside the JSON object.\n\nFEW-SHOT EXAMPLE (this demonstrates the required output; do not include the example in actual responses):\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"No, the capital of Germany is not Paris, the capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":5,\"coherence\":5,\"relevance\":5}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"The capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":3,\"completeness\":2,\"precision\":5,\"coherence\":5,\"relevance\":2}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"If capital stands for the central administrative region of a country, then no, Paris is not the capital of Germany. It's important to note what is the definintion of a 'capital'. However, due to the common popular opinion, a capital of a country is well defined.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":1,\"coherence\":4,\"relevance\":1}\n\nEND OF SYSTEM PROMPT."}, {"role": "user", "content": [{"type": "text", "text": "Question: "}, {"type": "text", "text": "Gold reference 1: \"Ralph W. Rose was photographed throwing a discus and the shot put at the 1904 Olympics.\""}, {"type": "text", "text": "Candidate answer: Ralph W. Rose was photographed throwing the shot put and the discus at the 1904 Olympics."}, {"type": "text", "text": "Please score the candidate exactly with the five integer ratings in JSON as instructed by the system prompt."}]}]}}
{"custom_id": "d5bf73a00dba11ecb1e81171463288e9_geval", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-mini-2025-04-14", "max_tokens": 200, "temperature": 1, "n": 20, "messages": [{"role": "system", "content": "You are an evaluation assistant. You will be given:\n  - A question Q.\n  - A gold/reference answer (one or more short reference sentences).\n  - A candidate/sample answer produced by a system.\n\nYour job is to **assign integer scores** (1..5) for the following criteria comparing the *candidate* to the *gold/reference*:\n\n1. correctness (1-5): How factually correct is the candidate vs the gold answer? (5 = fully correct, 1 = mostly or fully incorrect).\n2. completeness (1-5): How completely does the candidate cover the key points in the gold answer? (5 = covers all key points; 1 = almost none).\n3. precision (1-5): How concise and focused is the candidate (not too long answer)? (5 = concise & precise; 1 = verbose / many extraneous claims).\n4. coherence (1-5): Is the candidate fluent and well-structured? (5 = natural, coherent; 1 = disfluent or incoherent).\n5. relevance (1-5): Are the statements in the candidate relevant to the question and gold answer (not introducing unrelated claims)? (5 = fully relevant; 1 = mostly irrelevant).\n\nREQUIREMENTS (strict):\n- Output **ONLY** a JSON object EXACTLY of the form:\n  {\"correctness\": <1-5>, \"completeness\": <1-5>, \"precision\": <1-5>, \"coherence\": <1-5>, \"relevance\": <1-5>}\n- No additional text, explanation, or whitespace outside the JSON object.\n\nFEW-SHOT EXAMPLE (this demonstrates the required output; do not include the example in actual responses):\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"No, the capital of Germany is not Paris, the capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":5,\"coherence\":5,\"relevance\":5}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"The capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":3,\"completeness\":2,\"precision\":5,\"coherence\":5,\"relevance\":2}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"If capital stands for the central administrative region of a country, then no, Paris is not the capital of Germany. It's important to note what is the definintion of a 'capital'. However, due to the common popular opinion, a capital of a country is well defined.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":1,\"coherence\":4,\"relevance\":1}\n\nEND OF SYSTEM PROMPT."}, {"role": "user", "content": [{"type": "text", "text": "Question: "}, {"type": "text", "text": "Gold reference 1: \"Huashan Upside Down House and Wonderworks in Florida are both upside down.\""}, {"type": "text", "text": "Candidate answer: Both the Huashan Upside Down House and Wonderworks in Florida are attractions designed to create an illusion of being upside down, featuring unique architectural designs that challenge perceptions."}, {"type": "text", "text": "Please score the candidate exactly with the five integer ratings in JSON as instructed by the system prompt."}]}]}}
{"custom_id": "d5becae00dba11ecb1e81171463288e9_geval", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-mini-2025-04-14", "max_tokens": 200, "temperature": 1, "n": 20, "messages": [{"role": "system", "content": "You are an evaluation assistant. You will be given:\n  - A question Q.\n  - A gold/reference answer (one or more short reference sentences).\n  - A candidate/sample answer produced by a system.\n\nYour job is to **assign integer scores** (1..5) for the following criteria comparing the *candidate* to the *gold/reference*:\n\n1. correctness (1-5): How factually correct is the candidate vs the gold answer? (5 = fully correct, 1 = mostly or fully incorrect).\n2. completeness (1-5): How completely does the candidate cover the key points in the gold answer? (5 = covers all key points; 1 = almost none).\n3. precision (1-5): How concise and focused is the candidate (not too long answer)? (5 = concise & precise; 1 = verbose / many extraneous claims).\n4. coherence (1-5): Is the candidate fluent and well-structured? (5 = natural, coherent; 1 = disfluent or incoherent).\n5. relevance (1-5): Are the statements in the candidate relevant to the question and gold answer (not introducing unrelated claims)? (5 = fully relevant; 1 = mostly irrelevant).\n\nREQUIREMENTS (strict):\n- Output **ONLY** a JSON object EXACTLY of the form:\n  {\"correctness\": <1-5>, \"completeness\": <1-5>, \"precision\": <1-5>, \"coherence\": <1-5>, \"relevance\": <1-5>}\n- No additional text, explanation, or whitespace outside the JSON object.\n\nFEW-SHOT EXAMPLE (this demonstrates the required output; do not include the example in actual responses):\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"No, the capital of Germany is not Paris, the capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":5,\"coherence\":5,\"relevance\":5}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"The capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":3,\"completeness\":2,\"precision\":5,\"coherence\":5,\"relevance\":2}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"If capital stands for the central administrative region of a country, then no, Paris is not the capital of Germany. It's important to note what is the definintion of a 'capital'. However, due to the common popular opinion, a capital of a country is well defined.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":1,\"coherence\":4,\"relevance\":1}\n\nEND OF SYSTEM PROMPT."}, {"role": "user", "content": [{"type": "text", "text": "Question: "}, {"type": "text", "text": "Gold reference 1: \"Espinoza's jersey has a Puma logo.\""}, {"type": "text", "text": "Candidate answer: The sports apparel logo on the jersey of UNAM player Fernando Espinoza is the red letter U."}, {"type": "text", "text": "Please score the candidate exactly with the five integer ratings in JSON as instructed by the system prompt."}]}]}}
{"custom_id": "d5be937c0dba11ecb1e81171463288e9_geval", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-mini-2025-04-14", "max_tokens": 200, "temperature": 1, "n": 20, "messages": [{"role": "system", "content": "You are an evaluation assistant. You will be given:\n  - A question Q.\n  - A gold/reference answer (one or more short reference sentences).\n  - A candidate/sample answer produced by a system.\n\nYour job is to **assign integer scores** (1..5) for the following criteria comparing the *candidate* to the *gold/reference*:\n\n1. correctness (1-5): How factually correct is the candidate vs the gold answer? (5 = fully correct, 1 = mostly or fully incorrect).\n2. completeness (1-5): How completely does the candidate cover the key points in the gold answer? (5 = covers all key points; 1 = almost none).\n3. precision (1-5): How concise and focused is the candidate (not too long answer)? (5 = concise & precise; 1 = verbose / many extraneous claims).\n4. coherence (1-5): Is the candidate fluent and well-structured? (5 = natural, coherent; 1 = disfluent or incoherent).\n5. relevance (1-5): Are the statements in the candidate relevant to the question and gold answer (not introducing unrelated claims)? (5 = fully relevant; 1 = mostly irrelevant).\n\nREQUIREMENTS (strict):\n- Output **ONLY** a JSON object EXACTLY of the form:\n  {\"correctness\": <1-5>, \"completeness\": <1-5>, \"precision\": <1-5>, \"coherence\": <1-5>, \"relevance\": <1-5>}\n- No additional text, explanation, or whitespace outside the JSON object.\n\nFEW-SHOT EXAMPLE (this demonstrates the required output; do not include the example in actual responses):\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"No, the capital of Germany is not Paris, the capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":5,\"coherence\":5,\"relevance\":5}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"The capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":3,\"completeness\":2,\"precision\":5,\"coherence\":5,\"relevance\":2}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"If capital stands for the central administrative region of a country, then no, Paris is not the capital of Germany. It's important to note what is the definintion of a 'capital'. However, due to the common popular opinion, a capital of a country is well defined.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":1,\"coherence\":4,\"relevance\":1}\n\nEND OF SYSTEM PROMPT."}, {"role": "user", "content": [{"type": "text", "text": "Question: "}, {"type": "text", "text": "Gold reference 1: \"Ten concentric circles form the Covent Garden maze.\""}, {"type": "text", "text": "Candidate answer: The Covent Garden maze is formed by 12 concentric circles."}, {"type": "text", "text": "Please score the candidate exactly with the five integer ratings in JSON as instructed by the system prompt."}]}]}}
{"custom_id": "d5bf0d520dba11ecb1e81171463288e9_geval", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-mini-2025-04-14", "max_tokens": 200, "temperature": 1, "n": 20, "messages": [{"role": "system", "content": "You are an evaluation assistant. You will be given:\n  - A question Q.\n  - A gold/reference answer (one or more short reference sentences).\n  - A candidate/sample answer produced by a system.\n\nYour job is to **assign integer scores** (1..5) for the following criteria comparing the *candidate* to the *gold/reference*:\n\n1. correctness (1-5): How factually correct is the candidate vs the gold answer? (5 = fully correct, 1 = mostly or fully incorrect).\n2. completeness (1-5): How completely does the candidate cover the key points in the gold answer? (5 = covers all key points; 1 = almost none).\n3. precision (1-5): How concise and focused is the candidate (not too long answer)? (5 = concise & precise; 1 = verbose / many extraneous claims).\n4. coherence (1-5): Is the candidate fluent and well-structured? (5 = natural, coherent; 1 = disfluent or incoherent).\n5. relevance (1-5): Are the statements in the candidate relevant to the question and gold answer (not introducing unrelated claims)? (5 = fully relevant; 1 = mostly irrelevant).\n\nREQUIREMENTS (strict):\n- Output **ONLY** a JSON object EXACTLY of the form:\n  {\"correctness\": <1-5>, \"completeness\": <1-5>, \"precision\": <1-5>, \"coherence\": <1-5>, \"relevance\": <1-5>}\n- No additional text, explanation, or whitespace outside the JSON object.\n\nFEW-SHOT EXAMPLE (this demonstrates the required output; do not include the example in actual responses):\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"No, the capital of Germany is not Paris, the capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":5,\"coherence\":5,\"relevance\":5}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"The capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":3,\"completeness\":2,\"precision\":5,\"coherence\":5,\"relevance\":2}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"If capital stands for the central administrative region of a country, then no, Paris is not the capital of Germany. It's important to note what is the definintion of a 'capital'. However, due to the common popular opinion, a capital of a country is well defined.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":1,\"coherence\":4,\"relevance\":1}\n\nEND OF SYSTEM PROMPT."}, {"role": "user", "content": [{"type": "text", "text": "Question: "}, {"type": "text", "text": "Gold reference 1: \"The Ultima Tower in Edmonton, AB is taller than The Timms Centre of the University of Alberta in Edmonton, Alberta, Canada.\""}, {"type": "text", "text": "Candidate answer: The Ultima Tower is taller than The Timms Centre of the University of Alberta."}, {"type": "text", "text": "Please score the candidate exactly with the five integer ratings in JSON as instructed by the system prompt."}]}]}}
{"custom_id": "d5bfa0d20dba11ecb1e81171463288e9_geval", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-mini-2025-04-14", "max_tokens": 200, "temperature": 1, "n": 20, "messages": [{"role": "system", "content": "You are an evaluation assistant. You will be given:\n  - A question Q.\n  - A gold/reference answer (one or more short reference sentences).\n  - A candidate/sample answer produced by a system.\n\nYour job is to **assign integer scores** (1..5) for the following criteria comparing the *candidate* to the *gold/reference*:\n\n1. correctness (1-5): How factually correct is the candidate vs the gold answer? (5 = fully correct, 1 = mostly or fully incorrect).\n2. completeness (1-5): How completely does the candidate cover the key points in the gold answer? (5 = covers all key points; 1 = almost none).\n3. precision (1-5): How concise and focused is the candidate (not too long answer)? (5 = concise & precise; 1 = verbose / many extraneous claims).\n4. coherence (1-5): Is the candidate fluent and well-structured? (5 = natural, coherent; 1 = disfluent or incoherent).\n5. relevance (1-5): Are the statements in the candidate relevant to the question and gold answer (not introducing unrelated claims)? (5 = fully relevant; 1 = mostly irrelevant).\n\nREQUIREMENTS (strict):\n- Output **ONLY** a JSON object EXACTLY of the form:\n  {\"correctness\": <1-5>, \"completeness\": <1-5>, \"precision\": <1-5>, \"coherence\": <1-5>, \"relevance\": <1-5>}\n- No additional text, explanation, or whitespace outside the JSON object.\n\nFEW-SHOT EXAMPLE (this demonstrates the required output; do not include the example in actual responses):\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"No, the capital of Germany is not Paris, the capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":5,\"coherence\":5,\"relevance\":5}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"The capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":3,\"completeness\":2,\"precision\":5,\"coherence\":5,\"relevance\":2}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"If capital stands for the central administrative region of a country, then no, Paris is not the capital of Germany. It's important to note what is the definintion of a 'capital'. However, due to the common popular opinion, a capital of a country is well defined.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":1,\"coherence\":4,\"relevance\":1}\n\nEND OF SYSTEM PROMPT."}, {"role": "user", "content": [{"type": "text", "text": "Question: "}, {"type": "text", "text": "Gold reference 1: \"The Orangutan does not have long hair covering its face.\""}, {"type": "text", "text": "Candidate answer: Yes, orangutans have long hair covering their faces, especially in mature individuals."}, {"type": "text", "text": "Please score the candidate exactly with the five integer ratings in JSON as instructed by the system prompt."}]}]}}
{"custom_id": "d5bbdea20dba11ecb1e81171463288e9_geval", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-mini-2025-04-14", "max_tokens": 200, "temperature": 1, "n": 20, "messages": [{"role": "system", "content": "You are an evaluation assistant. You will be given:\n  - A question Q.\n  - A gold/reference answer (one or more short reference sentences).\n  - A candidate/sample answer produced by a system.\n\nYour job is to **assign integer scores** (1..5) for the following criteria comparing the *candidate* to the *gold/reference*:\n\n1. correctness (1-5): How factually correct is the candidate vs the gold answer? (5 = fully correct, 1 = mostly or fully incorrect).\n2. completeness (1-5): How completely does the candidate cover the key points in the gold answer? (5 = covers all key points; 1 = almost none).\n3. precision (1-5): How concise and focused is the candidate (not too long answer)? (5 = concise & precise; 1 = verbose / many extraneous claims).\n4. coherence (1-5): Is the candidate fluent and well-structured? (5 = natural, coherent; 1 = disfluent or incoherent).\n5. relevance (1-5): Are the statements in the candidate relevant to the question and gold answer (not introducing unrelated claims)? (5 = fully relevant; 1 = mostly irrelevant).\n\nREQUIREMENTS (strict):\n- Output **ONLY** a JSON object EXACTLY of the form:\n  {\"correctness\": <1-5>, \"completeness\": <1-5>, \"precision\": <1-5>, \"coherence\": <1-5>, \"relevance\": <1-5>}\n- No additional text, explanation, or whitespace outside the JSON object.\n\nFEW-SHOT EXAMPLE (this demonstrates the required output; do not include the example in actual responses):\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"No, the capital of Germany is not Paris, the capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":5,\"coherence\":5,\"relevance\":5}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"The capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":3,\"completeness\":2,\"precision\":5,\"coherence\":5,\"relevance\":2}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"If capital stands for the central administrative region of a country, then no, Paris is not the capital of Germany. It's important to note what is the definintion of a 'capital'. However, due to the common popular opinion, a capital of a country is well defined.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":1,\"coherence\":4,\"relevance\":1}\n\nEND OF SYSTEM PROMPT."}, {"role": "user", "content": [{"type": "text", "text": "Question: "}, {"type": "text", "text": "Gold reference 1: \"The boy's pink tongue is the one element that is not black and white on the Season's Greetings mural by graffiti artist Banksy, stenciled on a garage in Port Talbot, Wales in December 2018.\""}, {"type": "text", "text": "Candidate answer: The one part of the mural that is a different color is the red of the boy's sled."}, {"type": "text", "text": "Please score the candidate exactly with the five integer ratings in JSON as instructed by the system prompt."}]}]}}
{"custom_id": "d5bbe99c0dba11ecb1e81171463288e9_geval", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-mini-2025-04-14", "max_tokens": 200, "temperature": 1, "n": 20, "messages": [{"role": "system", "content": "You are an evaluation assistant. You will be given:\n  - A question Q.\n  - A gold/reference answer (one or more short reference sentences).\n  - A candidate/sample answer produced by a system.\n\nYour job is to **assign integer scores** (1..5) for the following criteria comparing the *candidate* to the *gold/reference*:\n\n1. correctness (1-5): How factually correct is the candidate vs the gold answer? (5 = fully correct, 1 = mostly or fully incorrect).\n2. completeness (1-5): How completely does the candidate cover the key points in the gold answer? (5 = covers all key points; 1 = almost none).\n3. precision (1-5): How concise and focused is the candidate (not too long answer)? (5 = concise & precise; 1 = verbose / many extraneous claims).\n4. coherence (1-5): Is the candidate fluent and well-structured? (5 = natural, coherent; 1 = disfluent or incoherent).\n5. relevance (1-5): Are the statements in the candidate relevant to the question and gold answer (not introducing unrelated claims)? (5 = fully relevant; 1 = mostly irrelevant).\n\nREQUIREMENTS (strict):\n- Output **ONLY** a JSON object EXACTLY of the form:\n  {\"correctness\": <1-5>, \"completeness\": <1-5>, \"precision\": <1-5>, \"coherence\": <1-5>, \"relevance\": <1-5>}\n- No additional text, explanation, or whitespace outside the JSON object.\n\nFEW-SHOT EXAMPLE (this demonstrates the required output; do not include the example in actual responses):\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"No, the capital of Germany is not Paris, the capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":5,\"coherence\":5,\"relevance\":5}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"The capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":3,\"completeness\":2,\"precision\":5,\"coherence\":5,\"relevance\":2}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"If capital stands for the central administrative region of a country, then no, Paris is not the capital of Germany. It's important to note what is the definintion of a 'capital'. However, due to the common popular opinion, a capital of a country is well defined.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":1,\"coherence\":4,\"relevance\":1}\n\nEND OF SYSTEM PROMPT."}, {"role": "user", "content": [{"type": "text", "text": "Question: "}, {"type": "text", "text": "Gold reference 1: \"The trashcans on British Columbia's 546-52 Fisgard Street are red.\""}, {"type": "text", "text": "Candidate answer: The trashcans on 546-52 Fisgard Street in British Columbia are red."}, {"type": "text", "text": "Please score the candidate exactly with the five integer ratings in JSON as instructed by the system prompt."}]}]}}
{"custom_id": "d5bbe1180dba11ecb1e81171463288e9_geval", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-mini-2025-04-14", "max_tokens": 200, "temperature": 1, "n": 20, "messages": [{"role": "system", "content": "You are an evaluation assistant. You will be given:\n  - A question Q.\n  - A gold/reference answer (one or more short reference sentences).\n  - A candidate/sample answer produced by a system.\n\nYour job is to **assign integer scores** (1..5) for the following criteria comparing the *candidate* to the *gold/reference*:\n\n1. correctness (1-5): How factually correct is the candidate vs the gold answer? (5 = fully correct, 1 = mostly or fully incorrect).\n2. completeness (1-5): How completely does the candidate cover the key points in the gold answer? (5 = covers all key points; 1 = almost none).\n3. precision (1-5): How concise and focused is the candidate (not too long answer)? (5 = concise & precise; 1 = verbose / many extraneous claims).\n4. coherence (1-5): Is the candidate fluent and well-structured? (5 = natural, coherent; 1 = disfluent or incoherent).\n5. relevance (1-5): Are the statements in the candidate relevant to the question and gold answer (not introducing unrelated claims)? (5 = fully relevant; 1 = mostly irrelevant).\n\nREQUIREMENTS (strict):\n- Output **ONLY** a JSON object EXACTLY of the form:\n  {\"correctness\": <1-5>, \"completeness\": <1-5>, \"precision\": <1-5>, \"coherence\": <1-5>, \"relevance\": <1-5>}\n- No additional text, explanation, or whitespace outside the JSON object.\n\nFEW-SHOT EXAMPLE (this demonstrates the required output; do not include the example in actual responses):\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"No, the capital of Germany is not Paris, the capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":5,\"coherence\":5,\"relevance\":5}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"The capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":3,\"completeness\":2,\"precision\":5,\"coherence\":5,\"relevance\":2}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"If capital stands for the central administrative region of a country, then no, Paris is not the capital of Germany. It's important to note what is the definintion of a 'capital'. However, due to the common popular opinion, a capital of a country is well defined.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":1,\"coherence\":4,\"relevance\":1}\n\nEND OF SYSTEM PROMPT."}, {"role": "user", "content": [{"type": "text", "text": "Question: "}, {"type": "text", "text": "Gold reference 1: \"There was a metallic sheen on the exterior of the Apollo 11 lunar module.\""}, {"type": "text", "text": "Candidate answer: The exterior of the lunar module during the Apollo 11 mission had a shiny, reflective surface, which was designed to protect it from the extreme temperatures of space."}, {"type": "text", "text": "Please score the candidate exactly with the five integer ratings in JSON as instructed by the system prompt."}]}]}}
{"custom_id": "d5bdfee40dba11ecb1e81171463288e9_geval", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-mini-2025-04-14", "max_tokens": 200, "temperature": 1, "n": 20, "messages": [{"role": "system", "content": "You are an evaluation assistant. You will be given:\n  - A question Q.\n  - A gold/reference answer (one or more short reference sentences).\n  - A candidate/sample answer produced by a system.\n\nYour job is to **assign integer scores** (1..5) for the following criteria comparing the *candidate* to the *gold/reference*:\n\n1. correctness (1-5): How factually correct is the candidate vs the gold answer? (5 = fully correct, 1 = mostly or fully incorrect).\n2. completeness (1-5): How completely does the candidate cover the key points in the gold answer? (5 = covers all key points; 1 = almost none).\n3. precision (1-5): How concise and focused is the candidate (not too long answer)? (5 = concise & precise; 1 = verbose / many extraneous claims).\n4. coherence (1-5): Is the candidate fluent and well-structured? (5 = natural, coherent; 1 = disfluent or incoherent).\n5. relevance (1-5): Are the statements in the candidate relevant to the question and gold answer (not introducing unrelated claims)? (5 = fully relevant; 1 = mostly irrelevant).\n\nREQUIREMENTS (strict):\n- Output **ONLY** a JSON object EXACTLY of the form:\n  {\"correctness\": <1-5>, \"completeness\": <1-5>, \"precision\": <1-5>, \"coherence\": <1-5>, \"relevance\": <1-5>}\n- No additional text, explanation, or whitespace outside the JSON object.\n\nFEW-SHOT EXAMPLE (this demonstrates the required output; do not include the example in actual responses):\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"No, the capital of Germany is not Paris, the capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":5,\"coherence\":5,\"relevance\":5}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"The capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":3,\"completeness\":2,\"precision\":5,\"coherence\":5,\"relevance\":2}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"If capital stands for the central administrative region of a country, then no, Paris is not the capital of Germany. It's important to note what is the definintion of a 'capital'. However, due to the common popular opinion, a capital of a country is well defined.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":1,\"coherence\":4,\"relevance\":1}\n\nEND OF SYSTEM PROMPT."}, {"role": "user", "content": [{"type": "text", "text": "Question: "}, {"type": "text", "text": "Gold reference 1: \"The color of the horse seen in Jacopo Tintoretto's \"crocifissione\" is white.\""}, {"type": "text", "text": "Candidate answer: The horse in Jacopo Tintoretto's \"Crocifissione\" is white."}, {"type": "text", "text": "Please score the candidate exactly with the five integer ratings in JSON as instructed by the system prompt."}]}]}}
{"custom_id": "d5bd83f60dba11ecb1e81171463288e9_geval", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-mini-2025-04-14", "max_tokens": 200, "temperature": 1, "n": 20, "messages": [{"role": "system", "content": "You are an evaluation assistant. You will be given:\n  - A question Q.\n  - A gold/reference answer (one or more short reference sentences).\n  - A candidate/sample answer produced by a system.\n\nYour job is to **assign integer scores** (1..5) for the following criteria comparing the *candidate* to the *gold/reference*:\n\n1. correctness (1-5): How factually correct is the candidate vs the gold answer? (5 = fully correct, 1 = mostly or fully incorrect).\n2. completeness (1-5): How completely does the candidate cover the key points in the gold answer? (5 = covers all key points; 1 = almost none).\n3. precision (1-5): How concise and focused is the candidate (not too long answer)? (5 = concise & precise; 1 = verbose / many extraneous claims).\n4. coherence (1-5): Is the candidate fluent and well-structured? (5 = natural, coherent; 1 = disfluent or incoherent).\n5. relevance (1-5): Are the statements in the candidate relevant to the question and gold answer (not introducing unrelated claims)? (5 = fully relevant; 1 = mostly irrelevant).\n\nREQUIREMENTS (strict):\n- Output **ONLY** a JSON object EXACTLY of the form:\n  {\"correctness\": <1-5>, \"completeness\": <1-5>, \"precision\": <1-5>, \"coherence\": <1-5>, \"relevance\": <1-5>}\n- No additional text, explanation, or whitespace outside the JSON object.\n\nFEW-SHOT EXAMPLE (this demonstrates the required output; do not include the example in actual responses):\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"No, the capital of Germany is not Paris, the capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":5,\"coherence\":5,\"relevance\":5}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"The capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":3,\"completeness\":2,\"precision\":5,\"coherence\":5,\"relevance\":2}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"If capital stands for the central administrative region of a country, then no, Paris is not the capital of Germany. It's important to note what is the definintion of a 'capital'. However, due to the common popular opinion, a capital of a country is well defined.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":1,\"coherence\":4,\"relevance\":1}\n\nEND OF SYSTEM PROMPT."}, {"role": "user", "content": [{"type": "text", "text": "Question: "}, {"type": "text", "text": "Gold reference 1: \"The German and Finnish teams had miniature flags of their respective countries during the 2010 Olympic Winter Games Opening Ceremony.\""}, {"type": "text", "text": "Candidate answer: Yes, both the German and Finnish teams had miniature flags of their respective countries during the 2010 Olympic Winter Games Opening Ceremony."}, {"type": "text", "text": "Please score the candidate exactly with the five integer ratings in JSON as instructed by the system prompt."}]}]}}
{"custom_id": "d5bf611c0dba11ecb1e81171463288e9_geval", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-mini-2025-04-14", "max_tokens": 200, "temperature": 1, "n": 20, "messages": [{"role": "system", "content": "You are an evaluation assistant. You will be given:\n  - A question Q.\n  - A gold/reference answer (one or more short reference sentences).\n  - A candidate/sample answer produced by a system.\n\nYour job is to **assign integer scores** (1..5) for the following criteria comparing the *candidate* to the *gold/reference*:\n\n1. correctness (1-5): How factually correct is the candidate vs the gold answer? (5 = fully correct, 1 = mostly or fully incorrect).\n2. completeness (1-5): How completely does the candidate cover the key points in the gold answer? (5 = covers all key points; 1 = almost none).\n3. precision (1-5): How concise and focused is the candidate (not too long answer)? (5 = concise & precise; 1 = verbose / many extraneous claims).\n4. coherence (1-5): Is the candidate fluent and well-structured? (5 = natural, coherent; 1 = disfluent or incoherent).\n5. relevance (1-5): Are the statements in the candidate relevant to the question and gold answer (not introducing unrelated claims)? (5 = fully relevant; 1 = mostly irrelevant).\n\nREQUIREMENTS (strict):\n- Output **ONLY** a JSON object EXACTLY of the form:\n  {\"correctness\": <1-5>, \"completeness\": <1-5>, \"precision\": <1-5>, \"coherence\": <1-5>, \"relevance\": <1-5>}\n- No additional text, explanation, or whitespace outside the JSON object.\n\nFEW-SHOT EXAMPLE (this demonstrates the required output; do not include the example in actual responses):\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"No, the capital of Germany is not Paris, the capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":5,\"coherence\":5,\"relevance\":5}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"The capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":3,\"completeness\":2,\"precision\":5,\"coherence\":5,\"relevance\":2}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"If capital stands for the central administrative region of a country, then no, Paris is not the capital of Germany. It's important to note what is the definintion of a 'capital'. However, due to the common popular opinion, a capital of a country is well defined.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":1,\"coherence\":4,\"relevance\":1}\n\nEND OF SYSTEM PROMPT."}, {"role": "user", "content": [{"type": "text", "text": "Question: "}, {"type": "text", "text": "Gold reference 1: \"You can park on both sides of the street at the main branch of the Indianapolis-Marion County Public Library.\""}, {"type": "text", "text": "Candidate answer: Parking is available on both sides of the street at the main branch of the Indianapolis-Marion County Public Library."}, {"type": "text", "text": "Please score the candidate exactly with the five integer ratings in JSON as instructed by the system prompt."}]}]}}
{"custom_id": "d5bf76f20dba11ecb1e81171463288e9_geval", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-mini-2025-04-14", "max_tokens": 200, "temperature": 1, "n": 20, "messages": [{"role": "system", "content": "You are an evaluation assistant. You will be given:\n  - A question Q.\n  - A gold/reference answer (one or more short reference sentences).\n  - A candidate/sample answer produced by a system.\n\nYour job is to **assign integer scores** (1..5) for the following criteria comparing the *candidate* to the *gold/reference*:\n\n1. correctness (1-5): How factually correct is the candidate vs the gold answer? (5 = fully correct, 1 = mostly or fully incorrect).\n2. completeness (1-5): How completely does the candidate cover the key points in the gold answer? (5 = covers all key points; 1 = almost none).\n3. precision (1-5): How concise and focused is the candidate (not too long answer)? (5 = concise & precise; 1 = verbose / many extraneous claims).\n4. coherence (1-5): Is the candidate fluent and well-structured? (5 = natural, coherent; 1 = disfluent or incoherent).\n5. relevance (1-5): Are the statements in the candidate relevant to the question and gold answer (not introducing unrelated claims)? (5 = fully relevant; 1 = mostly irrelevant).\n\nREQUIREMENTS (strict):\n- Output **ONLY** a JSON object EXACTLY of the form:\n  {\"correctness\": <1-5>, \"completeness\": <1-5>, \"precision\": <1-5>, \"coherence\": <1-5>, \"relevance\": <1-5>}\n- No additional text, explanation, or whitespace outside the JSON object.\n\nFEW-SHOT EXAMPLE (this demonstrates the required output; do not include the example in actual responses):\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"No, the capital of Germany is not Paris, the capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":5,\"coherence\":5,\"relevance\":5}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"The capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":3,\"completeness\":2,\"precision\":5,\"coherence\":5,\"relevance\":2}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"If capital stands for the central administrative region of a country, then no, Paris is not the capital of Germany. It's important to note what is the definintion of a 'capital'. However, due to the common popular opinion, a capital of a country is well defined.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":1,\"coherence\":4,\"relevance\":1}\n\nEND OF SYSTEM PROMPT."}, {"role": "user", "content": [{"type": "text", "text": "Question: "}, {"type": "text", "text": "Gold reference 1: \"Calocera viscosa appears to be more like a sea coral.\""}, {"type": "text", "text": "Candidate answer: Calocera viscosa appears more like a sea coral due to its branching, coral-like structure, while Pluteus salcinus has a more typical mushroom shape."}, {"type": "text", "text": "Please score the candidate exactly with the five integer ratings in JSON as instructed by the system prompt."}]}]}}
{"custom_id": "d5bece0a0dba11ecb1e81171463288e9_geval", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-mini-2025-04-14", "max_tokens": 200, "temperature": 1, "n": 20, "messages": [{"role": "system", "content": "You are an evaluation assistant. You will be given:\n  - A question Q.\n  - A gold/reference answer (one or more short reference sentences).\n  - A candidate/sample answer produced by a system.\n\nYour job is to **assign integer scores** (1..5) for the following criteria comparing the *candidate* to the *gold/reference*:\n\n1. correctness (1-5): How factually correct is the candidate vs the gold answer? (5 = fully correct, 1 = mostly or fully incorrect).\n2. completeness (1-5): How completely does the candidate cover the key points in the gold answer? (5 = covers all key points; 1 = almost none).\n3. precision (1-5): How concise and focused is the candidate (not too long answer)? (5 = concise & precise; 1 = verbose / many extraneous claims).\n4. coherence (1-5): Is the candidate fluent and well-structured? (5 = natural, coherent; 1 = disfluent or incoherent).\n5. relevance (1-5): Are the statements in the candidate relevant to the question and gold answer (not introducing unrelated claims)? (5 = fully relevant; 1 = mostly irrelevant).\n\nREQUIREMENTS (strict):\n- Output **ONLY** a JSON object EXACTLY of the form:\n  {\"correctness\": <1-5>, \"completeness\": <1-5>, \"precision\": <1-5>, \"coherence\": <1-5>, \"relevance\": <1-5>}\n- No additional text, explanation, or whitespace outside the JSON object.\n\nFEW-SHOT EXAMPLE (this demonstrates the required output; do not include the example in actual responses):\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"No, the capital of Germany is not Paris, the capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":5,\"coherence\":5,\"relevance\":5}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"The capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":3,\"completeness\":2,\"precision\":5,\"coherence\":5,\"relevance\":2}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"If capital stands for the central administrative region of a country, then no, Paris is not the capital of Germany. It's important to note what is the definintion of a 'capital'. However, due to the common popular opinion, a capital of a country is well defined.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":1,\"coherence\":4,\"relevance\":1}\n\nEND OF SYSTEM PROMPT."}, {"role": "user", "content": [{"type": "text", "text": "Question: "}, {"type": "text", "text": "Gold reference 1: \"The floor tiles in The Codrington Library, All Souls College, Oxford are white, gray and black.\""}, {"type": "text", "text": "Candidate answer: The floor tile in The Codrington Library is comprised of black, white, and grey colors."}, {"type": "text", "text": "Please score the candidate exactly with the five integer ratings in JSON as instructed by the system prompt."}]}]}}
{"custom_id": "d5be87560dba11ecb1e81171463288e9_geval", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-mini-2025-04-14", "max_tokens": 200, "temperature": 1, "n": 20, "messages": [{"role": "system", "content": "You are an evaluation assistant. You will be given:\n  - A question Q.\n  - A gold/reference answer (one or more short reference sentences).\n  - A candidate/sample answer produced by a system.\n\nYour job is to **assign integer scores** (1..5) for the following criteria comparing the *candidate* to the *gold/reference*:\n\n1. correctness (1-5): How factually correct is the candidate vs the gold answer? (5 = fully correct, 1 = mostly or fully incorrect).\n2. completeness (1-5): How completely does the candidate cover the key points in the gold answer? (5 = covers all key points; 1 = almost none).\n3. precision (1-5): How concise and focused is the candidate (not too long answer)? (5 = concise & precise; 1 = verbose / many extraneous claims).\n4. coherence (1-5): Is the candidate fluent and well-structured? (5 = natural, coherent; 1 = disfluent or incoherent).\n5. relevance (1-5): Are the statements in the candidate relevant to the question and gold answer (not introducing unrelated claims)? (5 = fully relevant; 1 = mostly irrelevant).\n\nREQUIREMENTS (strict):\n- Output **ONLY** a JSON object EXACTLY of the form:\n  {\"correctness\": <1-5>, \"completeness\": <1-5>, \"precision\": <1-5>, \"coherence\": <1-5>, \"relevance\": <1-5>}\n- No additional text, explanation, or whitespace outside the JSON object.\n\nFEW-SHOT EXAMPLE (this demonstrates the required output; do not include the example in actual responses):\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"No, the capital of Germany is not Paris, the capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":5,\"coherence\":5,\"relevance\":5}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"The capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":3,\"completeness\":2,\"precision\":5,\"coherence\":5,\"relevance\":2}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"If capital stands for the central administrative region of a country, then no, Paris is not the capital of Germany. It's important to note what is the definintion of a 'capital'. However, due to the common popular opinion, a capital of a country is well defined.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":1,\"coherence\":4,\"relevance\":1}\n\nEND OF SYSTEM PROMPT."}, {"role": "user", "content": [{"type": "text", "text": "Question: "}, {"type": "text", "text": "Gold reference 1: \"A Common foxglove has more speckles.\""}, {"type": "text", "text": "Candidate answer: The Common foxglove (Digitalis purpurea) has more speckles on its flowers compared to Lamium maculatum, which has less pronounced speckling."}, {"type": "text", "text": "Please score the candidate exactly with the five integer ratings in JSON as instructed by the system prompt."}]}]}}
{"custom_id": "d5bbf98c0dba11ecb1e81171463288e9_geval", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-mini-2025-04-14", "max_tokens": 200, "temperature": 1, "n": 20, "messages": [{"role": "system", "content": "You are an evaluation assistant. You will be given:\n  - A question Q.\n  - A gold/reference answer (one or more short reference sentences).\n  - A candidate/sample answer produced by a system.\n\nYour job is to **assign integer scores** (1..5) for the following criteria comparing the *candidate* to the *gold/reference*:\n\n1. correctness (1-5): How factually correct is the candidate vs the gold answer? (5 = fully correct, 1 = mostly or fully incorrect).\n2. completeness (1-5): How completely does the candidate cover the key points in the gold answer? (5 = covers all key points; 1 = almost none).\n3. precision (1-5): How concise and focused is the candidate (not too long answer)? (5 = concise & precise; 1 = verbose / many extraneous claims).\n4. coherence (1-5): Is the candidate fluent and well-structured? (5 = natural, coherent; 1 = disfluent or incoherent).\n5. relevance (1-5): Are the statements in the candidate relevant to the question and gold answer (not introducing unrelated claims)? (5 = fully relevant; 1 = mostly irrelevant).\n\nREQUIREMENTS (strict):\n- Output **ONLY** a JSON object EXACTLY of the form:\n  {\"correctness\": <1-5>, \"completeness\": <1-5>, \"precision\": <1-5>, \"coherence\": <1-5>, \"relevance\": <1-5>}\n- No additional text, explanation, or whitespace outside the JSON object.\n\nFEW-SHOT EXAMPLE (this demonstrates the required output; do not include the example in actual responses):\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"No, the capital of Germany is not Paris, the capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":5,\"coherence\":5,\"relevance\":5}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"The capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":3,\"completeness\":2,\"precision\":5,\"coherence\":5,\"relevance\":2}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"If capital stands for the central administrative region of a country, then no, Paris is not the capital of Germany. It's important to note what is the definintion of a 'capital'. However, due to the common popular opinion, a capital of a country is well defined.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":1,\"coherence\":4,\"relevance\":1}\n\nEND OF SYSTEM PROMPT."}, {"role": "user", "content": [{"type": "text", "text": "Question: "}, {"type": "text", "text": "Gold reference 1: \"Cinerary Urn, Etruscan, mid-2nd century BC, terra cotta features someone reclining, and the Gorgon archaic sculpture from the mid 6th century BC, parian marble does not.\""}, {"type": "text", "text": "Candidate answer: The work of art featuring someone reclining is the Cinerary Urn, Etruscan, mid-2nd century BC, terra cotta."}, {"type": "text", "text": "Please score the candidate exactly with the five integer ratings in JSON as instructed by the system prompt."}]}]}}
{"custom_id": "d5be94ee0dba11ecb1e81171463288e9_geval", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-mini-2025-04-14", "max_tokens": 200, "temperature": 1, "n": 20, "messages": [{"role": "system", "content": "You are an evaluation assistant. You will be given:\n  - A question Q.\n  - A gold/reference answer (one or more short reference sentences).\n  - A candidate/sample answer produced by a system.\n\nYour job is to **assign integer scores** (1..5) for the following criteria comparing the *candidate* to the *gold/reference*:\n\n1. correctness (1-5): How factually correct is the candidate vs the gold answer? (5 = fully correct, 1 = mostly or fully incorrect).\n2. completeness (1-5): How completely does the candidate cover the key points in the gold answer? (5 = covers all key points; 1 = almost none).\n3. precision (1-5): How concise and focused is the candidate (not too long answer)? (5 = concise & precise; 1 = verbose / many extraneous claims).\n4. coherence (1-5): Is the candidate fluent and well-structured? (5 = natural, coherent; 1 = disfluent or incoherent).\n5. relevance (1-5): Are the statements in the candidate relevant to the question and gold answer (not introducing unrelated claims)? (5 = fully relevant; 1 = mostly irrelevant).\n\nREQUIREMENTS (strict):\n- Output **ONLY** a JSON object EXACTLY of the form:\n  {\"correctness\": <1-5>, \"completeness\": <1-5>, \"precision\": <1-5>, \"coherence\": <1-5>, \"relevance\": <1-5>}\n- No additional text, explanation, or whitespace outside the JSON object.\n\nFEW-SHOT EXAMPLE (this demonstrates the required output; do not include the example in actual responses):\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"No, the capital of Germany is not Paris, the capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":5,\"coherence\":5,\"relevance\":5}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"The capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":3,\"completeness\":2,\"precision\":5,\"coherence\":5,\"relevance\":2}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"If capital stands for the central administrative region of a country, then no, Paris is not the capital of Germany. It's important to note what is the definintion of a 'capital'. However, due to the common popular opinion, a capital of a country is well defined.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":1,\"coherence\":4,\"relevance\":1}\n\nEND OF SYSTEM PROMPT."}, {"role": "user", "content": [{"type": "text", "text": "Question: "}, {"type": "text", "text": "Gold reference 1: \"No, the two groups of medalists in the girls' halfpipe and girls' slopestyle snowboarding events did not wear the same number of unique jackets on the podium.\""}, {"type": "text", "text": "Candidate answer: Yes, both groups of medalists wore three unique jackets on the podium."}, {"type": "text", "text": "Please score the candidate exactly with the five integer ratings in JSON as instructed by the system prompt."}]}]}}
{"custom_id": "d5bddd1a0dba11ecb1e81171463288e9_geval", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-mini-2025-04-14", "max_tokens": 200, "temperature": 1, "n": 20, "messages": [{"role": "system", "content": "You are an evaluation assistant. You will be given:\n  - A question Q.\n  - A gold/reference answer (one or more short reference sentences).\n  - A candidate/sample answer produced by a system.\n\nYour job is to **assign integer scores** (1..5) for the following criteria comparing the *candidate* to the *gold/reference*:\n\n1. correctness (1-5): How factually correct is the candidate vs the gold answer? (5 = fully correct, 1 = mostly or fully incorrect).\n2. completeness (1-5): How completely does the candidate cover the key points in the gold answer? (5 = covers all key points; 1 = almost none).\n3. precision (1-5): How concise and focused is the candidate (not too long answer)? (5 = concise & precise; 1 = verbose / many extraneous claims).\n4. coherence (1-5): Is the candidate fluent and well-structured? (5 = natural, coherent; 1 = disfluent or incoherent).\n5. relevance (1-5): Are the statements in the candidate relevant to the question and gold answer (not introducing unrelated claims)? (5 = fully relevant; 1 = mostly irrelevant).\n\nREQUIREMENTS (strict):\n- Output **ONLY** a JSON object EXACTLY of the form:\n  {\"correctness\": <1-5>, \"completeness\": <1-5>, \"precision\": <1-5>, \"coherence\": <1-5>, \"relevance\": <1-5>}\n- No additional text, explanation, or whitespace outside the JSON object.\n\nFEW-SHOT EXAMPLE (this demonstrates the required output; do not include the example in actual responses):\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"No, the capital of Germany is not Paris, the capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":5,\"coherence\":5,\"relevance\":5}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"The capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":3,\"completeness\":2,\"precision\":5,\"coherence\":5,\"relevance\":2}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"If capital stands for the central administrative region of a country, then no, Paris is not the capital of Germany. It's important to note what is the definintion of a 'capital'. However, due to the common popular opinion, a capital of a country is well defined.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":1,\"coherence\":4,\"relevance\":1}\n\nEND OF SYSTEM PROMPT."}, {"role": "user", "content": [{"type": "text", "text": "Question: "}, {"type": "text", "text": "Gold reference 1: \"No, the hair on the goat is not longer than the hair on the lemur.\""}, {"type": "text", "text": "Candidate answer: The hair on the goat is generally longer than the hair on the lemur."}, {"type": "text", "text": "Please score the candidate exactly with the five integer ratings in JSON as instructed by the system prompt."}]}]}}
{"custom_id": "d5be6b2c0dba11ecb1e81171463288e9_geval", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-mini-2025-04-14", "max_tokens": 200, "temperature": 1, "n": 20, "messages": [{"role": "system", "content": "You are an evaluation assistant. You will be given:\n  - A question Q.\n  - A gold/reference answer (one or more short reference sentences).\n  - A candidate/sample answer produced by a system.\n\nYour job is to **assign integer scores** (1..5) for the following criteria comparing the *candidate* to the *gold/reference*:\n\n1. correctness (1-5): How factually correct is the candidate vs the gold answer? (5 = fully correct, 1 = mostly or fully incorrect).\n2. completeness (1-5): How completely does the candidate cover the key points in the gold answer? (5 = covers all key points; 1 = almost none).\n3. precision (1-5): How concise and focused is the candidate (not too long answer)? (5 = concise & precise; 1 = verbose / many extraneous claims).\n4. coherence (1-5): Is the candidate fluent and well-structured? (5 = natural, coherent; 1 = disfluent or incoherent).\n5. relevance (1-5): Are the statements in the candidate relevant to the question and gold answer (not introducing unrelated claims)? (5 = fully relevant; 1 = mostly irrelevant).\n\nREQUIREMENTS (strict):\n- Output **ONLY** a JSON object EXACTLY of the form:\n  {\"correctness\": <1-5>, \"completeness\": <1-5>, \"precision\": <1-5>, \"coherence\": <1-5>, \"relevance\": <1-5>}\n- No additional text, explanation, or whitespace outside the JSON object.\n\nFEW-SHOT EXAMPLE (this demonstrates the required output; do not include the example in actual responses):\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"No, the capital of Germany is not Paris, the capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":5,\"coherence\":5,\"relevance\":5}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"The capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":3,\"completeness\":2,\"precision\":5,\"coherence\":5,\"relevance\":2}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"If capital stands for the central administrative region of a country, then no, Paris is not the capital of Germany. It's important to note what is the definintion of a 'capital'. However, due to the common popular opinion, a capital of a country is well defined.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":1,\"coherence\":4,\"relevance\":1}\n\nEND OF SYSTEM PROMPT."}, {"role": "user", "content": [{"type": "text", "text": "Question: "}, {"type": "text", "text": "Gold reference 1: \"No, not all Lamborghinis have a pointed front end.\""}, {"type": "text", "text": "Candidate answer: No, not all Lamborghinis have a pointed front end; some models feature more squared-off designs."}, {"type": "text", "text": "Please score the candidate exactly with the five integer ratings in JSON as instructed by the system prompt."}]}]}}
{"custom_id": "d5bf48440dba11ecb1e81171463288e9_geval", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-mini-2025-04-14", "max_tokens": 200, "temperature": 1, "n": 20, "messages": [{"role": "system", "content": "You are an evaluation assistant. You will be given:\n  - A question Q.\n  - A gold/reference answer (one or more short reference sentences).\n  - A candidate/sample answer produced by a system.\n\nYour job is to **assign integer scores** (1..5) for the following criteria comparing the *candidate* to the *gold/reference*:\n\n1. correctness (1-5): How factually correct is the candidate vs the gold answer? (5 = fully correct, 1 = mostly or fully incorrect).\n2. completeness (1-5): How completely does the candidate cover the key points in the gold answer? (5 = covers all key points; 1 = almost none).\n3. precision (1-5): How concise and focused is the candidate (not too long answer)? (5 = concise & precise; 1 = verbose / many extraneous claims).\n4. coherence (1-5): Is the candidate fluent and well-structured? (5 = natural, coherent; 1 = disfluent or incoherent).\n5. relevance (1-5): Are the statements in the candidate relevant to the question and gold answer (not introducing unrelated claims)? (5 = fully relevant; 1 = mostly irrelevant).\n\nREQUIREMENTS (strict):\n- Output **ONLY** a JSON object EXACTLY of the form:\n  {\"correctness\": <1-5>, \"completeness\": <1-5>, \"precision\": <1-5>, \"coherence\": <1-5>, \"relevance\": <1-5>}\n- No additional text, explanation, or whitespace outside the JSON object.\n\nFEW-SHOT EXAMPLE (this demonstrates the required output; do not include the example in actual responses):\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"No, the capital of Germany is not Paris, the capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":5,\"coherence\":5,\"relevance\":5}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"The capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":3,\"completeness\":2,\"precision\":5,\"coherence\":5,\"relevance\":2}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"If capital stands for the central administrative region of a country, then no, Paris is not the capital of Germany. It's important to note what is the definintion of a 'capital'. However, due to the common popular opinion, a capital of a country is well defined.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":1,\"coherence\":4,\"relevance\":1}\n\nEND OF SYSTEM PROMPT."}, {"role": "user", "content": [{"type": "text", "text": "Question: "}, {"type": "text", "text": "Gold reference 1: \"Yes, someone is playing an instrument in both.\""}, {"type": "text", "text": "Candidate answer: Yes, both paintings feature individuals playing instruments."}, {"type": "text", "text": "Please score the candidate exactly with the five integer ratings in JSON as instructed by the system prompt."}]}]}}
{"custom_id": "d5bbf5720dba11ecb1e81171463288e9_geval", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-mini-2025-04-14", "max_tokens": 200, "temperature": 1, "n": 20, "messages": [{"role": "system", "content": "You are an evaluation assistant. You will be given:\n  - A question Q.\n  - A gold/reference answer (one or more short reference sentences).\n  - A candidate/sample answer produced by a system.\n\nYour job is to **assign integer scores** (1..5) for the following criteria comparing the *candidate* to the *gold/reference*:\n\n1. correctness (1-5): How factually correct is the candidate vs the gold answer? (5 = fully correct, 1 = mostly or fully incorrect).\n2. completeness (1-5): How completely does the candidate cover the key points in the gold answer? (5 = covers all key points; 1 = almost none).\n3. precision (1-5): How concise and focused is the candidate (not too long answer)? (5 = concise & precise; 1 = verbose / many extraneous claims).\n4. coherence (1-5): Is the candidate fluent and well-structured? (5 = natural, coherent; 1 = disfluent or incoherent).\n5. relevance (1-5): Are the statements in the candidate relevant to the question and gold answer (not introducing unrelated claims)? (5 = fully relevant; 1 = mostly irrelevant).\n\nREQUIREMENTS (strict):\n- Output **ONLY** a JSON object EXACTLY of the form:\n  {\"correctness\": <1-5>, \"completeness\": <1-5>, \"precision\": <1-5>, \"coherence\": <1-5>, \"relevance\": <1-5>}\n- No additional text, explanation, or whitespace outside the JSON object.\n\nFEW-SHOT EXAMPLE (this demonstrates the required output; do not include the example in actual responses):\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"No, the capital of Germany is not Paris, the capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":5,\"coherence\":5,\"relevance\":5}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"The capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":3,\"completeness\":2,\"precision\":5,\"coherence\":5,\"relevance\":2}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"If capital stands for the central administrative region of a country, then no, Paris is not the capital of Germany. It's important to note what is the definintion of a 'capital'. However, due to the common popular opinion, a capital of a country is well defined.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":1,\"coherence\":4,\"relevance\":1}\n\nEND OF SYSTEM PROMPT."}, {"role": "user", "content": [{"type": "text", "text": "Question: "}, {"type": "text", "text": "Gold reference 1: \"Both have graffiti on the walls.\""}, {"type": "text", "text": "Candidate answer: Yes, both Sarajevo Bobbahn Olympia and Gro Bosna Sarajevo have graffiti on their walls."}, {"type": "text", "text": "Please score the candidate exactly with the five integer ratings in JSON as instructed by the system prompt."}]}]}}
{"custom_id": "d5bf62020dba11ecb1e81171463288e9_geval", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-mini-2025-04-14", "max_tokens": 200, "temperature": 1, "n": 20, "messages": [{"role": "system", "content": "You are an evaluation assistant. You will be given:\n  - A question Q.\n  - A gold/reference answer (one or more short reference sentences).\n  - A candidate/sample answer produced by a system.\n\nYour job is to **assign integer scores** (1..5) for the following criteria comparing the *candidate* to the *gold/reference*:\n\n1. correctness (1-5): How factually correct is the candidate vs the gold answer? (5 = fully correct, 1 = mostly or fully incorrect).\n2. completeness (1-5): How completely does the candidate cover the key points in the gold answer? (5 = covers all key points; 1 = almost none).\n3. precision (1-5): How concise and focused is the candidate (not too long answer)? (5 = concise & precise; 1 = verbose / many extraneous claims).\n4. coherence (1-5): Is the candidate fluent and well-structured? (5 = natural, coherent; 1 = disfluent or incoherent).\n5. relevance (1-5): Are the statements in the candidate relevant to the question and gold answer (not introducing unrelated claims)? (5 = fully relevant; 1 = mostly irrelevant).\n\nREQUIREMENTS (strict):\n- Output **ONLY** a JSON object EXACTLY of the form:\n  {\"correctness\": <1-5>, \"completeness\": <1-5>, \"precision\": <1-5>, \"coherence\": <1-5>, \"relevance\": <1-5>}\n- No additional text, explanation, or whitespace outside the JSON object.\n\nFEW-SHOT EXAMPLE (this demonstrates the required output; do not include the example in actual responses):\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"No, the capital of Germany is not Paris, the capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":5,\"coherence\":5,\"relevance\":5}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"The capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":3,\"completeness\":2,\"precision\":5,\"coherence\":5,\"relevance\":2}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"If capital stands for the central administrative region of a country, then no, Paris is not the capital of Germany. It's important to note what is the definintion of a 'capital'. However, due to the common popular opinion, a capital of a country is well defined.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":1,\"coherence\":4,\"relevance\":1}\n\nEND OF SYSTEM PROMPT."}, {"role": "user", "content": [{"type": "text", "text": "Question: "}, {"type": "text", "text": "Gold reference 1: \"Cattle is present in both paintings.\""}, {"type": "text", "text": "Candidate answer: The paintings feature cattle as the type of animal present."}, {"type": "text", "text": "Please score the candidate exactly with the five integer ratings in JSON as instructed by the system prompt."}]}]}}
{"custom_id": "d5be439a0dba11ecb1e81171463288e9_geval", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-mini-2025-04-14", "max_tokens": 200, "temperature": 1, "n": 20, "messages": [{"role": "system", "content": "You are an evaluation assistant. You will be given:\n  - A question Q.\n  - A gold/reference answer (one or more short reference sentences).\n  - A candidate/sample answer produced by a system.\n\nYour job is to **assign integer scores** (1..5) for the following criteria comparing the *candidate* to the *gold/reference*:\n\n1. correctness (1-5): How factually correct is the candidate vs the gold answer? (5 = fully correct, 1 = mostly or fully incorrect).\n2. completeness (1-5): How completely does the candidate cover the key points in the gold answer? (5 = covers all key points; 1 = almost none).\n3. precision (1-5): How concise and focused is the candidate (not too long answer)? (5 = concise & precise; 1 = verbose / many extraneous claims).\n4. coherence (1-5): Is the candidate fluent and well-structured? (5 = natural, coherent; 1 = disfluent or incoherent).\n5. relevance (1-5): Are the statements in the candidate relevant to the question and gold answer (not introducing unrelated claims)? (5 = fully relevant; 1 = mostly irrelevant).\n\nREQUIREMENTS (strict):\n- Output **ONLY** a JSON object EXACTLY of the form:\n  {\"correctness\": <1-5>, \"completeness\": <1-5>, \"precision\": <1-5>, \"coherence\": <1-5>, \"relevance\": <1-5>}\n- No additional text, explanation, or whitespace outside the JSON object.\n\nFEW-SHOT EXAMPLE (this demonstrates the required output; do not include the example in actual responses):\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"No, the capital of Germany is not Paris, the capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":5,\"coherence\":5,\"relevance\":5}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"The capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":3,\"completeness\":2,\"precision\":5,\"coherence\":5,\"relevance\":2}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"If capital stands for the central administrative region of a country, then no, Paris is not the capital of Germany. It's important to note what is the definintion of a 'capital'. However, due to the common popular opinion, a capital of a country is well defined.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":1,\"coherence\":4,\"relevance\":1}\n\nEND OF SYSTEM PROMPT."}, {"role": "user", "content": [{"type": "text", "text": "Question: "}, {"type": "text", "text": "Gold reference 1: \"1 man is in the canoe seen in Cornelius Krieghoff's \"The Narrows, Lake St. Charles\".\""}, {"type": "text", "text": "Candidate answer: There are two men in the canoe seen in Cornelius Krieghoff's \"The Narrows, Lake St. Charles.\""}, {"type": "text", "text": "Please score the candidate exactly with the five integer ratings in JSON as instructed by the system prompt."}]}]}}
{"custom_id": "d5be054c0dba11ecb1e81171463288e9_geval", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-mini-2025-04-14", "max_tokens": 200, "temperature": 1, "n": 20, "messages": [{"role": "system", "content": "You are an evaluation assistant. You will be given:\n  - A question Q.\n  - A gold/reference answer (one or more short reference sentences).\n  - A candidate/sample answer produced by a system.\n\nYour job is to **assign integer scores** (1..5) for the following criteria comparing the *candidate* to the *gold/reference*:\n\n1. correctness (1-5): How factually correct is the candidate vs the gold answer? (5 = fully correct, 1 = mostly or fully incorrect).\n2. completeness (1-5): How completely does the candidate cover the key points in the gold answer? (5 = covers all key points; 1 = almost none).\n3. precision (1-5): How concise and focused is the candidate (not too long answer)? (5 = concise & precise; 1 = verbose / many extraneous claims).\n4. coherence (1-5): Is the candidate fluent and well-structured? (5 = natural, coherent; 1 = disfluent or incoherent).\n5. relevance (1-5): Are the statements in the candidate relevant to the question and gold answer (not introducing unrelated claims)? (5 = fully relevant; 1 = mostly irrelevant).\n\nREQUIREMENTS (strict):\n- Output **ONLY** a JSON object EXACTLY of the form:\n  {\"correctness\": <1-5>, \"completeness\": <1-5>, \"precision\": <1-5>, \"coherence\": <1-5>, \"relevance\": <1-5>}\n- No additional text, explanation, or whitespace outside the JSON object.\n\nFEW-SHOT EXAMPLE (this demonstrates the required output; do not include the example in actual responses):\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"No, the capital of Germany is not Paris, the capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":5,\"coherence\":5,\"relevance\":5}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"The capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":3,\"completeness\":2,\"precision\":5,\"coherence\":5,\"relevance\":2}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"If capital stands for the central administrative region of a country, then no, Paris is not the capital of Germany. It's important to note what is the definintion of a 'capital'. However, due to the common popular opinion, a capital of a country is well defined.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":1,\"coherence\":4,\"relevance\":1}\n\nEND OF SYSTEM PROMPT."}, {"role": "user", "content": [{"type": "text", "text": "Question: "}, {"type": "text", "text": "Gold reference 1: \"Anthias woodsi appears to have spiky needles on the top of its upper body.\""}, {"type": "text", "text": "Candidate answer: The fish with spiky needles on the top of their upper body is Anthias woodsi."}, {"type": "text", "text": "Please score the candidate exactly with the five integer ratings in JSON as instructed by the system prompt."}]}]}}
{"custom_id": "d5bee35e0dba11ecb1e81171463288e9_geval", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-mini-2025-04-14", "max_tokens": 200, "temperature": 1, "n": 20, "messages": [{"role": "system", "content": "You are an evaluation assistant. You will be given:\n  - A question Q.\n  - A gold/reference answer (one or more short reference sentences).\n  - A candidate/sample answer produced by a system.\n\nYour job is to **assign integer scores** (1..5) for the following criteria comparing the *candidate* to the *gold/reference*:\n\n1. correctness (1-5): How factually correct is the candidate vs the gold answer? (5 = fully correct, 1 = mostly or fully incorrect).\n2. completeness (1-5): How completely does the candidate cover the key points in the gold answer? (5 = covers all key points; 1 = almost none).\n3. precision (1-5): How concise and focused is the candidate (not too long answer)? (5 = concise & precise; 1 = verbose / many extraneous claims).\n4. coherence (1-5): Is the candidate fluent and well-structured? (5 = natural, coherent; 1 = disfluent or incoherent).\n5. relevance (1-5): Are the statements in the candidate relevant to the question and gold answer (not introducing unrelated claims)? (5 = fully relevant; 1 = mostly irrelevant).\n\nREQUIREMENTS (strict):\n- Output **ONLY** a JSON object EXACTLY of the form:\n  {\"correctness\": <1-5>, \"completeness\": <1-5>, \"precision\": <1-5>, \"coherence\": <1-5>, \"relevance\": <1-5>}\n- No additional text, explanation, or whitespace outside the JSON object.\n\nFEW-SHOT EXAMPLE (this demonstrates the required output; do not include the example in actual responses):\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"No, the capital of Germany is not Paris, the capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":5,\"coherence\":5,\"relevance\":5}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"The capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":3,\"completeness\":2,\"precision\":5,\"coherence\":5,\"relevance\":2}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"If capital stands for the central administrative region of a country, then no, Paris is not the capital of Germany. It's important to note what is the definintion of a 'capital'. However, due to the common popular opinion, a capital of a country is well defined.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":1,\"coherence\":4,\"relevance\":1}\n\nEND OF SYSTEM PROMPT."}, {"role": "user", "content": [{"type": "text", "text": "Question: "}, {"type": "text", "text": "Gold reference 1: \"The hat in the Blue Lady painting by Pierre Auguste Renoir does not cover all of her hair.\""}, {"type": "text", "text": "Candidate answer: No, the hat in the Blue Lady painting does not cover all of her hair."}, {"type": "text", "text": "Please score the candidate exactly with the five integer ratings in JSON as instructed by the system prompt."}]}]}}
{"custom_id": "d5bcbac00dba11ecb1e81171463288e9_geval", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-mini-2025-04-14", "max_tokens": 200, "temperature": 1, "n": 20, "messages": [{"role": "system", "content": "You are an evaluation assistant. You will be given:\n  - A question Q.\n  - A gold/reference answer (one or more short reference sentences).\n  - A candidate/sample answer produced by a system.\n\nYour job is to **assign integer scores** (1..5) for the following criteria comparing the *candidate* to the *gold/reference*:\n\n1. correctness (1-5): How factually correct is the candidate vs the gold answer? (5 = fully correct, 1 = mostly or fully incorrect).\n2. completeness (1-5): How completely does the candidate cover the key points in the gold answer? (5 = covers all key points; 1 = almost none).\n3. precision (1-5): How concise and focused is the candidate (not too long answer)? (5 = concise & precise; 1 = verbose / many extraneous claims).\n4. coherence (1-5): Is the candidate fluent and well-structured? (5 = natural, coherent; 1 = disfluent or incoherent).\n5. relevance (1-5): Are the statements in the candidate relevant to the question and gold answer (not introducing unrelated claims)? (5 = fully relevant; 1 = mostly irrelevant).\n\nREQUIREMENTS (strict):\n- Output **ONLY** a JSON object EXACTLY of the form:\n  {\"correctness\": <1-5>, \"completeness\": <1-5>, \"precision\": <1-5>, \"coherence\": <1-5>, \"relevance\": <1-5>}\n- No additional text, explanation, or whitespace outside the JSON object.\n\nFEW-SHOT EXAMPLE (this demonstrates the required output; do not include the example in actual responses):\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"No, the capital of Germany is not Paris, the capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":5,\"coherence\":5,\"relevance\":5}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"The capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":3,\"completeness\":2,\"precision\":5,\"coherence\":5,\"relevance\":2}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"If capital stands for the central administrative region of a country, then no, Paris is not the capital of Germany. It's important to note what is the definintion of a 'capital'. However, due to the common popular opinion, a capital of a country is well defined.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":1,\"coherence\":4,\"relevance\":1}\n\nEND OF SYSTEM PROMPT."}, {"role": "user", "content": [{"type": "text", "text": "Question: "}, {"type": "text", "text": "Gold reference 1: \"No, Drew Barrymore's star on the Hollywood Walk of Fame does not have more gold on it.\""}, {"type": "text", "text": "Candidate answer: Drew Barrymore's star has more gold coloring than Jane Mansfield's star."}, {"type": "text", "text": "Please score the candidate exactly with the five integer ratings in JSON as instructed by the system prompt."}]}]}}
{"custom_id": "d5be714e0dba11ecb1e81171463288e9_geval", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-mini-2025-04-14", "max_tokens": 200, "temperature": 1, "n": 20, "messages": [{"role": "system", "content": "You are an evaluation assistant. You will be given:\n  - A question Q.\n  - A gold/reference answer (one or more short reference sentences).\n  - A candidate/sample answer produced by a system.\n\nYour job is to **assign integer scores** (1..5) for the following criteria comparing the *candidate* to the *gold/reference*:\n\n1. correctness (1-5): How factually correct is the candidate vs the gold answer? (5 = fully correct, 1 = mostly or fully incorrect).\n2. completeness (1-5): How completely does the candidate cover the key points in the gold answer? (5 = covers all key points; 1 = almost none).\n3. precision (1-5): How concise and focused is the candidate (not too long answer)? (5 = concise & precise; 1 = verbose / many extraneous claims).\n4. coherence (1-5): Is the candidate fluent and well-structured? (5 = natural, coherent; 1 = disfluent or incoherent).\n5. relevance (1-5): Are the statements in the candidate relevant to the question and gold answer (not introducing unrelated claims)? (5 = fully relevant; 1 = mostly irrelevant).\n\nREQUIREMENTS (strict):\n- Output **ONLY** a JSON object EXACTLY of the form:\n  {\"correctness\": <1-5>, \"completeness\": <1-5>, \"precision\": <1-5>, \"coherence\": <1-5>, \"relevance\": <1-5>}\n- No additional text, explanation, or whitespace outside the JSON object.\n\nFEW-SHOT EXAMPLE (this demonstrates the required output; do not include the example in actual responses):\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"No, the capital of Germany is not Paris, the capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":5,\"coherence\":5,\"relevance\":5}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"The capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":3,\"completeness\":2,\"precision\":5,\"coherence\":5,\"relevance\":2}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"If capital stands for the central administrative region of a country, then no, Paris is not the capital of Germany. It's important to note what is the definintion of a 'capital'. However, due to the common popular opinion, a capital of a country is well defined.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":1,\"coherence\":4,\"relevance\":1}\n\nEND OF SYSTEM PROMPT."}, {"role": "user", "content": [{"type": "text", "text": "Question: "}, {"type": "text", "text": "Gold reference 1: \"The trashcan near the fence was taller than the fence.\""}, {"type": "text", "text": "Candidate answer: The height of the fence surrounding the 2016 Olympic cauldron in Beijing is not specified, nor is the height of the trashcan near the fence, so a comparison cannot be made."}, {"type": "text", "text": "Please score the candidate exactly with the five integer ratings in JSON as instructed by the system prompt."}]}]}}
{"custom_id": "d5bed0f80dba11ecb1e81171463288e9_geval", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-mini-2025-04-14", "max_tokens": 200, "temperature": 1, "n": 20, "messages": [{"role": "system", "content": "You are an evaluation assistant. You will be given:\n  - A question Q.\n  - A gold/reference answer (one or more short reference sentences).\n  - A candidate/sample answer produced by a system.\n\nYour job is to **assign integer scores** (1..5) for the following criteria comparing the *candidate* to the *gold/reference*:\n\n1. correctness (1-5): How factually correct is the candidate vs the gold answer? (5 = fully correct, 1 = mostly or fully incorrect).\n2. completeness (1-5): How completely does the candidate cover the key points in the gold answer? (5 = covers all key points; 1 = almost none).\n3. precision (1-5): How concise and focused is the candidate (not too long answer)? (5 = concise & precise; 1 = verbose / many extraneous claims).\n4. coherence (1-5): Is the candidate fluent and well-structured? (5 = natural, coherent; 1 = disfluent or incoherent).\n5. relevance (1-5): Are the statements in the candidate relevant to the question and gold answer (not introducing unrelated claims)? (5 = fully relevant; 1 = mostly irrelevant).\n\nREQUIREMENTS (strict):\n- Output **ONLY** a JSON object EXACTLY of the form:\n  {\"correctness\": <1-5>, \"completeness\": <1-5>, \"precision\": <1-5>, \"coherence\": <1-5>, \"relevance\": <1-5>}\n- No additional text, explanation, or whitespace outside the JSON object.\n\nFEW-SHOT EXAMPLE (this demonstrates the required output; do not include the example in actual responses):\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"No, the capital of Germany is not Paris, the capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":5,\"coherence\":5,\"relevance\":5}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"The capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":3,\"completeness\":2,\"precision\":5,\"coherence\":5,\"relevance\":2}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"If capital stands for the central administrative region of a country, then no, Paris is not the capital of Germany. It's important to note what is the definintion of a 'capital'. However, due to the common popular opinion, a capital of a country is well defined.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":1,\"coherence\":4,\"relevance\":1}\n\nEND OF SYSTEM PROMPT."}, {"role": "user", "content": [{"type": "text", "text": "Question: "}, {"type": "text", "text": "Gold reference 1: \"There are three columns of buttons found on the vest.\""}, {"type": "text", "text": "Candidate answer: The vest of Galician Traditional Clothes features three columns of buttons."}, {"type": "text", "text": "Please score the candidate exactly with the five integer ratings in JSON as instructed by the system prompt."}]}]}}
{"custom_id": "d5bf45e20dba11ecb1e81171463288e9_geval", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-mini-2025-04-14", "max_tokens": 200, "temperature": 1, "n": 20, "messages": [{"role": "system", "content": "You are an evaluation assistant. You will be given:\n  - A question Q.\n  - A gold/reference answer (one or more short reference sentences).\n  - A candidate/sample answer produced by a system.\n\nYour job is to **assign integer scores** (1..5) for the following criteria comparing the *candidate* to the *gold/reference*:\n\n1. correctness (1-5): How factually correct is the candidate vs the gold answer? (5 = fully correct, 1 = mostly or fully incorrect).\n2. completeness (1-5): How completely does the candidate cover the key points in the gold answer? (5 = covers all key points; 1 = almost none).\n3. precision (1-5): How concise and focused is the candidate (not too long answer)? (5 = concise & precise; 1 = verbose / many extraneous claims).\n4. coherence (1-5): Is the candidate fluent and well-structured? (5 = natural, coherent; 1 = disfluent or incoherent).\n5. relevance (1-5): Are the statements in the candidate relevant to the question and gold answer (not introducing unrelated claims)? (5 = fully relevant; 1 = mostly irrelevant).\n\nREQUIREMENTS (strict):\n- Output **ONLY** a JSON object EXACTLY of the form:\n  {\"correctness\": <1-5>, \"completeness\": <1-5>, \"precision\": <1-5>, \"coherence\": <1-5>, \"relevance\": <1-5>}\n- No additional text, explanation, or whitespace outside the JSON object.\n\nFEW-SHOT EXAMPLE (this demonstrates the required output; do not include the example in actual responses):\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"No, the capital of Germany is not Paris, the capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":5,\"coherence\":5,\"relevance\":5}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"The capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":3,\"completeness\":2,\"precision\":5,\"coherence\":5,\"relevance\":2}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"If capital stands for the central administrative region of a country, then no, Paris is not the capital of Germany. It's important to note what is the definintion of a 'capital'. However, due to the common popular opinion, a capital of a country is well defined.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":1,\"coherence\":4,\"relevance\":1}\n\nEND OF SYSTEM PROMPT."}, {"role": "user", "content": [{"type": "text", "text": "Question: "}, {"type": "text", "text": "Gold reference 1: \"Yes, there are parts of the cliff in water in Claude Monet's paintings \"The Cliffs at Etretat\" and \"The Cliff of Aval, Etrétat.\""}, {"type": "text", "text": "Candidate answer: Yes, both paintings depict cliffs that are partially in the water."}, {"type": "text", "text": "Please score the candidate exactly with the five integer ratings in JSON as instructed by the system prompt."}]}]}}
{"custom_id": "d5bc819a0dba11ecb1e81171463288e9_geval", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-mini-2025-04-14", "max_tokens": 200, "temperature": 1, "n": 20, "messages": [{"role": "system", "content": "You are an evaluation assistant. You will be given:\n  - A question Q.\n  - A gold/reference answer (one or more short reference sentences).\n  - A candidate/sample answer produced by a system.\n\nYour job is to **assign integer scores** (1..5) for the following criteria comparing the *candidate* to the *gold/reference*:\n\n1. correctness (1-5): How factually correct is the candidate vs the gold answer? (5 = fully correct, 1 = mostly or fully incorrect).\n2. completeness (1-5): How completely does the candidate cover the key points in the gold answer? (5 = covers all key points; 1 = almost none).\n3. precision (1-5): How concise and focused is the candidate (not too long answer)? (5 = concise & precise; 1 = verbose / many extraneous claims).\n4. coherence (1-5): Is the candidate fluent and well-structured? (5 = natural, coherent; 1 = disfluent or incoherent).\n5. relevance (1-5): Are the statements in the candidate relevant to the question and gold answer (not introducing unrelated claims)? (5 = fully relevant; 1 = mostly irrelevant).\n\nREQUIREMENTS (strict):\n- Output **ONLY** a JSON object EXACTLY of the form:\n  {\"correctness\": <1-5>, \"completeness\": <1-5>, \"precision\": <1-5>, \"coherence\": <1-5>, \"relevance\": <1-5>}\n- No additional text, explanation, or whitespace outside the JSON object.\n\nFEW-SHOT EXAMPLE (this demonstrates the required output; do not include the example in actual responses):\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"No, the capital of Germany is not Paris, the capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":5,\"coherence\":5,\"relevance\":5}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"The capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":3,\"completeness\":2,\"precision\":5,\"coherence\":5,\"relevance\":2}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"If capital stands for the central administrative region of a country, then no, Paris is not the capital of Germany. It's important to note what is the definintion of a 'capital'. However, due to the common popular opinion, a capital of a country is well defined.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":1,\"coherence\":4,\"relevance\":1}\n\nEND OF SYSTEM PROMPT."}, {"role": "user", "content": [{"type": "text", "text": "Question: "}, {"type": "text", "text": "Gold reference 1: \"The Rainbow Bridge in Tokyo is lit up with different colours each night.\""}, {"type": "text", "text": "Candidate answer: The Rainbow Bridge in Tokyo is illuminated in three different colors—red, white, and green—every night, so it does not always light up the same colors."}, {"type": "text", "text": "Please score the candidate exactly with the five integer ratings in JSON as instructed by the system prompt."}]}]}}
{"custom_id": "d5bbe1680dba11ecb1e81171463288e9_geval", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-mini-2025-04-14", "max_tokens": 200, "temperature": 1, "n": 20, "messages": [{"role": "system", "content": "You are an evaluation assistant. You will be given:\n  - A question Q.\n  - A gold/reference answer (one or more short reference sentences).\n  - A candidate/sample answer produced by a system.\n\nYour job is to **assign integer scores** (1..5) for the following criteria comparing the *candidate* to the *gold/reference*:\n\n1. correctness (1-5): How factually correct is the candidate vs the gold answer? (5 = fully correct, 1 = mostly or fully incorrect).\n2. completeness (1-5): How completely does the candidate cover the key points in the gold answer? (5 = covers all key points; 1 = almost none).\n3. precision (1-5): How concise and focused is the candidate (not too long answer)? (5 = concise & precise; 1 = verbose / many extraneous claims).\n4. coherence (1-5): Is the candidate fluent and well-structured? (5 = natural, coherent; 1 = disfluent or incoherent).\n5. relevance (1-5): Are the statements in the candidate relevant to the question and gold answer (not introducing unrelated claims)? (5 = fully relevant; 1 = mostly irrelevant).\n\nREQUIREMENTS (strict):\n- Output **ONLY** a JSON object EXACTLY of the form:\n  {\"correctness\": <1-5>, \"completeness\": <1-5>, \"precision\": <1-5>, \"coherence\": <1-5>, \"relevance\": <1-5>}\n- No additional text, explanation, or whitespace outside the JSON object.\n\nFEW-SHOT EXAMPLE (this demonstrates the required output; do not include the example in actual responses):\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"No, the capital of Germany is not Paris, the capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":5,\"coherence\":5,\"relevance\":5}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"The capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":3,\"completeness\":2,\"precision\":5,\"coherence\":5,\"relevance\":2}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"If capital stands for the central administrative region of a country, then no, Paris is not the capital of Germany. It's important to note what is the definintion of a 'capital'. However, due to the common popular opinion, a capital of a country is well defined.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":1,\"coherence\":4,\"relevance\":1}\n\nEND OF SYSTEM PROMPT."}, {"role": "user", "content": [{"type": "text", "text": "Question: "}, {"type": "text", "text": "Gold reference 1: \"It is day time.\""}, {"type": "text", "text": "Candidate answer: In the painting \"By the river\" by Henri Biva, it is daytime."}, {"type": "text", "text": "Please score the candidate exactly with the five integer ratings in JSON as instructed by the system prompt."}]}]}}
{"custom_id": "d5bda07a0dba11ecb1e81171463288e9_geval", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-mini-2025-04-14", "max_tokens": 200, "temperature": 1, "n": 20, "messages": [{"role": "system", "content": "You are an evaluation assistant. You will be given:\n  - A question Q.\n  - A gold/reference answer (one or more short reference sentences).\n  - A candidate/sample answer produced by a system.\n\nYour job is to **assign integer scores** (1..5) for the following criteria comparing the *candidate* to the *gold/reference*:\n\n1. correctness (1-5): How factually correct is the candidate vs the gold answer? (5 = fully correct, 1 = mostly or fully incorrect).\n2. completeness (1-5): How completely does the candidate cover the key points in the gold answer? (5 = covers all key points; 1 = almost none).\n3. precision (1-5): How concise and focused is the candidate (not too long answer)? (5 = concise & precise; 1 = verbose / many extraneous claims).\n4. coherence (1-5): Is the candidate fluent and well-structured? (5 = natural, coherent; 1 = disfluent or incoherent).\n5. relevance (1-5): Are the statements in the candidate relevant to the question and gold answer (not introducing unrelated claims)? (5 = fully relevant; 1 = mostly irrelevant).\n\nREQUIREMENTS (strict):\n- Output **ONLY** a JSON object EXACTLY of the form:\n  {\"correctness\": <1-5>, \"completeness\": <1-5>, \"precision\": <1-5>, \"coherence\": <1-5>, \"relevance\": <1-5>}\n- No additional text, explanation, or whitespace outside the JSON object.\n\nFEW-SHOT EXAMPLE (this demonstrates the required output; do not include the example in actual responses):\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"No, the capital of Germany is not Paris, the capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":5,\"coherence\":5,\"relevance\":5}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"The capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":3,\"completeness\":2,\"precision\":5,\"coherence\":5,\"relevance\":2}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"If capital stands for the central administrative region of a country, then no, Paris is not the capital of Germany. It's important to note what is the definintion of a 'capital'. However, due to the common popular opinion, a capital of a country is well defined.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":1,\"coherence\":4,\"relevance\":1}\n\nEND OF SYSTEM PROMPT."}, {"role": "user", "content": [{"type": "text", "text": "Question: "}, {"type": "text", "text": "Gold reference 1: \"The Pipe organ San Giovanni in Laterano is surrounded by more angels than the Ponce Cathedral pipe organ in Ponce, Puerto Rico.\""}, {"type": "text", "text": "Candidate answer: The pipe organ at San Giovanni in Laterano is surrounded by more angels than the Ponce Cathedral pipe organ."}, {"type": "text", "text": "Please score the candidate exactly with the five integer ratings in JSON as instructed by the system prompt."}]}]}}
{"custom_id": "d5bf22380dba11ecb1e81171463288e9_geval", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-mini-2025-04-14", "max_tokens": 200, "temperature": 1, "n": 20, "messages": [{"role": "system", "content": "You are an evaluation assistant. You will be given:\n  - A question Q.\n  - A gold/reference answer (one or more short reference sentences).\n  - A candidate/sample answer produced by a system.\n\nYour job is to **assign integer scores** (1..5) for the following criteria comparing the *candidate* to the *gold/reference*:\n\n1. correctness (1-5): How factually correct is the candidate vs the gold answer? (5 = fully correct, 1 = mostly or fully incorrect).\n2. completeness (1-5): How completely does the candidate cover the key points in the gold answer? (5 = covers all key points; 1 = almost none).\n3. precision (1-5): How concise and focused is the candidate (not too long answer)? (5 = concise & precise; 1 = verbose / many extraneous claims).\n4. coherence (1-5): Is the candidate fluent and well-structured? (5 = natural, coherent; 1 = disfluent or incoherent).\n5. relevance (1-5): Are the statements in the candidate relevant to the question and gold answer (not introducing unrelated claims)? (5 = fully relevant; 1 = mostly irrelevant).\n\nREQUIREMENTS (strict):\n- Output **ONLY** a JSON object EXACTLY of the form:\n  {\"correctness\": <1-5>, \"completeness\": <1-5>, \"precision\": <1-5>, \"coherence\": <1-5>, \"relevance\": <1-5>}\n- No additional text, explanation, or whitespace outside the JSON object.\n\nFEW-SHOT EXAMPLE (this demonstrates the required output; do not include the example in actual responses):\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"No, the capital of Germany is not Paris, the capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":5,\"coherence\":5,\"relevance\":5}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"The capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":3,\"completeness\":2,\"precision\":5,\"coherence\":5,\"relevance\":2}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"If capital stands for the central administrative region of a country, then no, Paris is not the capital of Germany. It's important to note what is the definintion of a 'capital'. However, due to the common popular opinion, a capital of a country is well defined.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":1,\"coherence\":4,\"relevance\":1}\n\nEND OF SYSTEM PROMPT."}, {"role": "user", "content": [{"type": "text", "text": "Question: "}, {"type": "text", "text": "Gold reference 1: \"The lower half of the Beijing Olympic torch from 2008 is red.\""}, {"type": "text", "text": "Candidate answer: The lower half of the Beijing Olympic torch from 2008 is red."}, {"type": "text", "text": "Please score the candidate exactly with the five integer ratings in JSON as instructed by the system prompt."}]}]}}
{"custom_id": "d5bd08720dba11ecb1e81171463288e9_geval", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-mini-2025-04-14", "max_tokens": 200, "temperature": 1, "n": 20, "messages": [{"role": "system", "content": "You are an evaluation assistant. You will be given:\n  - A question Q.\n  - A gold/reference answer (one or more short reference sentences).\n  - A candidate/sample answer produced by a system.\n\nYour job is to **assign integer scores** (1..5) for the following criteria comparing the *candidate* to the *gold/reference*:\n\n1. correctness (1-5): How factually correct is the candidate vs the gold answer? (5 = fully correct, 1 = mostly or fully incorrect).\n2. completeness (1-5): How completely does the candidate cover the key points in the gold answer? (5 = covers all key points; 1 = almost none).\n3. precision (1-5): How concise and focused is the candidate (not too long answer)? (5 = concise & precise; 1 = verbose / many extraneous claims).\n4. coherence (1-5): Is the candidate fluent and well-structured? (5 = natural, coherent; 1 = disfluent or incoherent).\n5. relevance (1-5): Are the statements in the candidate relevant to the question and gold answer (not introducing unrelated claims)? (5 = fully relevant; 1 = mostly irrelevant).\n\nREQUIREMENTS (strict):\n- Output **ONLY** a JSON object EXACTLY of the form:\n  {\"correctness\": <1-5>, \"completeness\": <1-5>, \"precision\": <1-5>, \"coherence\": <1-5>, \"relevance\": <1-5>}\n- No additional text, explanation, or whitespace outside the JSON object.\n\nFEW-SHOT EXAMPLE (this demonstrates the required output; do not include the example in actual responses):\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"No, the capital of Germany is not Paris, the capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":5,\"coherence\":5,\"relevance\":5}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"The capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":3,\"completeness\":2,\"precision\":5,\"coherence\":5,\"relevance\":2}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"If capital stands for the central administrative region of a country, then no, Paris is not the capital of Germany. It's important to note what is the definintion of a 'capital'. However, due to the common popular opinion, a capital of a country is well defined.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":1,\"coherence\":4,\"relevance\":1}\n\nEND OF SYSTEM PROMPT."}, {"role": "user", "content": [{"type": "text", "text": "Question: "}, {"type": "text", "text": "Gold reference 1: \"The tallest type of tree found in front of the Museum of TV and Radio is the palm tree.\""}, {"type": "text", "text": "Candidate answer: The tallest type of tree found in front of the Museum of TV and Radio is not specified in the provided sources."}, {"type": "text", "text": "Please score the candidate exactly with the five integer ratings in JSON as instructed by the system prompt."}]}]}}
{"custom_id": "d5be16180dba11ecb1e81171463288e9_geval", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-mini-2025-04-14", "max_tokens": 200, "temperature": 1, "n": 20, "messages": [{"role": "system", "content": "You are an evaluation assistant. You will be given:\n  - A question Q.\n  - A gold/reference answer (one or more short reference sentences).\n  - A candidate/sample answer produced by a system.\n\nYour job is to **assign integer scores** (1..5) for the following criteria comparing the *candidate* to the *gold/reference*:\n\n1. correctness (1-5): How factually correct is the candidate vs the gold answer? (5 = fully correct, 1 = mostly or fully incorrect).\n2. completeness (1-5): How completely does the candidate cover the key points in the gold answer? (5 = covers all key points; 1 = almost none).\n3. precision (1-5): How concise and focused is the candidate (not too long answer)? (5 = concise & precise; 1 = verbose / many extraneous claims).\n4. coherence (1-5): Is the candidate fluent and well-structured? (5 = natural, coherent; 1 = disfluent or incoherent).\n5. relevance (1-5): Are the statements in the candidate relevant to the question and gold answer (not introducing unrelated claims)? (5 = fully relevant; 1 = mostly irrelevant).\n\nREQUIREMENTS (strict):\n- Output **ONLY** a JSON object EXACTLY of the form:\n  {\"correctness\": <1-5>, \"completeness\": <1-5>, \"precision\": <1-5>, \"coherence\": <1-5>, \"relevance\": <1-5>}\n- No additional text, explanation, or whitespace outside the JSON object.\n\nFEW-SHOT EXAMPLE (this demonstrates the required output; do not include the example in actual responses):\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"No, the capital of Germany is not Paris, the capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":5,\"coherence\":5,\"relevance\":5}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"The capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":3,\"completeness\":2,\"precision\":5,\"coherence\":5,\"relevance\":2}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"If capital stands for the central administrative region of a country, then no, Paris is not the capital of Germany. It's important to note what is the definintion of a 'capital'. However, due to the common popular opinion, a capital of a country is well defined.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":1,\"coherence\":4,\"relevance\":1}\n\nEND OF SYSTEM PROMPT."}, {"role": "user", "content": [{"type": "text", "text": "Question: "}, {"type": "text", "text": "Gold reference 1: \"The main subject of Chief Pretty Eagle-A Crow Chief is wearing a feather.\""}, {"type": "text", "text": "Candidate answer: Chief Pretty Eagle is wearing a traditional feathered headdress."}, {"type": "text", "text": "Please score the candidate exactly with the five integer ratings in JSON as instructed by the system prompt."}]}]}}
{"custom_id": "d5bee7fa0dba11ecb1e81171463288e9_geval", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-mini-2025-04-14", "max_tokens": 200, "temperature": 1, "n": 20, "messages": [{"role": "system", "content": "You are an evaluation assistant. You will be given:\n  - A question Q.\n  - A gold/reference answer (one or more short reference sentences).\n  - A candidate/sample answer produced by a system.\n\nYour job is to **assign integer scores** (1..5) for the following criteria comparing the *candidate* to the *gold/reference*:\n\n1. correctness (1-5): How factually correct is the candidate vs the gold answer? (5 = fully correct, 1 = mostly or fully incorrect).\n2. completeness (1-5): How completely does the candidate cover the key points in the gold answer? (5 = covers all key points; 1 = almost none).\n3. precision (1-5): How concise and focused is the candidate (not too long answer)? (5 = concise & precise; 1 = verbose / many extraneous claims).\n4. coherence (1-5): Is the candidate fluent and well-structured? (5 = natural, coherent; 1 = disfluent or incoherent).\n5. relevance (1-5): Are the statements in the candidate relevant to the question and gold answer (not introducing unrelated claims)? (5 = fully relevant; 1 = mostly irrelevant).\n\nREQUIREMENTS (strict):\n- Output **ONLY** a JSON object EXACTLY of the form:\n  {\"correctness\": <1-5>, \"completeness\": <1-5>, \"precision\": <1-5>, \"coherence\": <1-5>, \"relevance\": <1-5>}\n- No additional text, explanation, or whitespace outside the JSON object.\n\nFEW-SHOT EXAMPLE (this demonstrates the required output; do not include the example in actual responses):\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"No, the capital of Germany is not Paris, the capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":5,\"coherence\":5,\"relevance\":5}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"The capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":3,\"completeness\":2,\"precision\":5,\"coherence\":5,\"relevance\":2}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"If capital stands for the central administrative region of a country, then no, Paris is not the capital of Germany. It's important to note what is the definintion of a 'capital'. However, due to the common popular opinion, a capital of a country is well defined.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":1,\"coherence\":4,\"relevance\":1}\n\nEND OF SYSTEM PROMPT."}, {"role": "user", "content": [{"type": "text", "text": "Question: "}, {"type": "text", "text": "Gold reference 1: \"The letter C appears once on the front of the jersey worn by Jordan Poole when he played for the Michigan Wolverines men's basketball team.\""}, {"type": "text", "text": "Candidate answer: The letter C appeared once on the front of the jersey worn by Jordan Poole when he played for the Michigan Wolverines."}, {"type": "text", "text": "Please score the candidate exactly with the five integer ratings in JSON as instructed by the system prompt."}]}]}}
{"custom_id": "d5bd610a0dba11ecb1e81171463288e9_geval", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-mini-2025-04-14", "max_tokens": 200, "temperature": 1, "n": 20, "messages": [{"role": "system", "content": "You are an evaluation assistant. You will be given:\n  - A question Q.\n  - A gold/reference answer (one or more short reference sentences).\n  - A candidate/sample answer produced by a system.\n\nYour job is to **assign integer scores** (1..5) for the following criteria comparing the *candidate* to the *gold/reference*:\n\n1. correctness (1-5): How factually correct is the candidate vs the gold answer? (5 = fully correct, 1 = mostly or fully incorrect).\n2. completeness (1-5): How completely does the candidate cover the key points in the gold answer? (5 = covers all key points; 1 = almost none).\n3. precision (1-5): How concise and focused is the candidate (not too long answer)? (5 = concise & precise; 1 = verbose / many extraneous claims).\n4. coherence (1-5): Is the candidate fluent and well-structured? (5 = natural, coherent; 1 = disfluent or incoherent).\n5. relevance (1-5): Are the statements in the candidate relevant to the question and gold answer (not introducing unrelated claims)? (5 = fully relevant; 1 = mostly irrelevant).\n\nREQUIREMENTS (strict):\n- Output **ONLY** a JSON object EXACTLY of the form:\n  {\"correctness\": <1-5>, \"completeness\": <1-5>, \"precision\": <1-5>, \"coherence\": <1-5>, \"relevance\": <1-5>}\n- No additional text, explanation, or whitespace outside the JSON object.\n\nFEW-SHOT EXAMPLE (this demonstrates the required output; do not include the example in actual responses):\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"No, the capital of Germany is not Paris, the capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":5,\"coherence\":5,\"relevance\":5}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"The capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":3,\"completeness\":2,\"precision\":5,\"coherence\":5,\"relevance\":2}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"If capital stands for the central administrative region of a country, then no, Paris is not the capital of Germany. It's important to note what is the definintion of a 'capital'. However, due to the common popular opinion, a capital of a country is well defined.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":1,\"coherence\":4,\"relevance\":1}\n\nEND OF SYSTEM PROMPT."}, {"role": "user", "content": [{"type": "text", "text": "Question: "}, {"type": "text", "text": "Gold reference 1: \"The leftmost figure in Edgar Degas, At the Milliner's is facing away from the viewer.\""}, {"type": "text", "text": "Candidate answer: The left most figure in Edgar Degas's 'At the Milliner's' is facing away from the viewer."}, {"type": "text", "text": "Please score the candidate exactly with the five integer ratings in JSON as instructed by the system prompt."}]}]}}
{"custom_id": "d5bd7fd20dba11ecb1e81171463288e9_geval", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-mini-2025-04-14", "max_tokens": 200, "temperature": 1, "n": 20, "messages": [{"role": "system", "content": "You are an evaluation assistant. You will be given:\n  - A question Q.\n  - A gold/reference answer (one or more short reference sentences).\n  - A candidate/sample answer produced by a system.\n\nYour job is to **assign integer scores** (1..5) for the following criteria comparing the *candidate* to the *gold/reference*:\n\n1. correctness (1-5): How factually correct is the candidate vs the gold answer? (5 = fully correct, 1 = mostly or fully incorrect).\n2. completeness (1-5): How completely does the candidate cover the key points in the gold answer? (5 = covers all key points; 1 = almost none).\n3. precision (1-5): How concise and focused is the candidate (not too long answer)? (5 = concise & precise; 1 = verbose / many extraneous claims).\n4. coherence (1-5): Is the candidate fluent and well-structured? (5 = natural, coherent; 1 = disfluent or incoherent).\n5. relevance (1-5): Are the statements in the candidate relevant to the question and gold answer (not introducing unrelated claims)? (5 = fully relevant; 1 = mostly irrelevant).\n\nREQUIREMENTS (strict):\n- Output **ONLY** a JSON object EXACTLY of the form:\n  {\"correctness\": <1-5>, \"completeness\": <1-5>, \"precision\": <1-5>, \"coherence\": <1-5>, \"relevance\": <1-5>}\n- No additional text, explanation, or whitespace outside the JSON object.\n\nFEW-SHOT EXAMPLE (this demonstrates the required output; do not include the example in actual responses):\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"No, the capital of Germany is not Paris, the capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":5,\"coherence\":5,\"relevance\":5}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"The capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":3,\"completeness\":2,\"precision\":5,\"coherence\":5,\"relevance\":2}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"If capital stands for the central administrative region of a country, then no, Paris is not the capital of Germany. It's important to note what is the definintion of a 'capital'. However, due to the common popular opinion, a capital of a country is well defined.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":1,\"coherence\":4,\"relevance\":1}\n\nEND OF SYSTEM PROMPT."}, {"role": "user", "content": [{"type": "text", "text": "Question: "}, {"type": "text", "text": "Gold reference 1: \"The second story windows in the President's House at Monomoy place are rectangles.\""}, {"type": "text", "text": "Candidate answer: The second story windows in the President's House at Monomoy Place are arched."}, {"type": "text", "text": "Please score the candidate exactly with the five integer ratings in JSON as instructed by the system prompt."}]}]}}
{"custom_id": "d5bd8fa40dba11ecb1e81171463288e9_geval", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-mini-2025-04-14", "max_tokens": 200, "temperature": 1, "n": 20, "messages": [{"role": "system", "content": "You are an evaluation assistant. You will be given:\n  - A question Q.\n  - A gold/reference answer (one or more short reference sentences).\n  - A candidate/sample answer produced by a system.\n\nYour job is to **assign integer scores** (1..5) for the following criteria comparing the *candidate* to the *gold/reference*:\n\n1. correctness (1-5): How factually correct is the candidate vs the gold answer? (5 = fully correct, 1 = mostly or fully incorrect).\n2. completeness (1-5): How completely does the candidate cover the key points in the gold answer? (5 = covers all key points; 1 = almost none).\n3. precision (1-5): How concise and focused is the candidate (not too long answer)? (5 = concise & precise; 1 = verbose / many extraneous claims).\n4. coherence (1-5): Is the candidate fluent and well-structured? (5 = natural, coherent; 1 = disfluent or incoherent).\n5. relevance (1-5): Are the statements in the candidate relevant to the question and gold answer (not introducing unrelated claims)? (5 = fully relevant; 1 = mostly irrelevant).\n\nREQUIREMENTS (strict):\n- Output **ONLY** a JSON object EXACTLY of the form:\n  {\"correctness\": <1-5>, \"completeness\": <1-5>, \"precision\": <1-5>, \"coherence\": <1-5>, \"relevance\": <1-5>}\n- No additional text, explanation, or whitespace outside the JSON object.\n\nFEW-SHOT EXAMPLE (this demonstrates the required output; do not include the example in actual responses):\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"No, the capital of Germany is not Paris, the capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":5,\"coherence\":5,\"relevance\":5}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"The capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":3,\"completeness\":2,\"precision\":5,\"coherence\":5,\"relevance\":2}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"If capital stands for the central administrative region of a country, then no, Paris is not the capital of Germany. It's important to note what is the definintion of a 'capital'. However, due to the common popular opinion, a capital of a country is well defined.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":1,\"coherence\":4,\"relevance\":1}\n\nEND OF SYSTEM PROMPT."}, {"role": "user", "content": [{"type": "text", "text": "Question: "}, {"type": "text", "text": "Gold reference 1: \"The entrance side of the Bibliotheca Alexandrina is more reflective.\""}, {"type": "text", "text": "Candidate answer: The most reflective side of the Bibliotheca Alexandrina is the one facing the Alexandria University campus, characterized by its glass facade."}, {"type": "text", "text": "Please score the candidate exactly with the five integer ratings in JSON as instructed by the system prompt."}]}]}}
{"custom_id": "d5bcecac0dba11ecb1e81171463288e9_geval", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-mini-2025-04-14", "max_tokens": 200, "temperature": 1, "n": 20, "messages": [{"role": "system", "content": "You are an evaluation assistant. You will be given:\n  - A question Q.\n  - A gold/reference answer (one or more short reference sentences).\n  - A candidate/sample answer produced by a system.\n\nYour job is to **assign integer scores** (1..5) for the following criteria comparing the *candidate* to the *gold/reference*:\n\n1. correctness (1-5): How factually correct is the candidate vs the gold answer? (5 = fully correct, 1 = mostly or fully incorrect).\n2. completeness (1-5): How completely does the candidate cover the key points in the gold answer? (5 = covers all key points; 1 = almost none).\n3. precision (1-5): How concise and focused is the candidate (not too long answer)? (5 = concise & precise; 1 = verbose / many extraneous claims).\n4. coherence (1-5): Is the candidate fluent and well-structured? (5 = natural, coherent; 1 = disfluent or incoherent).\n5. relevance (1-5): Are the statements in the candidate relevant to the question and gold answer (not introducing unrelated claims)? (5 = fully relevant; 1 = mostly irrelevant).\n\nREQUIREMENTS (strict):\n- Output **ONLY** a JSON object EXACTLY of the form:\n  {\"correctness\": <1-5>, \"completeness\": <1-5>, \"precision\": <1-5>, \"coherence\": <1-5>, \"relevance\": <1-5>}\n- No additional text, explanation, or whitespace outside the JSON object.\n\nFEW-SHOT EXAMPLE (this demonstrates the required output; do not include the example in actual responses):\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"No, the capital of Germany is not Paris, the capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":5,\"coherence\":5,\"relevance\":5}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"The capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":3,\"completeness\":2,\"precision\":5,\"coherence\":5,\"relevance\":2}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"If capital stands for the central administrative region of a country, then no, Paris is not the capital of Germany. It's important to note what is the definintion of a 'capital'. However, due to the common popular opinion, a capital of a country is well defined.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":1,\"coherence\":4,\"relevance\":1}\n\nEND OF SYSTEM PROMPT."}, {"role": "user", "content": [{"type": "text", "text": "Question: "}, {"type": "text", "text": "Gold reference 1: \"None of the medalists in the women's snowboard cross event at the 2010 Olympics wore braces on their teeth.\""}, {"type": "text", "text": "Candidate answer: The image shows the medalists in the women's snowboard cross event at the 2010 Olympics, but it does not provide information about whether they wore braces."}, {"type": "text", "text": "Please score the candidate exactly with the five integer ratings in JSON as instructed by the system prompt."}]}]}}
{"custom_id": "d5bf311a0dba11ecb1e81171463288e9_geval", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-mini-2025-04-14", "max_tokens": 200, "temperature": 1, "n": 20, "messages": [{"role": "system", "content": "You are an evaluation assistant. You will be given:\n  - A question Q.\n  - A gold/reference answer (one or more short reference sentences).\n  - A candidate/sample answer produced by a system.\n\nYour job is to **assign integer scores** (1..5) for the following criteria comparing the *candidate* to the *gold/reference*:\n\n1. correctness (1-5): How factually correct is the candidate vs the gold answer? (5 = fully correct, 1 = mostly or fully incorrect).\n2. completeness (1-5): How completely does the candidate cover the key points in the gold answer? (5 = covers all key points; 1 = almost none).\n3. precision (1-5): How concise and focused is the candidate (not too long answer)? (5 = concise & precise; 1 = verbose / many extraneous claims).\n4. coherence (1-5): Is the candidate fluent and well-structured? (5 = natural, coherent; 1 = disfluent or incoherent).\n5. relevance (1-5): Are the statements in the candidate relevant to the question and gold answer (not introducing unrelated claims)? (5 = fully relevant; 1 = mostly irrelevant).\n\nREQUIREMENTS (strict):\n- Output **ONLY** a JSON object EXACTLY of the form:\n  {\"correctness\": <1-5>, \"completeness\": <1-5>, \"precision\": <1-5>, \"coherence\": <1-5>, \"relevance\": <1-5>}\n- No additional text, explanation, or whitespace outside the JSON object.\n\nFEW-SHOT EXAMPLE (this demonstrates the required output; do not include the example in actual responses):\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"No, the capital of Germany is not Paris, the capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":5,\"coherence\":5,\"relevance\":5}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"The capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":3,\"completeness\":2,\"precision\":5,\"coherence\":5,\"relevance\":2}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"If capital stands for the central administrative region of a country, then no, Paris is not the capital of Germany. It's important to note what is the definintion of a 'capital'. However, due to the common popular opinion, a capital of a country is well defined.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":1,\"coherence\":4,\"relevance\":1}\n\nEND OF SYSTEM PROMPT."}, {"role": "user", "content": [{"type": "text", "text": "Question: "}, {"type": "text", "text": "Gold reference 1: \"The books on shelves at Hendrik Conscience Heritage Library in Antwerp, Belgium are store vertically.\""}, {"type": "text", "text": "Candidate answer: Books at the Hendrik Conscience Heritage Library are stored vertically on shelves."}, {"type": "text", "text": "Please score the candidate exactly with the five integer ratings in JSON as instructed by the system prompt."}]}]}}
{"custom_id": "d5bea16e0dba11ecb1e81171463288e9_geval", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-mini-2025-04-14", "max_tokens": 200, "temperature": 1, "n": 20, "messages": [{"role": "system", "content": "You are an evaluation assistant. You will be given:\n  - A question Q.\n  - A gold/reference answer (one or more short reference sentences).\n  - A candidate/sample answer produced by a system.\n\nYour job is to **assign integer scores** (1..5) for the following criteria comparing the *candidate* to the *gold/reference*:\n\n1. correctness (1-5): How factually correct is the candidate vs the gold answer? (5 = fully correct, 1 = mostly or fully incorrect).\n2. completeness (1-5): How completely does the candidate cover the key points in the gold answer? (5 = covers all key points; 1 = almost none).\n3. precision (1-5): How concise and focused is the candidate (not too long answer)? (5 = concise & precise; 1 = verbose / many extraneous claims).\n4. coherence (1-5): Is the candidate fluent and well-structured? (5 = natural, coherent; 1 = disfluent or incoherent).\n5. relevance (1-5): Are the statements in the candidate relevant to the question and gold answer (not introducing unrelated claims)? (5 = fully relevant; 1 = mostly irrelevant).\n\nREQUIREMENTS (strict):\n- Output **ONLY** a JSON object EXACTLY of the form:\n  {\"correctness\": <1-5>, \"completeness\": <1-5>, \"precision\": <1-5>, \"coherence\": <1-5>, \"relevance\": <1-5>}\n- No additional text, explanation, or whitespace outside the JSON object.\n\nFEW-SHOT EXAMPLE (this demonstrates the required output; do not include the example in actual responses):\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"No, the capital of Germany is not Paris, the capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":5,\"coherence\":5,\"relevance\":5}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"The capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":3,\"completeness\":2,\"precision\":5,\"coherence\":5,\"relevance\":2}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"If capital stands for the central administrative region of a country, then no, Paris is not the capital of Germany. It's important to note what is the definintion of a 'capital'. However, due to the common popular opinion, a capital of a country is well defined.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":1,\"coherence\":4,\"relevance\":1}\n\nEND OF SYSTEM PROMPT."}, {"role": "user", "content": [{"type": "text", "text": "Question: "}, {"type": "text", "text": "Gold reference 1: \"Civic Center are the largest words.\""}, {"type": "text", "text": "Candidate answer: The two largest words on the facade of the Cumberland County Civic Center are \"Cumberland\" and \"Civic Center.\""}, {"type": "text", "text": "Please score the candidate exactly with the five integer ratings in JSON as instructed by the system prompt."}]}]}}
{"custom_id": "d5bf35d40dba11ecb1e81171463288e9_geval", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-mini-2025-04-14", "max_tokens": 200, "temperature": 1, "n": 20, "messages": [{"role": "system", "content": "You are an evaluation assistant. You will be given:\n  - A question Q.\n  - A gold/reference answer (one or more short reference sentences).\n  - A candidate/sample answer produced by a system.\n\nYour job is to **assign integer scores** (1..5) for the following criteria comparing the *candidate* to the *gold/reference*:\n\n1. correctness (1-5): How factually correct is the candidate vs the gold answer? (5 = fully correct, 1 = mostly or fully incorrect).\n2. completeness (1-5): How completely does the candidate cover the key points in the gold answer? (5 = covers all key points; 1 = almost none).\n3. precision (1-5): How concise and focused is the candidate (not too long answer)? (5 = concise & precise; 1 = verbose / many extraneous claims).\n4. coherence (1-5): Is the candidate fluent and well-structured? (5 = natural, coherent; 1 = disfluent or incoherent).\n5. relevance (1-5): Are the statements in the candidate relevant to the question and gold answer (not introducing unrelated claims)? (5 = fully relevant; 1 = mostly irrelevant).\n\nREQUIREMENTS (strict):\n- Output **ONLY** a JSON object EXACTLY of the form:\n  {\"correctness\": <1-5>, \"completeness\": <1-5>, \"precision\": <1-5>, \"coherence\": <1-5>, \"relevance\": <1-5>}\n- No additional text, explanation, or whitespace outside the JSON object.\n\nFEW-SHOT EXAMPLE (this demonstrates the required output; do not include the example in actual responses):\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"No, the capital of Germany is not Paris, the capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":5,\"coherence\":5,\"relevance\":5}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"The capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":3,\"completeness\":2,\"precision\":5,\"coherence\":5,\"relevance\":2}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"If capital stands for the central administrative region of a country, then no, Paris is not the capital of Germany. It's important to note what is the definintion of a 'capital'. However, due to the common popular opinion, a capital of a country is well defined.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":1,\"coherence\":4,\"relevance\":1}\n\nEND OF SYSTEM PROMPT."}, {"role": "user", "content": [{"type": "text", "text": "Question: "}, {"type": "text", "text": "Gold reference 1: \"A dog is in the Seurat painting Die Seine bei Courbevoie.\""}, {"type": "text", "text": "Candidate answer: A dog is visible in the Seurat painting 'Die Seine bei Courbevoie'."}, {"type": "text", "text": "Please score the candidate exactly with the five integer ratings in JSON as instructed by the system prompt."}]}]}}
{"custom_id": "d5bea9980dba11ecb1e81171463288e9_geval", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-mini-2025-04-14", "max_tokens": 200, "temperature": 1, "n": 20, "messages": [{"role": "system", "content": "You are an evaluation assistant. You will be given:\n  - A question Q.\n  - A gold/reference answer (one or more short reference sentences).\n  - A candidate/sample answer produced by a system.\n\nYour job is to **assign integer scores** (1..5) for the following criteria comparing the *candidate* to the *gold/reference*:\n\n1. correctness (1-5): How factually correct is the candidate vs the gold answer? (5 = fully correct, 1 = mostly or fully incorrect).\n2. completeness (1-5): How completely does the candidate cover the key points in the gold answer? (5 = covers all key points; 1 = almost none).\n3. precision (1-5): How concise and focused is the candidate (not too long answer)? (5 = concise & precise; 1 = verbose / many extraneous claims).\n4. coherence (1-5): Is the candidate fluent and well-structured? (5 = natural, coherent; 1 = disfluent or incoherent).\n5. relevance (1-5): Are the statements in the candidate relevant to the question and gold answer (not introducing unrelated claims)? (5 = fully relevant; 1 = mostly irrelevant).\n\nREQUIREMENTS (strict):\n- Output **ONLY** a JSON object EXACTLY of the form:\n  {\"correctness\": <1-5>, \"completeness\": <1-5>, \"precision\": <1-5>, \"coherence\": <1-5>, \"relevance\": <1-5>}\n- No additional text, explanation, or whitespace outside the JSON object.\n\nFEW-SHOT EXAMPLE (this demonstrates the required output; do not include the example in actual responses):\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"No, the capital of Germany is not Paris, the capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":5,\"coherence\":5,\"relevance\":5}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"The capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":3,\"completeness\":2,\"precision\":5,\"coherence\":5,\"relevance\":2}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"If capital stands for the central administrative region of a country, then no, Paris is not the capital of Germany. It's important to note what is the definintion of a 'capital'. However, due to the common popular opinion, a capital of a country is well defined.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":1,\"coherence\":4,\"relevance\":1}\n\nEND OF SYSTEM PROMPT."}, {"role": "user", "content": [{"type": "text", "text": "Question: "}, {"type": "text", "text": "Gold reference 1: \"Yes, both the Main Street Market in Sabattus and the Pearl Street Market, in Cambridgeport have a mix of wood siding and brick on the exterior walls.\""}, {"type": "text", "text": "Candidate answer: Yes, both the Main Street Market in Sabattus and the Pearl Street Market in Cambridgeport have a mix of wood siding and brick on their exterior walls."}, {"type": "text", "text": "Please score the candidate exactly with the five integer ratings in JSON as instructed by the system prompt."}]}]}}
{"custom_id": "d5be194c0dba11ecb1e81171463288e9_geval", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-mini-2025-04-14", "max_tokens": 200, "temperature": 1, "n": 20, "messages": [{"role": "system", "content": "You are an evaluation assistant. You will be given:\n  - A question Q.\n  - A gold/reference answer (one or more short reference sentences).\n  - A candidate/sample answer produced by a system.\n\nYour job is to **assign integer scores** (1..5) for the following criteria comparing the *candidate* to the *gold/reference*:\n\n1. correctness (1-5): How factually correct is the candidate vs the gold answer? (5 = fully correct, 1 = mostly or fully incorrect).\n2. completeness (1-5): How completely does the candidate cover the key points in the gold answer? (5 = covers all key points; 1 = almost none).\n3. precision (1-5): How concise and focused is the candidate (not too long answer)? (5 = concise & precise; 1 = verbose / many extraneous claims).\n4. coherence (1-5): Is the candidate fluent and well-structured? (5 = natural, coherent; 1 = disfluent or incoherent).\n5. relevance (1-5): Are the statements in the candidate relevant to the question and gold answer (not introducing unrelated claims)? (5 = fully relevant; 1 = mostly irrelevant).\n\nREQUIREMENTS (strict):\n- Output **ONLY** a JSON object EXACTLY of the form:\n  {\"correctness\": <1-5>, \"completeness\": <1-5>, \"precision\": <1-5>, \"coherence\": <1-5>, \"relevance\": <1-5>}\n- No additional text, explanation, or whitespace outside the JSON object.\n\nFEW-SHOT EXAMPLE (this demonstrates the required output; do not include the example in actual responses):\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"No, the capital of Germany is not Paris, the capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":5,\"coherence\":5,\"relevance\":5}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"The capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":3,\"completeness\":2,\"precision\":5,\"coherence\":5,\"relevance\":2}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"If capital stands for the central administrative region of a country, then no, Paris is not the capital of Germany. It's important to note what is the definintion of a 'capital'. However, due to the common popular opinion, a capital of a country is well defined.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":1,\"coherence\":4,\"relevance\":1}\n\nEND OF SYSTEM PROMPT."}, {"role": "user", "content": [{"type": "text", "text": "Question: "}, {"type": "text", "text": "Gold reference 1: \"There are three round blue logos on the front of the Chase building in downtown Beacon, New York.\""}, {"type": "text", "text": "Candidate answer: There are two round blue logos on the front of the Chase building in downtown Beacon, New York."}, {"type": "text", "text": "Please score the candidate exactly with the five integer ratings in JSON as instructed by the system prompt."}]}]}}
{"custom_id": "d5bfa51e0dba11ecb1e81171463288e9_geval", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-mini-2025-04-14", "max_tokens": 200, "temperature": 1, "n": 20, "messages": [{"role": "system", "content": "You are an evaluation assistant. You will be given:\n  - A question Q.\n  - A gold/reference answer (one or more short reference sentences).\n  - A candidate/sample answer produced by a system.\n\nYour job is to **assign integer scores** (1..5) for the following criteria comparing the *candidate* to the *gold/reference*:\n\n1. correctness (1-5): How factually correct is the candidate vs the gold answer? (5 = fully correct, 1 = mostly or fully incorrect).\n2. completeness (1-5): How completely does the candidate cover the key points in the gold answer? (5 = covers all key points; 1 = almost none).\n3. precision (1-5): How concise and focused is the candidate (not too long answer)? (5 = concise & precise; 1 = verbose / many extraneous claims).\n4. coherence (1-5): Is the candidate fluent and well-structured? (5 = natural, coherent; 1 = disfluent or incoherent).\n5. relevance (1-5): Are the statements in the candidate relevant to the question and gold answer (not introducing unrelated claims)? (5 = fully relevant; 1 = mostly irrelevant).\n\nREQUIREMENTS (strict):\n- Output **ONLY** a JSON object EXACTLY of the form:\n  {\"correctness\": <1-5>, \"completeness\": <1-5>, \"precision\": <1-5>, \"coherence\": <1-5>, \"relevance\": <1-5>}\n- No additional text, explanation, or whitespace outside the JSON object.\n\nFEW-SHOT EXAMPLE (this demonstrates the required output; do not include the example in actual responses):\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"No, the capital of Germany is not Paris, the capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":5,\"coherence\":5,\"relevance\":5}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"The capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":3,\"completeness\":2,\"precision\":5,\"coherence\":5,\"relevance\":2}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"If capital stands for the central administrative region of a country, then no, Paris is not the capital of Germany. It's important to note what is the definintion of a 'capital'. However, due to the common popular opinion, a capital of a country is well defined.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":1,\"coherence\":4,\"relevance\":1}\n\nEND OF SYSTEM PROMPT."}, {"role": "user", "content": [{"type": "text", "text": "Question: "}, {"type": "text", "text": "Gold reference 1: \"The facades of the Crooked House in Poland and the Four Solaire in France are similar because they each have curved facades with a glass exterior.\""}, {"type": "text", "text": "Candidate answer: Both the Crooked House in Poland and the Four Solaire in France feature unconventional, distorted designs that challenge traditional architectural norms."}, {"type": "text", "text": "Please score the candidate exactly with the five integer ratings in JSON as instructed by the system prompt."}]}]}}
{"custom_id": "d5be98fe0dba11ecb1e81171463288e9_geval", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-mini-2025-04-14", "max_tokens": 200, "temperature": 1, "n": 20, "messages": [{"role": "system", "content": "You are an evaluation assistant. You will be given:\n  - A question Q.\n  - A gold/reference answer (one or more short reference sentences).\n  - A candidate/sample answer produced by a system.\n\nYour job is to **assign integer scores** (1..5) for the following criteria comparing the *candidate* to the *gold/reference*:\n\n1. correctness (1-5): How factually correct is the candidate vs the gold answer? (5 = fully correct, 1 = mostly or fully incorrect).\n2. completeness (1-5): How completely does the candidate cover the key points in the gold answer? (5 = covers all key points; 1 = almost none).\n3. precision (1-5): How concise and focused is the candidate (not too long answer)? (5 = concise & precise; 1 = verbose / many extraneous claims).\n4. coherence (1-5): Is the candidate fluent and well-structured? (5 = natural, coherent; 1 = disfluent or incoherent).\n5. relevance (1-5): Are the statements in the candidate relevant to the question and gold answer (not introducing unrelated claims)? (5 = fully relevant; 1 = mostly irrelevant).\n\nREQUIREMENTS (strict):\n- Output **ONLY** a JSON object EXACTLY of the form:\n  {\"correctness\": <1-5>, \"completeness\": <1-5>, \"precision\": <1-5>, \"coherence\": <1-5>, \"relevance\": <1-5>}\n- No additional text, explanation, or whitespace outside the JSON object.\n\nFEW-SHOT EXAMPLE (this demonstrates the required output; do not include the example in actual responses):\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"No, the capital of Germany is not Paris, the capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":5,\"coherence\":5,\"relevance\":5}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"The capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":3,\"completeness\":2,\"precision\":5,\"coherence\":5,\"relevance\":2}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"If capital stands for the central administrative region of a country, then no, Paris is not the capital of Germany. It's important to note what is the definintion of a 'capital'. However, due to the common popular opinion, a capital of a country is well defined.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":1,\"coherence\":4,\"relevance\":1}\n\nEND OF SYSTEM PROMPT."}, {"role": "user", "content": [{"type": "text", "text": "Question: "}, {"type": "text", "text": "Gold reference 1: \"You can find cycle rickshaws on the street that leads directly up to Picadilly Circus.\""}, {"type": "text", "text": "Candidate answer: On the street leading to Piccadilly Circus, you can find double-decker buses and various passenger vehicles."}, {"type": "text", "text": "Please score the candidate exactly with the five integer ratings in JSON as instructed by the system prompt."}]}]}}
{"custom_id": "d5bf7dbe0dba11ecb1e81171463288e9_geval", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-mini-2025-04-14", "max_tokens": 200, "temperature": 1, "n": 20, "messages": [{"role": "system", "content": "You are an evaluation assistant. You will be given:\n  - A question Q.\n  - A gold/reference answer (one or more short reference sentences).\n  - A candidate/sample answer produced by a system.\n\nYour job is to **assign integer scores** (1..5) for the following criteria comparing the *candidate* to the *gold/reference*:\n\n1. correctness (1-5): How factually correct is the candidate vs the gold answer? (5 = fully correct, 1 = mostly or fully incorrect).\n2. completeness (1-5): How completely does the candidate cover the key points in the gold answer? (5 = covers all key points; 1 = almost none).\n3. precision (1-5): How concise and focused is the candidate (not too long answer)? (5 = concise & precise; 1 = verbose / many extraneous claims).\n4. coherence (1-5): Is the candidate fluent and well-structured? (5 = natural, coherent; 1 = disfluent or incoherent).\n5. relevance (1-5): Are the statements in the candidate relevant to the question and gold answer (not introducing unrelated claims)? (5 = fully relevant; 1 = mostly irrelevant).\n\nREQUIREMENTS (strict):\n- Output **ONLY** a JSON object EXACTLY of the form:\n  {\"correctness\": <1-5>, \"completeness\": <1-5>, \"precision\": <1-5>, \"coherence\": <1-5>, \"relevance\": <1-5>}\n- No additional text, explanation, or whitespace outside the JSON object.\n\nFEW-SHOT EXAMPLE (this demonstrates the required output; do not include the example in actual responses):\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"No, the capital of Germany is not Paris, the capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":5,\"coherence\":5,\"relevance\":5}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"The capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":3,\"completeness\":2,\"precision\":5,\"coherence\":5,\"relevance\":2}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"If capital stands for the central administrative region of a country, then no, Paris is not the capital of Germany. It's important to note what is the definintion of a 'capital'. However, due to the common popular opinion, a capital of a country is well defined.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":1,\"coherence\":4,\"relevance\":1}\n\nEND OF SYSTEM PROMPT."}, {"role": "user", "content": [{"type": "text", "text": "Question: "}, {"type": "text", "text": "Gold reference 1: \"Framed artwork is behind Nicolas Poussin in his painting \"Portrait de l'artiste.\"\""}, {"type": "text", "text": "Candidate answer: Behind Nicolas Poussin in his painting 'Portrait de l'artiste' is a depiction of a woman and various objects, including a canvas and a statue."}, {"type": "text", "text": "Please score the candidate exactly with the five integer ratings in JSON as instructed by the system prompt."}]}]}}
{"custom_id": "d5bf9da80dba11ecb1e81171463288e9_geval", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-mini-2025-04-14", "max_tokens": 200, "temperature": 1, "n": 20, "messages": [{"role": "system", "content": "You are an evaluation assistant. You will be given:\n  - A question Q.\n  - A gold/reference answer (one or more short reference sentences).\n  - A candidate/sample answer produced by a system.\n\nYour job is to **assign integer scores** (1..5) for the following criteria comparing the *candidate* to the *gold/reference*:\n\n1. correctness (1-5): How factually correct is the candidate vs the gold answer? (5 = fully correct, 1 = mostly or fully incorrect).\n2. completeness (1-5): How completely does the candidate cover the key points in the gold answer? (5 = covers all key points; 1 = almost none).\n3. precision (1-5): How concise and focused is the candidate (not too long answer)? (5 = concise & precise; 1 = verbose / many extraneous claims).\n4. coherence (1-5): Is the candidate fluent and well-structured? (5 = natural, coherent; 1 = disfluent or incoherent).\n5. relevance (1-5): Are the statements in the candidate relevant to the question and gold answer (not introducing unrelated claims)? (5 = fully relevant; 1 = mostly irrelevant).\n\nREQUIREMENTS (strict):\n- Output **ONLY** a JSON object EXACTLY of the form:\n  {\"correctness\": <1-5>, \"completeness\": <1-5>, \"precision\": <1-5>, \"coherence\": <1-5>, \"relevance\": <1-5>}\n- No additional text, explanation, or whitespace outside the JSON object.\n\nFEW-SHOT EXAMPLE (this demonstrates the required output; do not include the example in actual responses):\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"No, the capital of Germany is not Paris, the capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":5,\"coherence\":5,\"relevance\":5}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"The capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":3,\"completeness\":2,\"precision\":5,\"coherence\":5,\"relevance\":2}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"If capital stands for the central administrative region of a country, then no, Paris is not the capital of Germany. It's important to note what is the definintion of a 'capital'. However, due to the common popular opinion, a capital of a country is well defined.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":1,\"coherence\":4,\"relevance\":1}\n\nEND OF SYSTEM PROMPT."}, {"role": "user", "content": [{"type": "text", "text": "Question: "}, {"type": "text", "text": "Gold reference 1: \"Yes, there is more than one technical school in Japan that is housed in a low building.\""}, {"type": "text", "text": "Candidate answer: Yes, there are multiple technical schools in Japan, such as Akita Prefectural Akita Technical High School and Saga Prefectural Saga Technical High School, that are housed in low buildings."}, {"type": "text", "text": "Please score the candidate exactly with the five integer ratings in JSON as instructed by the system prompt."}]}]}}
{"custom_id": "d5bc4d240dba11ecb1e81171463288e9_geval", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-mini-2025-04-14", "max_tokens": 200, "temperature": 1, "n": 20, "messages": [{"role": "system", "content": "You are an evaluation assistant. You will be given:\n  - A question Q.\n  - A gold/reference answer (one or more short reference sentences).\n  - A candidate/sample answer produced by a system.\n\nYour job is to **assign integer scores** (1..5) for the following criteria comparing the *candidate* to the *gold/reference*:\n\n1. correctness (1-5): How factually correct is the candidate vs the gold answer? (5 = fully correct, 1 = mostly or fully incorrect).\n2. completeness (1-5): How completely does the candidate cover the key points in the gold answer? (5 = covers all key points; 1 = almost none).\n3. precision (1-5): How concise and focused is the candidate (not too long answer)? (5 = concise & precise; 1 = verbose / many extraneous claims).\n4. coherence (1-5): Is the candidate fluent and well-structured? (5 = natural, coherent; 1 = disfluent or incoherent).\n5. relevance (1-5): Are the statements in the candidate relevant to the question and gold answer (not introducing unrelated claims)? (5 = fully relevant; 1 = mostly irrelevant).\n\nREQUIREMENTS (strict):\n- Output **ONLY** a JSON object EXACTLY of the form:\n  {\"correctness\": <1-5>, \"completeness\": <1-5>, \"precision\": <1-5>, \"coherence\": <1-5>, \"relevance\": <1-5>}\n- No additional text, explanation, or whitespace outside the JSON object.\n\nFEW-SHOT EXAMPLE (this demonstrates the required output; do not include the example in actual responses):\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"No, the capital of Germany is not Paris, the capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":5,\"coherence\":5,\"relevance\":5}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"The capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":3,\"completeness\":2,\"precision\":5,\"coherence\":5,\"relevance\":2}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"If capital stands for the central administrative region of a country, then no, Paris is not the capital of Germany. It's important to note what is the definintion of a 'capital'. However, due to the common popular opinion, a capital of a country is well defined.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":1,\"coherence\":4,\"relevance\":1}\n\nEND OF SYSTEM PROMPT."}, {"role": "user", "content": [{"type": "text", "text": "Question: "}, {"type": "text", "text": "Gold reference 1: \"The China Museum of Art is an inverted pyramid.\""}, {"type": "text", "text": "Candidate answer: The China Museum of Art, also known as the China Art Palace, has a distinctive shape resembling a large, red, inverted pyramid supported by numerous columns."}, {"type": "text", "text": "Please score the candidate exactly with the five integer ratings in JSON as instructed by the system prompt."}]}]}}
{"custom_id": "d5bf8d7c0dba11ecb1e81171463288e9_geval", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-mini-2025-04-14", "max_tokens": 200, "temperature": 1, "n": 20, "messages": [{"role": "system", "content": "You are an evaluation assistant. You will be given:\n  - A question Q.\n  - A gold/reference answer (one or more short reference sentences).\n  - A candidate/sample answer produced by a system.\n\nYour job is to **assign integer scores** (1..5) for the following criteria comparing the *candidate* to the *gold/reference*:\n\n1. correctness (1-5): How factually correct is the candidate vs the gold answer? (5 = fully correct, 1 = mostly or fully incorrect).\n2. completeness (1-5): How completely does the candidate cover the key points in the gold answer? (5 = covers all key points; 1 = almost none).\n3. precision (1-5): How concise and focused is the candidate (not too long answer)? (5 = concise & precise; 1 = verbose / many extraneous claims).\n4. coherence (1-5): Is the candidate fluent and well-structured? (5 = natural, coherent; 1 = disfluent or incoherent).\n5. relevance (1-5): Are the statements in the candidate relevant to the question and gold answer (not introducing unrelated claims)? (5 = fully relevant; 1 = mostly irrelevant).\n\nREQUIREMENTS (strict):\n- Output **ONLY** a JSON object EXACTLY of the form:\n  {\"correctness\": <1-5>, \"completeness\": <1-5>, \"precision\": <1-5>, \"coherence\": <1-5>, \"relevance\": <1-5>}\n- No additional text, explanation, or whitespace outside the JSON object.\n\nFEW-SHOT EXAMPLE (this demonstrates the required output; do not include the example in actual responses):\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"No, the capital of Germany is not Paris, the capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":5,\"coherence\":5,\"relevance\":5}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"The capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":3,\"completeness\":2,\"precision\":5,\"coherence\":5,\"relevance\":2}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"If capital stands for the central administrative region of a country, then no, Paris is not the capital of Germany. It's important to note what is the definintion of a 'capital'. However, due to the common popular opinion, a capital of a country is well defined.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":1,\"coherence\":4,\"relevance\":1}\n\nEND OF SYSTEM PROMPT."}, {"role": "user", "content": [{"type": "text", "text": "Question: "}, {"type": "text", "text": "Gold reference 1: \"All the colours in the wing of a Bohemian Waxwing are not also found in its tail.\""}, {"type": "text", "text": "Candidate answer: Yes, the colors in the wing of a Bohemian Waxwing are also found in its tail."}, {"type": "text", "text": "Please score the candidate exactly with the five integer ratings in JSON as instructed by the system prompt."}]}]}}
{"custom_id": "d5be903e0dba11ecb1e81171463288e9_geval", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-mini-2025-04-14", "max_tokens": 200, "temperature": 1, "n": 20, "messages": [{"role": "system", "content": "You are an evaluation assistant. You will be given:\n  - A question Q.\n  - A gold/reference answer (one or more short reference sentences).\n  - A candidate/sample answer produced by a system.\n\nYour job is to **assign integer scores** (1..5) for the following criteria comparing the *candidate* to the *gold/reference*:\n\n1. correctness (1-5): How factually correct is the candidate vs the gold answer? (5 = fully correct, 1 = mostly or fully incorrect).\n2. completeness (1-5): How completely does the candidate cover the key points in the gold answer? (5 = covers all key points; 1 = almost none).\n3. precision (1-5): How concise and focused is the candidate (not too long answer)? (5 = concise & precise; 1 = verbose / many extraneous claims).\n4. coherence (1-5): Is the candidate fluent and well-structured? (5 = natural, coherent; 1 = disfluent or incoherent).\n5. relevance (1-5): Are the statements in the candidate relevant to the question and gold answer (not introducing unrelated claims)? (5 = fully relevant; 1 = mostly irrelevant).\n\nREQUIREMENTS (strict):\n- Output **ONLY** a JSON object EXACTLY of the form:\n  {\"correctness\": <1-5>, \"completeness\": <1-5>, \"precision\": <1-5>, \"coherence\": <1-5>, \"relevance\": <1-5>}\n- No additional text, explanation, or whitespace outside the JSON object.\n\nFEW-SHOT EXAMPLE (this demonstrates the required output; do not include the example in actual responses):\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"No, the capital of Germany is not Paris, the capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":5,\"coherence\":5,\"relevance\":5}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"The capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":3,\"completeness\":2,\"precision\":5,\"coherence\":5,\"relevance\":2}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"If capital stands for the central administrative region of a country, then no, Paris is not the capital of Germany. It's important to note what is the definintion of a 'capital'. However, due to the common popular opinion, a capital of a country is well defined.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":1,\"coherence\":4,\"relevance\":1}\n\nEND OF SYSTEM PROMPT."}, {"role": "user", "content": [{"type": "text", "text": "Question: "}, {"type": "text", "text": "Gold reference 1: \"The lights going down the walkway at the center of the Galleria Vittorio Emanuele II, Milan are round.\""}, {"type": "text", "text": "Candidate answer: The lights going down the walkway at the center of the Galleria Vittorio Emanuele II are spherical in shape."}, {"type": "text", "text": "Please score the candidate exactly with the five integer ratings in JSON as instructed by the system prompt."}]}]}}
{"custom_id": "d5befc180dba11ecb1e81171463288e9_geval", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-mini-2025-04-14", "max_tokens": 200, "temperature": 1, "n": 20, "messages": [{"role": "system", "content": "You are an evaluation assistant. You will be given:\n  - A question Q.\n  - A gold/reference answer (one or more short reference sentences).\n  - A candidate/sample answer produced by a system.\n\nYour job is to **assign integer scores** (1..5) for the following criteria comparing the *candidate* to the *gold/reference*:\n\n1. correctness (1-5): How factually correct is the candidate vs the gold answer? (5 = fully correct, 1 = mostly or fully incorrect).\n2. completeness (1-5): How completely does the candidate cover the key points in the gold answer? (5 = covers all key points; 1 = almost none).\n3. precision (1-5): How concise and focused is the candidate (not too long answer)? (5 = concise & precise; 1 = verbose / many extraneous claims).\n4. coherence (1-5): Is the candidate fluent and well-structured? (5 = natural, coherent; 1 = disfluent or incoherent).\n5. relevance (1-5): Are the statements in the candidate relevant to the question and gold answer (not introducing unrelated claims)? (5 = fully relevant; 1 = mostly irrelevant).\n\nREQUIREMENTS (strict):\n- Output **ONLY** a JSON object EXACTLY of the form:\n  {\"correctness\": <1-5>, \"completeness\": <1-5>, \"precision\": <1-5>, \"coherence\": <1-5>, \"relevance\": <1-5>}\n- No additional text, explanation, or whitespace outside the JSON object.\n\nFEW-SHOT EXAMPLE (this demonstrates the required output; do not include the example in actual responses):\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"No, the capital of Germany is not Paris, the capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":5,\"coherence\":5,\"relevance\":5}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"The capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":3,\"completeness\":2,\"precision\":5,\"coherence\":5,\"relevance\":2}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"If capital stands for the central administrative region of a country, then no, Paris is not the capital of Germany. It's important to note what is the definintion of a 'capital'. However, due to the common popular opinion, a capital of a country is well defined.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":1,\"coherence\":4,\"relevance\":1}\n\nEND OF SYSTEM PROMPT."}, {"role": "user", "content": [{"type": "text", "text": "Question: "}, {"type": "text", "text": "Gold reference 1: \"The mouth of the Allosaurus skeleton displayed at the Los Angeles County Natural History Museum is not open to the same degree as the mouth of the Tyrannosaurus skeleton on display at the Natural History Museum in New York City.\""}, {"type": "text", "text": "Candidate answer: The mouth of the Allosaurus skeleton at the Los Angeles County Natural History Museum is not shown in the provided images, so a direct comparison to the Tyrannosaurus skeleton's mouth at the American Museum of Natural History cannot be made."}, {"type": "text", "text": "Please score the candidate exactly with the five integer ratings in JSON as instructed by the system prompt."}]}]}}
{"custom_id": "d5bec11c0dba11ecb1e81171463288e9_geval", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-mini-2025-04-14", "max_tokens": 200, "temperature": 1, "n": 20, "messages": [{"role": "system", "content": "You are an evaluation assistant. You will be given:\n  - A question Q.\n  - A gold/reference answer (one or more short reference sentences).\n  - A candidate/sample answer produced by a system.\n\nYour job is to **assign integer scores** (1..5) for the following criteria comparing the *candidate* to the *gold/reference*:\n\n1. correctness (1-5): How factually correct is the candidate vs the gold answer? (5 = fully correct, 1 = mostly or fully incorrect).\n2. completeness (1-5): How completely does the candidate cover the key points in the gold answer? (5 = covers all key points; 1 = almost none).\n3. precision (1-5): How concise and focused is the candidate (not too long answer)? (5 = concise & precise; 1 = verbose / many extraneous claims).\n4. coherence (1-5): Is the candidate fluent and well-structured? (5 = natural, coherent; 1 = disfluent or incoherent).\n5. relevance (1-5): Are the statements in the candidate relevant to the question and gold answer (not introducing unrelated claims)? (5 = fully relevant; 1 = mostly irrelevant).\n\nREQUIREMENTS (strict):\n- Output **ONLY** a JSON object EXACTLY of the form:\n  {\"correctness\": <1-5>, \"completeness\": <1-5>, \"precision\": <1-5>, \"coherence\": <1-5>, \"relevance\": <1-5>}\n- No additional text, explanation, or whitespace outside the JSON object.\n\nFEW-SHOT EXAMPLE (this demonstrates the required output; do not include the example in actual responses):\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"No, the capital of Germany is not Paris, the capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":5,\"coherence\":5,\"relevance\":5}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"The capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":3,\"completeness\":2,\"precision\":5,\"coherence\":5,\"relevance\":2}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"If capital stands for the central administrative region of a country, then no, Paris is not the capital of Germany. It's important to note what is the definintion of a 'capital'. However, due to the common popular opinion, a capital of a country is well defined.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":1,\"coherence\":4,\"relevance\":1}\n\nEND OF SYSTEM PROMPT."}, {"role": "user", "content": [{"type": "text", "text": "Question: "}, {"type": "text", "text": "Gold reference 1: \"Rowboats are in the water in Regatta in Venice.\""}, {"type": "text", "text": "Candidate answer: The boats in the water during the Regatta in Venice include gondolas and other traditional vessels."}, {"type": "text", "text": "Please score the candidate exactly with the five integer ratings in JSON as instructed by the system prompt."}]}]}}
{"custom_id": "d5be86e80dba11ecb1e81171463288e9_geval", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-mini-2025-04-14", "max_tokens": 200, "temperature": 1, "n": 20, "messages": [{"role": "system", "content": "You are an evaluation assistant. You will be given:\n  - A question Q.\n  - A gold/reference answer (one or more short reference sentences).\n  - A candidate/sample answer produced by a system.\n\nYour job is to **assign integer scores** (1..5) for the following criteria comparing the *candidate* to the *gold/reference*:\n\n1. correctness (1-5): How factually correct is the candidate vs the gold answer? (5 = fully correct, 1 = mostly or fully incorrect).\n2. completeness (1-5): How completely does the candidate cover the key points in the gold answer? (5 = covers all key points; 1 = almost none).\n3. precision (1-5): How concise and focused is the candidate (not too long answer)? (5 = concise & precise; 1 = verbose / many extraneous claims).\n4. coherence (1-5): Is the candidate fluent and well-structured? (5 = natural, coherent; 1 = disfluent or incoherent).\n5. relevance (1-5): Are the statements in the candidate relevant to the question and gold answer (not introducing unrelated claims)? (5 = fully relevant; 1 = mostly irrelevant).\n\nREQUIREMENTS (strict):\n- Output **ONLY** a JSON object EXACTLY of the form:\n  {\"correctness\": <1-5>, \"completeness\": <1-5>, \"precision\": <1-5>, \"coherence\": <1-5>, \"relevance\": <1-5>}\n- No additional text, explanation, or whitespace outside the JSON object.\n\nFEW-SHOT EXAMPLE (this demonstrates the required output; do not include the example in actual responses):\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"No, the capital of Germany is not Paris, the capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":5,\"coherence\":5,\"relevance\":5}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"The capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":3,\"completeness\":2,\"precision\":5,\"coherence\":5,\"relevance\":2}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"If capital stands for the central administrative region of a country, then no, Paris is not the capital of Germany. It's important to note what is the definintion of a 'capital'. However, due to the common popular opinion, a capital of a country is well defined.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":1,\"coherence\":4,\"relevance\":1}\n\nEND OF SYSTEM PROMPT."}, {"role": "user", "content": [{"type": "text", "text": "Question: "}, {"type": "text", "text": "Gold reference 1: \"The exterior surface of the pyramid at the Rock and Roll Hall of Fame Museum in Cleveland, Ohio is made of glass.\""}, {"type": "text", "text": "Candidate answer: The exterior surface of the pyramid at the Rock and Roll Hall of Fame Museum is made of glass."}, {"type": "text", "text": "Please score the candidate exactly with the five integer ratings in JSON as instructed by the system prompt."}]}]}}
{"custom_id": "d5bd6e0c0dba11ecb1e81171463288e9_geval", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-mini-2025-04-14", "max_tokens": 200, "temperature": 1, "n": 20, "messages": [{"role": "system", "content": "You are an evaluation assistant. You will be given:\n  - A question Q.\n  - A gold/reference answer (one or more short reference sentences).\n  - A candidate/sample answer produced by a system.\n\nYour job is to **assign integer scores** (1..5) for the following criteria comparing the *candidate* to the *gold/reference*:\n\n1. correctness (1-5): How factually correct is the candidate vs the gold answer? (5 = fully correct, 1 = mostly or fully incorrect).\n2. completeness (1-5): How completely does the candidate cover the key points in the gold answer? (5 = covers all key points; 1 = almost none).\n3. precision (1-5): How concise and focused is the candidate (not too long answer)? (5 = concise & precise; 1 = verbose / many extraneous claims).\n4. coherence (1-5): Is the candidate fluent and well-structured? (5 = natural, coherent; 1 = disfluent or incoherent).\n5. relevance (1-5): Are the statements in the candidate relevant to the question and gold answer (not introducing unrelated claims)? (5 = fully relevant; 1 = mostly irrelevant).\n\nREQUIREMENTS (strict):\n- Output **ONLY** a JSON object EXACTLY of the form:\n  {\"correctness\": <1-5>, \"completeness\": <1-5>, \"precision\": <1-5>, \"coherence\": <1-5>, \"relevance\": <1-5>}\n- No additional text, explanation, or whitespace outside the JSON object.\n\nFEW-SHOT EXAMPLE (this demonstrates the required output; do not include the example in actual responses):\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"No, the capital of Germany is not Paris, the capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":5,\"coherence\":5,\"relevance\":5}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"The capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":3,\"completeness\":2,\"precision\":5,\"coherence\":5,\"relevance\":2}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"If capital stands for the central administrative region of a country, then no, Paris is not the capital of Germany. It's important to note what is the definintion of a 'capital'. However, due to the common popular opinion, a capital of a country is well defined.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":1,\"coherence\":4,\"relevance\":1}\n\nEND OF SYSTEM PROMPT."}, {"role": "user", "content": [{"type": "text", "text": "Question: "}, {"type": "text", "text": "Gold reference 1: \"The Place de la Concorde Ferris wheel has less than 40 spokes since only 36 exist.\""}, {"type": "text", "text": "Candidate answer: The Roue de Paris, installed at the Place de la Concorde, has 42 spokes."}, {"type": "text", "text": "Please score the candidate exactly with the five integer ratings in JSON as instructed by the system prompt."}]}]}}
{"custom_id": "d5bf9dee0dba11ecb1e81171463288e9_geval", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-mini-2025-04-14", "max_tokens": 200, "temperature": 1, "n": 20, "messages": [{"role": "system", "content": "You are an evaluation assistant. You will be given:\n  - A question Q.\n  - A gold/reference answer (one or more short reference sentences).\n  - A candidate/sample answer produced by a system.\n\nYour job is to **assign integer scores** (1..5) for the following criteria comparing the *candidate* to the *gold/reference*:\n\n1. correctness (1-5): How factually correct is the candidate vs the gold answer? (5 = fully correct, 1 = mostly or fully incorrect).\n2. completeness (1-5): How completely does the candidate cover the key points in the gold answer? (5 = covers all key points; 1 = almost none).\n3. precision (1-5): How concise and focused is the candidate (not too long answer)? (5 = concise & precise; 1 = verbose / many extraneous claims).\n4. coherence (1-5): Is the candidate fluent and well-structured? (5 = natural, coherent; 1 = disfluent or incoherent).\n5. relevance (1-5): Are the statements in the candidate relevant to the question and gold answer (not introducing unrelated claims)? (5 = fully relevant; 1 = mostly irrelevant).\n\nREQUIREMENTS (strict):\n- Output **ONLY** a JSON object EXACTLY of the form:\n  {\"correctness\": <1-5>, \"completeness\": <1-5>, \"precision\": <1-5>, \"coherence\": <1-5>, \"relevance\": <1-5>}\n- No additional text, explanation, or whitespace outside the JSON object.\n\nFEW-SHOT EXAMPLE (this demonstrates the required output; do not include the example in actual responses):\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"No, the capital of Germany is not Paris, the capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":5,\"coherence\":5,\"relevance\":5}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"The capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":3,\"completeness\":2,\"precision\":5,\"coherence\":5,\"relevance\":2}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"If capital stands for the central administrative region of a country, then no, Paris is not the capital of Germany. It's important to note what is the definintion of a 'capital'. However, due to the common popular opinion, a capital of a country is well defined.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":1,\"coherence\":4,\"relevance\":1}\n\nEND OF SYSTEM PROMPT."}, {"role": "user", "content": [{"type": "text", "text": "Question: "}, {"type": "text", "text": "Gold reference 1: \"On the cylindrical components of Harry Partch's Boo I bamboo marimba, a number is written upward on them in white.\""}, {"type": "text", "text": "Candidate answer: The upward facing side of each cylindrical component of Harry Partch's Boo I bamboo marimba has numbers written in white."}, {"type": "text", "text": "Please score the candidate exactly with the five integer ratings in JSON as instructed by the system prompt."}]}]}}
{"custom_id": "d5bf168a0dba11ecb1e81171463288e9_geval", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-mini-2025-04-14", "max_tokens": 200, "temperature": 1, "n": 20, "messages": [{"role": "system", "content": "You are an evaluation assistant. You will be given:\n  - A question Q.\n  - A gold/reference answer (one or more short reference sentences).\n  - A candidate/sample answer produced by a system.\n\nYour job is to **assign integer scores** (1..5) for the following criteria comparing the *candidate* to the *gold/reference*:\n\n1. correctness (1-5): How factually correct is the candidate vs the gold answer? (5 = fully correct, 1 = mostly or fully incorrect).\n2. completeness (1-5): How completely does the candidate cover the key points in the gold answer? (5 = covers all key points; 1 = almost none).\n3. precision (1-5): How concise and focused is the candidate (not too long answer)? (5 = concise & precise; 1 = verbose / many extraneous claims).\n4. coherence (1-5): Is the candidate fluent and well-structured? (5 = natural, coherent; 1 = disfluent or incoherent).\n5. relevance (1-5): Are the statements in the candidate relevant to the question and gold answer (not introducing unrelated claims)? (5 = fully relevant; 1 = mostly irrelevant).\n\nREQUIREMENTS (strict):\n- Output **ONLY** a JSON object EXACTLY of the form:\n  {\"correctness\": <1-5>, \"completeness\": <1-5>, \"precision\": <1-5>, \"coherence\": <1-5>, \"relevance\": <1-5>}\n- No additional text, explanation, or whitespace outside the JSON object.\n\nFEW-SHOT EXAMPLE (this demonstrates the required output; do not include the example in actual responses):\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"No, the capital of Germany is not Paris, the capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":5,\"coherence\":5,\"relevance\":5}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"The capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":3,\"completeness\":2,\"precision\":5,\"coherence\":5,\"relevance\":2}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"If capital stands for the central administrative region of a country, then no, Paris is not the capital of Germany. It's important to note what is the definintion of a 'capital'. However, due to the common popular opinion, a capital of a country is well defined.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":1,\"coherence\":4,\"relevance\":1}\n\nEND OF SYSTEM PROMPT."}, {"role": "user", "content": [{"type": "text", "text": "Question: "}, {"type": "text", "text": "Gold reference 1: \"The Lion of Venice sticks its tail farther out from its body.\""}, {"type": "text", "text": "Candidate answer: The Winged Lion of Generali has its tail sticking out farther from its body compared to the Lion of Venice."}, {"type": "text", "text": "Please score the candidate exactly with the five integer ratings in JSON as instructed by the system prompt."}]}]}}
{"custom_id": "d5be8c920dba11ecb1e81171463288e9_geval", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-mini-2025-04-14", "max_tokens": 200, "temperature": 1, "n": 20, "messages": [{"role": "system", "content": "You are an evaluation assistant. You will be given:\n  - A question Q.\n  - A gold/reference answer (one or more short reference sentences).\n  - A candidate/sample answer produced by a system.\n\nYour job is to **assign integer scores** (1..5) for the following criteria comparing the *candidate* to the *gold/reference*:\n\n1. correctness (1-5): How factually correct is the candidate vs the gold answer? (5 = fully correct, 1 = mostly or fully incorrect).\n2. completeness (1-5): How completely does the candidate cover the key points in the gold answer? (5 = covers all key points; 1 = almost none).\n3. precision (1-5): How concise and focused is the candidate (not too long answer)? (5 = concise & precise; 1 = verbose / many extraneous claims).\n4. coherence (1-5): Is the candidate fluent and well-structured? (5 = natural, coherent; 1 = disfluent or incoherent).\n5. relevance (1-5): Are the statements in the candidate relevant to the question and gold answer (not introducing unrelated claims)? (5 = fully relevant; 1 = mostly irrelevant).\n\nREQUIREMENTS (strict):\n- Output **ONLY** a JSON object EXACTLY of the form:\n  {\"correctness\": <1-5>, \"completeness\": <1-5>, \"precision\": <1-5>, \"coherence\": <1-5>, \"relevance\": <1-5>}\n- No additional text, explanation, or whitespace outside the JSON object.\n\nFEW-SHOT EXAMPLE (this demonstrates the required output; do not include the example in actual responses):\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"No, the capital of Germany is not Paris, the capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":5,\"coherence\":5,\"relevance\":5}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"The capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":3,\"completeness\":2,\"precision\":5,\"coherence\":5,\"relevance\":2}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"If capital stands for the central administrative region of a country, then no, Paris is not the capital of Germany. It's important to note what is the definintion of a 'capital'. However, due to the common popular opinion, a capital of a country is well defined.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":1,\"coherence\":4,\"relevance\":1}\n\nEND OF SYSTEM PROMPT."}, {"role": "user", "content": [{"type": "text", "text": "Question: "}, {"type": "text", "text": "Gold reference 1: \"The center of the forehead often has a jewel on it during Hindu Wedding ceremonies.\""}, {"type": "text", "text": "Candidate answer: The face part often bejeweled during Hindu wedding ceremonies is the forehead, typically adorned with a 'bindi'."}, {"type": "text", "text": "Please score the candidate exactly with the five integer ratings in JSON as instructed by the system prompt."}]}]}}
{"custom_id": "d5bf32460dba11ecb1e81171463288e9_geval", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-mini-2025-04-14", "max_tokens": 200, "temperature": 1, "n": 20, "messages": [{"role": "system", "content": "You are an evaluation assistant. You will be given:\n  - A question Q.\n  - A gold/reference answer (one or more short reference sentences).\n  - A candidate/sample answer produced by a system.\n\nYour job is to **assign integer scores** (1..5) for the following criteria comparing the *candidate* to the *gold/reference*:\n\n1. correctness (1-5): How factually correct is the candidate vs the gold answer? (5 = fully correct, 1 = mostly or fully incorrect).\n2. completeness (1-5): How completely does the candidate cover the key points in the gold answer? (5 = covers all key points; 1 = almost none).\n3. precision (1-5): How concise and focused is the candidate (not too long answer)? (5 = concise & precise; 1 = verbose / many extraneous claims).\n4. coherence (1-5): Is the candidate fluent and well-structured? (5 = natural, coherent; 1 = disfluent or incoherent).\n5. relevance (1-5): Are the statements in the candidate relevant to the question and gold answer (not introducing unrelated claims)? (5 = fully relevant; 1 = mostly irrelevant).\n\nREQUIREMENTS (strict):\n- Output **ONLY** a JSON object EXACTLY of the form:\n  {\"correctness\": <1-5>, \"completeness\": <1-5>, \"precision\": <1-5>, \"coherence\": <1-5>, \"relevance\": <1-5>}\n- No additional text, explanation, or whitespace outside the JSON object.\n\nFEW-SHOT EXAMPLE (this demonstrates the required output; do not include the example in actual responses):\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"No, the capital of Germany is not Paris, the capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":5,\"coherence\":5,\"relevance\":5}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"The capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":3,\"completeness\":2,\"precision\":5,\"coherence\":5,\"relevance\":2}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"If capital stands for the central administrative region of a country, then no, Paris is not the capital of Germany. It's important to note what is the definintion of a 'capital'. However, due to the common popular opinion, a capital of a country is well defined.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":1,\"coherence\":4,\"relevance\":1}\n\nEND OF SYSTEM PROMPT."}, {"role": "user", "content": [{"type": "text", "text": "Question: "}, {"type": "text", "text": "Gold reference 1: \"Center Street Apartments has more floors.\""}, {"type": "text", "text": "Candidate answer: The Center Street Apartments building has more floors than the Georgia Tech Student Center building."}, {"type": "text", "text": "Please score the candidate exactly with the five integer ratings in JSON as instructed by the system prompt."}]}]}}
{"custom_id": "d5befaec0dba11ecb1e81171463288e9_geval", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-mini-2025-04-14", "max_tokens": 200, "temperature": 1, "n": 20, "messages": [{"role": "system", "content": "You are an evaluation assistant. You will be given:\n  - A question Q.\n  - A gold/reference answer (one or more short reference sentences).\n  - A candidate/sample answer produced by a system.\n\nYour job is to **assign integer scores** (1..5) for the following criteria comparing the *candidate* to the *gold/reference*:\n\n1. correctness (1-5): How factually correct is the candidate vs the gold answer? (5 = fully correct, 1 = mostly or fully incorrect).\n2. completeness (1-5): How completely does the candidate cover the key points in the gold answer? (5 = covers all key points; 1 = almost none).\n3. precision (1-5): How concise and focused is the candidate (not too long answer)? (5 = concise & precise; 1 = verbose / many extraneous claims).\n4. coherence (1-5): Is the candidate fluent and well-structured? (5 = natural, coherent; 1 = disfluent or incoherent).\n5. relevance (1-5): Are the statements in the candidate relevant to the question and gold answer (not introducing unrelated claims)? (5 = fully relevant; 1 = mostly irrelevant).\n\nREQUIREMENTS (strict):\n- Output **ONLY** a JSON object EXACTLY of the form:\n  {\"correctness\": <1-5>, \"completeness\": <1-5>, \"precision\": <1-5>, \"coherence\": <1-5>, \"relevance\": <1-5>}\n- No additional text, explanation, or whitespace outside the JSON object.\n\nFEW-SHOT EXAMPLE (this demonstrates the required output; do not include the example in actual responses):\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"No, the capital of Germany is not Paris, the capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":5,\"coherence\":5,\"relevance\":5}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"The capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":3,\"completeness\":2,\"precision\":5,\"coherence\":5,\"relevance\":2}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"If capital stands for the central administrative region of a country, then no, Paris is not the capital of Germany. It's important to note what is the definintion of a 'capital'. However, due to the common popular opinion, a capital of a country is well defined.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":1,\"coherence\":4,\"relevance\":1}\n\nEND OF SYSTEM PROMPT."}, {"role": "user", "content": [{"type": "text", "text": "Question: "}, {"type": "text", "text": "Gold reference 1: \"No, the face of the building at Mayo Clinic & Med School with a raised rectangular roof doesn't have more windows than its adjacent face.\""}, {"type": "text", "text": "Candidate answer: The face of the Mayo Clinic & Med School building with a raised rectangular roof has more windows than its adjacent face."}, {"type": "text", "text": "Please score the candidate exactly with the five integer ratings in JSON as instructed by the system prompt."}]}]}}
{"custom_id": "d5bbd0920dba11ecb1e81171463288e9_geval", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-mini-2025-04-14", "max_tokens": 200, "temperature": 1, "n": 20, "messages": [{"role": "system", "content": "You are an evaluation assistant. You will be given:\n  - A question Q.\n  - A gold/reference answer (one or more short reference sentences).\n  - A candidate/sample answer produced by a system.\n\nYour job is to **assign integer scores** (1..5) for the following criteria comparing the *candidate* to the *gold/reference*:\n\n1. correctness (1-5): How factually correct is the candidate vs the gold answer? (5 = fully correct, 1 = mostly or fully incorrect).\n2. completeness (1-5): How completely does the candidate cover the key points in the gold answer? (5 = covers all key points; 1 = almost none).\n3. precision (1-5): How concise and focused is the candidate (not too long answer)? (5 = concise & precise; 1 = verbose / many extraneous claims).\n4. coherence (1-5): Is the candidate fluent and well-structured? (5 = natural, coherent; 1 = disfluent or incoherent).\n5. relevance (1-5): Are the statements in the candidate relevant to the question and gold answer (not introducing unrelated claims)? (5 = fully relevant; 1 = mostly irrelevant).\n\nREQUIREMENTS (strict):\n- Output **ONLY** a JSON object EXACTLY of the form:\n  {\"correctness\": <1-5>, \"completeness\": <1-5>, \"precision\": <1-5>, \"coherence\": <1-5>, \"relevance\": <1-5>}\n- No additional text, explanation, or whitespace outside the JSON object.\n\nFEW-SHOT EXAMPLE (this demonstrates the required output; do not include the example in actual responses):\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"No, the capital of Germany is not Paris, the capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":5,\"coherence\":5,\"relevance\":5}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"The capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":3,\"completeness\":2,\"precision\":5,\"coherence\":5,\"relevance\":2}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"If capital stands for the central administrative region of a country, then no, Paris is not the capital of Germany. It's important to note what is the definintion of a 'capital'. However, due to the common popular opinion, a capital of a country is well defined.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":1,\"coherence\":4,\"relevance\":1}\n\nEND OF SYSTEM PROMPT."}, {"role": "user", "content": [{"type": "text", "text": "Question: "}, {"type": "text", "text": "Gold reference 1: \"Tutankhamun's golden bed is resting on the floor.\""}, {"type": "text", "text": "Candidate answer: Tutankhamun's golden bed is resting on a base supported by two stylized animal figures."}, {"type": "text", "text": "Please score the candidate exactly with the five integer ratings in JSON as instructed by the system prompt."}]}]}}
{"custom_id": "d5be6d020dba11ecb1e81171463288e9_geval", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-mini-2025-04-14", "max_tokens": 200, "temperature": 1, "n": 20, "messages": [{"role": "system", "content": "You are an evaluation assistant. You will be given:\n  - A question Q.\n  - A gold/reference answer (one or more short reference sentences).\n  - A candidate/sample answer produced by a system.\n\nYour job is to **assign integer scores** (1..5) for the following criteria comparing the *candidate* to the *gold/reference*:\n\n1. correctness (1-5): How factually correct is the candidate vs the gold answer? (5 = fully correct, 1 = mostly or fully incorrect).\n2. completeness (1-5): How completely does the candidate cover the key points in the gold answer? (5 = covers all key points; 1 = almost none).\n3. precision (1-5): How concise and focused is the candidate (not too long answer)? (5 = concise & precise; 1 = verbose / many extraneous claims).\n4. coherence (1-5): Is the candidate fluent and well-structured? (5 = natural, coherent; 1 = disfluent or incoherent).\n5. relevance (1-5): Are the statements in the candidate relevant to the question and gold answer (not introducing unrelated claims)? (5 = fully relevant; 1 = mostly irrelevant).\n\nREQUIREMENTS (strict):\n- Output **ONLY** a JSON object EXACTLY of the form:\n  {\"correctness\": <1-5>, \"completeness\": <1-5>, \"precision\": <1-5>, \"coherence\": <1-5>, \"relevance\": <1-5>}\n- No additional text, explanation, or whitespace outside the JSON object.\n\nFEW-SHOT EXAMPLE (this demonstrates the required output; do not include the example in actual responses):\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"No, the capital of Germany is not Paris, the capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":5,\"coherence\":5,\"relevance\":5}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"The capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":3,\"completeness\":2,\"precision\":5,\"coherence\":5,\"relevance\":2}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"If capital stands for the central administrative region of a country, then no, Paris is not the capital of Germany. It's important to note what is the definintion of a 'capital'. However, due to the common popular opinion, a capital of a country is well defined.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":1,\"coherence\":4,\"relevance\":1}\n\nEND OF SYSTEM PROMPT."}, {"role": "user", "content": [{"type": "text", "text": "Question: "}, {"type": "text", "text": "Gold reference 1: \"It has no door windows.\""}, {"type": "text", "text": "Candidate answer: The 1954 MG TF 1250 has two door windows."}, {"type": "text", "text": "Please score the candidate exactly with the five integer ratings in JSON as instructed by the system prompt."}]}]}}
{"custom_id": "d5bce61c0dba11ecb1e81171463288e9_geval", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-mini-2025-04-14", "max_tokens": 200, "temperature": 1, "n": 20, "messages": [{"role": "system", "content": "You are an evaluation assistant. You will be given:\n  - A question Q.\n  - A gold/reference answer (one or more short reference sentences).\n  - A candidate/sample answer produced by a system.\n\nYour job is to **assign integer scores** (1..5) for the following criteria comparing the *candidate* to the *gold/reference*:\n\n1. correctness (1-5): How factually correct is the candidate vs the gold answer? (5 = fully correct, 1 = mostly or fully incorrect).\n2. completeness (1-5): How completely does the candidate cover the key points in the gold answer? (5 = covers all key points; 1 = almost none).\n3. precision (1-5): How concise and focused is the candidate (not too long answer)? (5 = concise & precise; 1 = verbose / many extraneous claims).\n4. coherence (1-5): Is the candidate fluent and well-structured? (5 = natural, coherent; 1 = disfluent or incoherent).\n5. relevance (1-5): Are the statements in the candidate relevant to the question and gold answer (not introducing unrelated claims)? (5 = fully relevant; 1 = mostly irrelevant).\n\nREQUIREMENTS (strict):\n- Output **ONLY** a JSON object EXACTLY of the form:\n  {\"correctness\": <1-5>, \"completeness\": <1-5>, \"precision\": <1-5>, \"coherence\": <1-5>, \"relevance\": <1-5>}\n- No additional text, explanation, or whitespace outside the JSON object.\n\nFEW-SHOT EXAMPLE (this demonstrates the required output; do not include the example in actual responses):\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"No, the capital of Germany is not Paris, the capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":5,\"coherence\":5,\"relevance\":5}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"The capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":3,\"completeness\":2,\"precision\":5,\"coherence\":5,\"relevance\":2}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"If capital stands for the central administrative region of a country, then no, Paris is not the capital of Germany. It's important to note what is the definintion of a 'capital'. However, due to the common popular opinion, a capital of a country is well defined.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":1,\"coherence\":4,\"relevance\":1}\n\nEND OF SYSTEM PROMPT."}, {"role": "user", "content": [{"type": "text", "text": "Question: "}, {"type": "text", "text": "Gold reference 1: \"Garibaldi features more body at Washington Square Park.\""}, {"type": "text", "text": "Candidate answer: The Garibaldi statue features more body than the Holley statue at Washington Square Park."}, {"type": "text", "text": "Please score the candidate exactly with the five integer ratings in JSON as instructed by the system prompt."}]}]}}
{"custom_id": "d5bf735a0dba11ecb1e81171463288e9_geval", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-mini-2025-04-14", "max_tokens": 200, "temperature": 1, "n": 20, "messages": [{"role": "system", "content": "You are an evaluation assistant. You will be given:\n  - A question Q.\n  - A gold/reference answer (one or more short reference sentences).\n  - A candidate/sample answer produced by a system.\n\nYour job is to **assign integer scores** (1..5) for the following criteria comparing the *candidate* to the *gold/reference*:\n\n1. correctness (1-5): How factually correct is the candidate vs the gold answer? (5 = fully correct, 1 = mostly or fully incorrect).\n2. completeness (1-5): How completely does the candidate cover the key points in the gold answer? (5 = covers all key points; 1 = almost none).\n3. precision (1-5): How concise and focused is the candidate (not too long answer)? (5 = concise & precise; 1 = verbose / many extraneous claims).\n4. coherence (1-5): Is the candidate fluent and well-structured? (5 = natural, coherent; 1 = disfluent or incoherent).\n5. relevance (1-5): Are the statements in the candidate relevant to the question and gold answer (not introducing unrelated claims)? (5 = fully relevant; 1 = mostly irrelevant).\n\nREQUIREMENTS (strict):\n- Output **ONLY** a JSON object EXACTLY of the form:\n  {\"correctness\": <1-5>, \"completeness\": <1-5>, \"precision\": <1-5>, \"coherence\": <1-5>, \"relevance\": <1-5>}\n- No additional text, explanation, or whitespace outside the JSON object.\n\nFEW-SHOT EXAMPLE (this demonstrates the required output; do not include the example in actual responses):\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"No, the capital of Germany is not Paris, the capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":5,\"coherence\":5,\"relevance\":5}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"The capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":3,\"completeness\":2,\"precision\":5,\"coherence\":5,\"relevance\":2}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"If capital stands for the central administrative region of a country, then no, Paris is not the capital of Germany. It's important to note what is the definintion of a 'capital'. However, due to the common popular opinion, a capital of a country is well defined.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":1,\"coherence\":4,\"relevance\":1}\n\nEND OF SYSTEM PROMPT."}, {"role": "user", "content": [{"type": "text", "text": "Question: "}, {"type": "text", "text": "Gold reference 1: \"No, Secession hall keep two plants in pots out front year round.\""}, {"type": "text", "text": "Candidate answer: Yes, Secession Hall keeps two plants in pots out front year-round."}, {"type": "text", "text": "Please score the candidate exactly with the five integer ratings in JSON as instructed by the system prompt."}]}]}}
{"custom_id": "d5bf75620dba11ecb1e81171463288e9_geval", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-mini-2025-04-14", "max_tokens": 200, "temperature": 1, "n": 20, "messages": [{"role": "system", "content": "You are an evaluation assistant. You will be given:\n  - A question Q.\n  - A gold/reference answer (one or more short reference sentences).\n  - A candidate/sample answer produced by a system.\n\nYour job is to **assign integer scores** (1..5) for the following criteria comparing the *candidate* to the *gold/reference*:\n\n1. correctness (1-5): How factually correct is the candidate vs the gold answer? (5 = fully correct, 1 = mostly or fully incorrect).\n2. completeness (1-5): How completely does the candidate cover the key points in the gold answer? (5 = covers all key points; 1 = almost none).\n3. precision (1-5): How concise and focused is the candidate (not too long answer)? (5 = concise & precise; 1 = verbose / many extraneous claims).\n4. coherence (1-5): Is the candidate fluent and well-structured? (5 = natural, coherent; 1 = disfluent or incoherent).\n5. relevance (1-5): Are the statements in the candidate relevant to the question and gold answer (not introducing unrelated claims)? (5 = fully relevant; 1 = mostly irrelevant).\n\nREQUIREMENTS (strict):\n- Output **ONLY** a JSON object EXACTLY of the form:\n  {\"correctness\": <1-5>, \"completeness\": <1-5>, \"precision\": <1-5>, \"coherence\": <1-5>, \"relevance\": <1-5>}\n- No additional text, explanation, or whitespace outside the JSON object.\n\nFEW-SHOT EXAMPLE (this demonstrates the required output; do not include the example in actual responses):\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"No, the capital of Germany is not Paris, the capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":5,\"coherence\":5,\"relevance\":5}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"The capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":3,\"completeness\":2,\"precision\":5,\"coherence\":5,\"relevance\":2}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"If capital stands for the central administrative region of a country, then no, Paris is not the capital of Germany. It's important to note what is the definintion of a 'capital'. However, due to the common popular opinion, a capital of a country is well defined.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":1,\"coherence\":4,\"relevance\":1}\n\nEND OF SYSTEM PROMPT."}, {"role": "user", "content": [{"type": "text", "text": "Question: "}, {"type": "text", "text": "Gold reference 1: \"No, stripes are not present in both the Schizophyllum commune and the Red-Juice Tooth Fungus.\""}, {"type": "text", "text": "Candidate answer: Yes, both Schizophyllum commune and the Red-Juice Tooth Fungus have striped appearances."}, {"type": "text", "text": "Please score the candidate exactly with the five integer ratings in JSON as instructed by the system prompt."}]}]}}
{"custom_id": "d5bfaff00dba11ecb1e81171463288e9_geval", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-mini-2025-04-14", "max_tokens": 200, "temperature": 1, "n": 20, "messages": [{"role": "system", "content": "You are an evaluation assistant. You will be given:\n  - A question Q.\n  - A gold/reference answer (one or more short reference sentences).\n  - A candidate/sample answer produced by a system.\n\nYour job is to **assign integer scores** (1..5) for the following criteria comparing the *candidate* to the *gold/reference*:\n\n1. correctness (1-5): How factually correct is the candidate vs the gold answer? (5 = fully correct, 1 = mostly or fully incorrect).\n2. completeness (1-5): How completely does the candidate cover the key points in the gold answer? (5 = covers all key points; 1 = almost none).\n3. precision (1-5): How concise and focused is the candidate (not too long answer)? (5 = concise & precise; 1 = verbose / many extraneous claims).\n4. coherence (1-5): Is the candidate fluent and well-structured? (5 = natural, coherent; 1 = disfluent or incoherent).\n5. relevance (1-5): Are the statements in the candidate relevant to the question and gold answer (not introducing unrelated claims)? (5 = fully relevant; 1 = mostly irrelevant).\n\nREQUIREMENTS (strict):\n- Output **ONLY** a JSON object EXACTLY of the form:\n  {\"correctness\": <1-5>, \"completeness\": <1-5>, \"precision\": <1-5>, \"coherence\": <1-5>, \"relevance\": <1-5>}\n- No additional text, explanation, or whitespace outside the JSON object.\n\nFEW-SHOT EXAMPLE (this demonstrates the required output; do not include the example in actual responses):\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"No, the capital of Germany is not Paris, the capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":5,\"coherence\":5,\"relevance\":5}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"The capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":3,\"completeness\":2,\"precision\":5,\"coherence\":5,\"relevance\":2}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"If capital stands for the central administrative region of a country, then no, Paris is not the capital of Germany. It's important to note what is the definintion of a 'capital'. However, due to the common popular opinion, a capital of a country is well defined.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":1,\"coherence\":4,\"relevance\":1}\n\nEND OF SYSTEM PROMPT."}, {"role": "user", "content": [{"type": "text", "text": "Question: "}, {"type": "text", "text": "Gold reference 1: \"The feathers at the abdomen of the Yellow-billed Kite and the Daurian redstart at Daisen Park in Osaka are both light brown.\""}, {"type": "text", "text": "Candidate answer: The abdomen feathers of the Yellow-billed Kite are brown, while the Daurian redstart has orange and black feathers at its abdomen."}, {"type": "text", "text": "Please score the candidate exactly with the five integer ratings in JSON as instructed by the system prompt."}]}]}}
{"custom_id": "d5bd96340dba11ecb1e81171463288e9_geval", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-mini-2025-04-14", "max_tokens": 200, "temperature": 1, "n": 20, "messages": [{"role": "system", "content": "You are an evaluation assistant. You will be given:\n  - A question Q.\n  - A gold/reference answer (one or more short reference sentences).\n  - A candidate/sample answer produced by a system.\n\nYour job is to **assign integer scores** (1..5) for the following criteria comparing the *candidate* to the *gold/reference*:\n\n1. correctness (1-5): How factually correct is the candidate vs the gold answer? (5 = fully correct, 1 = mostly or fully incorrect).\n2. completeness (1-5): How completely does the candidate cover the key points in the gold answer? (5 = covers all key points; 1 = almost none).\n3. precision (1-5): How concise and focused is the candidate (not too long answer)? (5 = concise & precise; 1 = verbose / many extraneous claims).\n4. coherence (1-5): Is the candidate fluent and well-structured? (5 = natural, coherent; 1 = disfluent or incoherent).\n5. relevance (1-5): Are the statements in the candidate relevant to the question and gold answer (not introducing unrelated claims)? (5 = fully relevant; 1 = mostly irrelevant).\n\nREQUIREMENTS (strict):\n- Output **ONLY** a JSON object EXACTLY of the form:\n  {\"correctness\": <1-5>, \"completeness\": <1-5>, \"precision\": <1-5>, \"coherence\": <1-5>, \"relevance\": <1-5>}\n- No additional text, explanation, or whitespace outside the JSON object.\n\nFEW-SHOT EXAMPLE (this demonstrates the required output; do not include the example in actual responses):\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"No, the capital of Germany is not Paris, the capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":5,\"coherence\":5,\"relevance\":5}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"The capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":3,\"completeness\":2,\"precision\":5,\"coherence\":5,\"relevance\":2}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"If capital stands for the central administrative region of a country, then no, Paris is not the capital of Germany. It's important to note what is the definintion of a 'capital'. However, due to the common popular opinion, a capital of a country is well defined.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":1,\"coherence\":4,\"relevance\":1}\n\nEND OF SYSTEM PROMPT."}, {"role": "user", "content": [{"type": "text", "text": "Question: "}, {"type": "text", "text": "Gold reference 1: \"No, the Lakeside Cafe in Heaton Park has fewer tables.\""}, {"type": "text", "text": "Candidate answer: The Lakeside Cafe in Heaton Park has outdoor seating, while the Bistro 1900 in Paris also has outdoor tables, but the exact number of tables at each location is not provided."}, {"type": "text", "text": "Please score the candidate exactly with the five integer ratings in JSON as instructed by the system prompt."}]}]}}
{"custom_id": "d5bf047e0dba11ecb1e81171463288e9_geval", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-mini-2025-04-14", "max_tokens": 200, "temperature": 1, "n": 20, "messages": [{"role": "system", "content": "You are an evaluation assistant. You will be given:\n  - A question Q.\n  - A gold/reference answer (one or more short reference sentences).\n  - A candidate/sample answer produced by a system.\n\nYour job is to **assign integer scores** (1..5) for the following criteria comparing the *candidate* to the *gold/reference*:\n\n1. correctness (1-5): How factually correct is the candidate vs the gold answer? (5 = fully correct, 1 = mostly or fully incorrect).\n2. completeness (1-5): How completely does the candidate cover the key points in the gold answer? (5 = covers all key points; 1 = almost none).\n3. precision (1-5): How concise and focused is the candidate (not too long answer)? (5 = concise & precise; 1 = verbose / many extraneous claims).\n4. coherence (1-5): Is the candidate fluent and well-structured? (5 = natural, coherent; 1 = disfluent or incoherent).\n5. relevance (1-5): Are the statements in the candidate relevant to the question and gold answer (not introducing unrelated claims)? (5 = fully relevant; 1 = mostly irrelevant).\n\nREQUIREMENTS (strict):\n- Output **ONLY** a JSON object EXACTLY of the form:\n  {\"correctness\": <1-5>, \"completeness\": <1-5>, \"precision\": <1-5>, \"coherence\": <1-5>, \"relevance\": <1-5>}\n- No additional text, explanation, or whitespace outside the JSON object.\n\nFEW-SHOT EXAMPLE (this demonstrates the required output; do not include the example in actual responses):\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"No, the capital of Germany is not Paris, the capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":5,\"coherence\":5,\"relevance\":5}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"The capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":3,\"completeness\":2,\"precision\":5,\"coherence\":5,\"relevance\":2}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"If capital stands for the central administrative region of a country, then no, Paris is not the capital of Germany. It's important to note what is the definintion of a 'capital'. However, due to the common popular opinion, a capital of a country is well defined.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":1,\"coherence\":4,\"relevance\":1}\n\nEND OF SYSTEM PROMPT."}, {"role": "user", "content": [{"type": "text", "text": "Question: "}, {"type": "text", "text": "Gold reference 1: \"The port of Barcelona has multiple structures jutting out into the water that have buildings on them.\""}, {"type": "text", "text": "Candidate answer: Yes, the port of Barcelona has multiple structures jutting out into the water, including buildings like the Maremagnum and various docks."}, {"type": "text", "text": "Please score the candidate exactly with the five integer ratings in JSON as instructed by the system prompt."}]}]}}
{"custom_id": "d5bf3e940dba11ecb1e81171463288e9_geval", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-mini-2025-04-14", "max_tokens": 200, "temperature": 1, "n": 20, "messages": [{"role": "system", "content": "You are an evaluation assistant. You will be given:\n  - A question Q.\n  - A gold/reference answer (one or more short reference sentences).\n  - A candidate/sample answer produced by a system.\n\nYour job is to **assign integer scores** (1..5) for the following criteria comparing the *candidate* to the *gold/reference*:\n\n1. correctness (1-5): How factually correct is the candidate vs the gold answer? (5 = fully correct, 1 = mostly or fully incorrect).\n2. completeness (1-5): How completely does the candidate cover the key points in the gold answer? (5 = covers all key points; 1 = almost none).\n3. precision (1-5): How concise and focused is the candidate (not too long answer)? (5 = concise & precise; 1 = verbose / many extraneous claims).\n4. coherence (1-5): Is the candidate fluent and well-structured? (5 = natural, coherent; 1 = disfluent or incoherent).\n5. relevance (1-5): Are the statements in the candidate relevant to the question and gold answer (not introducing unrelated claims)? (5 = fully relevant; 1 = mostly irrelevant).\n\nREQUIREMENTS (strict):\n- Output **ONLY** a JSON object EXACTLY of the form:\n  {\"correctness\": <1-5>, \"completeness\": <1-5>, \"precision\": <1-5>, \"coherence\": <1-5>, \"relevance\": <1-5>}\n- No additional text, explanation, or whitespace outside the JSON object.\n\nFEW-SHOT EXAMPLE (this demonstrates the required output; do not include the example in actual responses):\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"No, the capital of Germany is not Paris, the capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":5,\"coherence\":5,\"relevance\":5}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"The capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":3,\"completeness\":2,\"precision\":5,\"coherence\":5,\"relevance\":2}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"If capital stands for the central administrative region of a country, then no, Paris is not the capital of Germany. It's important to note what is the definintion of a 'capital'. However, due to the common popular opinion, a capital of a country is well defined.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":1,\"coherence\":4,\"relevance\":1}\n\nEND OF SYSTEM PROMPT."}, {"role": "user", "content": [{"type": "text", "text": "Question: "}, {"type": "text", "text": "Gold reference 1: \"More of the building on the corner of King William St-Gracechurch St is grey than green.\""}, {"type": "text", "text": "Candidate answer: The building on the corner of King William St-Gracechurch St appears to be more grey than green."}, {"type": "text", "text": "Please score the candidate exactly with the five integer ratings in JSON as instructed by the system prompt."}]}]}}
{"custom_id": "d5bf33220dba11ecb1e81171463288e9_geval", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-mini-2025-04-14", "max_tokens": 200, "temperature": 1, "n": 20, "messages": [{"role": "system", "content": "You are an evaluation assistant. You will be given:\n  - A question Q.\n  - A gold/reference answer (one or more short reference sentences).\n  - A candidate/sample answer produced by a system.\n\nYour job is to **assign integer scores** (1..5) for the following criteria comparing the *candidate* to the *gold/reference*:\n\n1. correctness (1-5): How factually correct is the candidate vs the gold answer? (5 = fully correct, 1 = mostly or fully incorrect).\n2. completeness (1-5): How completely does the candidate cover the key points in the gold answer? (5 = covers all key points; 1 = almost none).\n3. precision (1-5): How concise and focused is the candidate (not too long answer)? (5 = concise & precise; 1 = verbose / many extraneous claims).\n4. coherence (1-5): Is the candidate fluent and well-structured? (5 = natural, coherent; 1 = disfluent or incoherent).\n5. relevance (1-5): Are the statements in the candidate relevant to the question and gold answer (not introducing unrelated claims)? (5 = fully relevant; 1 = mostly irrelevant).\n\nREQUIREMENTS (strict):\n- Output **ONLY** a JSON object EXACTLY of the form:\n  {\"correctness\": <1-5>, \"completeness\": <1-5>, \"precision\": <1-5>, \"coherence\": <1-5>, \"relevance\": <1-5>}\n- No additional text, explanation, or whitespace outside the JSON object.\n\nFEW-SHOT EXAMPLE (this demonstrates the required output; do not include the example in actual responses):\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"No, the capital of Germany is not Paris, the capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":5,\"coherence\":5,\"relevance\":5}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"The capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":3,\"completeness\":2,\"precision\":5,\"coherence\":5,\"relevance\":2}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"If capital stands for the central administrative region of a country, then no, Paris is not the capital of Germany. It's important to note what is the definintion of a 'capital'. However, due to the common popular opinion, a capital of a country is well defined.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":1,\"coherence\":4,\"relevance\":1}\n\nEND OF SYSTEM PROMPT."}, {"role": "user", "content": [{"type": "text", "text": "Question: "}, {"type": "text", "text": "Gold reference 1: \"Both the highest and the widest windows on Beacon Dutch Reformed Church have a circle shape.\""}, {"type": "text", "text": "Candidate answer: Both the highest and the widest windows on Beacon Dutch Reformed Church are pointed arch-shaped."}, {"type": "text", "text": "Please score the candidate exactly with the five integer ratings in JSON as instructed by the system prompt."}]}]}}
{"custom_id": "d5bf497a0dba11ecb1e81171463288e9_geval", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-mini-2025-04-14", "max_tokens": 200, "temperature": 1, "n": 20, "messages": [{"role": "system", "content": "You are an evaluation assistant. You will be given:\n  - A question Q.\n  - A gold/reference answer (one or more short reference sentences).\n  - A candidate/sample answer produced by a system.\n\nYour job is to **assign integer scores** (1..5) for the following criteria comparing the *candidate* to the *gold/reference*:\n\n1. correctness (1-5): How factually correct is the candidate vs the gold answer? (5 = fully correct, 1 = mostly or fully incorrect).\n2. completeness (1-5): How completely does the candidate cover the key points in the gold answer? (5 = covers all key points; 1 = almost none).\n3. precision (1-5): How concise and focused is the candidate (not too long answer)? (5 = concise & precise; 1 = verbose / many extraneous claims).\n4. coherence (1-5): Is the candidate fluent and well-structured? (5 = natural, coherent; 1 = disfluent or incoherent).\n5. relevance (1-5): Are the statements in the candidate relevant to the question and gold answer (not introducing unrelated claims)? (5 = fully relevant; 1 = mostly irrelevant).\n\nREQUIREMENTS (strict):\n- Output **ONLY** a JSON object EXACTLY of the form:\n  {\"correctness\": <1-5>, \"completeness\": <1-5>, \"precision\": <1-5>, \"coherence\": <1-5>, \"relevance\": <1-5>}\n- No additional text, explanation, or whitespace outside the JSON object.\n\nFEW-SHOT EXAMPLE (this demonstrates the required output; do not include the example in actual responses):\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"No, the capital of Germany is not Paris, the capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":5,\"coherence\":5,\"relevance\":5}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"The capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":3,\"completeness\":2,\"precision\":5,\"coherence\":5,\"relevance\":2}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"If capital stands for the central administrative region of a country, then no, Paris is not the capital of Germany. It's important to note what is the definintion of a 'capital'. However, due to the common popular opinion, a capital of a country is well defined.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":1,\"coherence\":4,\"relevance\":1}\n\nEND OF SYSTEM PROMPT."}, {"role": "user", "content": [{"type": "text", "text": "Question: "}, {"type": "text", "text": "Gold reference 1: \"The insect on top of the pink flower resting on the table in \"Flowers in a Vase\" by Henriette Geertruida Knip is a butterfly.\""}, {"type": "text", "text": "Candidate answer: The insect on top of the pink flower in Henriette Geertruida Knip's painting titled 'Flowers in a Vase' is a butterfly."}, {"type": "text", "text": "Please score the candidate exactly with the five integer ratings in JSON as instructed by the system prompt."}]}]}}
{"custom_id": "d5bf21e80dba11ecb1e81171463288e9_geval", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-mini-2025-04-14", "max_tokens": 200, "temperature": 1, "n": 20, "messages": [{"role": "system", "content": "You are an evaluation assistant. You will be given:\n  - A question Q.\n  - A gold/reference answer (one or more short reference sentences).\n  - A candidate/sample answer produced by a system.\n\nYour job is to **assign integer scores** (1..5) for the following criteria comparing the *candidate* to the *gold/reference*:\n\n1. correctness (1-5): How factually correct is the candidate vs the gold answer? (5 = fully correct, 1 = mostly or fully incorrect).\n2. completeness (1-5): How completely does the candidate cover the key points in the gold answer? (5 = covers all key points; 1 = almost none).\n3. precision (1-5): How concise and focused is the candidate (not too long answer)? (5 = concise & precise; 1 = verbose / many extraneous claims).\n4. coherence (1-5): Is the candidate fluent and well-structured? (5 = natural, coherent; 1 = disfluent or incoherent).\n5. relevance (1-5): Are the statements in the candidate relevant to the question and gold answer (not introducing unrelated claims)? (5 = fully relevant; 1 = mostly irrelevant).\n\nREQUIREMENTS (strict):\n- Output **ONLY** a JSON object EXACTLY of the form:\n  {\"correctness\": <1-5>, \"completeness\": <1-5>, \"precision\": <1-5>, \"coherence\": <1-5>, \"relevance\": <1-5>}\n- No additional text, explanation, or whitespace outside the JSON object.\n\nFEW-SHOT EXAMPLE (this demonstrates the required output; do not include the example in actual responses):\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"No, the capital of Germany is not Paris, the capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":5,\"coherence\":5,\"relevance\":5}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"The capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":3,\"completeness\":2,\"precision\":5,\"coherence\":5,\"relevance\":2}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"If capital stands for the central administrative region of a country, then no, Paris is not the capital of Germany. It's important to note what is the definintion of a 'capital'. However, due to the common popular opinion, a capital of a country is well defined.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":1,\"coherence\":4,\"relevance\":1}\n\nEND OF SYSTEM PROMPT."}, {"role": "user", "content": [{"type": "text", "text": "Question: "}, {"type": "text", "text": "Gold reference 1: \"The phrase \"Hot. Cool. Yours.\" is displayed twice on the front of the Fisht 2014 Olympic stadium in Sochi.\""}, {"type": "text", "text": "Candidate answer: The phrase \"Hot. Cool. Yours.\" is displayed three times on the front of the Fisht Olympic Stadium in Sochi."}, {"type": "text", "text": "Please score the candidate exactly with the five integer ratings in JSON as instructed by the system prompt."}]}]}}
{"custom_id": "d5bc01de0dba11ecb1e81171463288e9_geval", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-mini-2025-04-14", "max_tokens": 200, "temperature": 1, "n": 20, "messages": [{"role": "system", "content": "You are an evaluation assistant. You will be given:\n  - A question Q.\n  - A gold/reference answer (one or more short reference sentences).\n  - A candidate/sample answer produced by a system.\n\nYour job is to **assign integer scores** (1..5) for the following criteria comparing the *candidate* to the *gold/reference*:\n\n1. correctness (1-5): How factually correct is the candidate vs the gold answer? (5 = fully correct, 1 = mostly or fully incorrect).\n2. completeness (1-5): How completely does the candidate cover the key points in the gold answer? (5 = covers all key points; 1 = almost none).\n3. precision (1-5): How concise and focused is the candidate (not too long answer)? (5 = concise & precise; 1 = verbose / many extraneous claims).\n4. coherence (1-5): Is the candidate fluent and well-structured? (5 = natural, coherent; 1 = disfluent or incoherent).\n5. relevance (1-5): Are the statements in the candidate relevant to the question and gold answer (not introducing unrelated claims)? (5 = fully relevant; 1 = mostly irrelevant).\n\nREQUIREMENTS (strict):\n- Output **ONLY** a JSON object EXACTLY of the form:\n  {\"correctness\": <1-5>, \"completeness\": <1-5>, \"precision\": <1-5>, \"coherence\": <1-5>, \"relevance\": <1-5>}\n- No additional text, explanation, or whitespace outside the JSON object.\n\nFEW-SHOT EXAMPLE (this demonstrates the required output; do not include the example in actual responses):\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"No, the capital of Germany is not Paris, the capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":5,\"coherence\":5,\"relevance\":5}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"The capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":3,\"completeness\":2,\"precision\":5,\"coherence\":5,\"relevance\":2}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"If capital stands for the central administrative region of a country, then no, Paris is not the capital of Germany. It's important to note what is the definintion of a 'capital'. However, due to the common popular opinion, a capital of a country is well defined.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":1,\"coherence\":4,\"relevance\":1}\n\nEND OF SYSTEM PROMPT."}, {"role": "user", "content": [{"type": "text", "text": "Question: "}, {"type": "text", "text": "Gold reference 1: \"The letters in the New Westfield logo are red.\""}, {"type": "text", "text": "Candidate answer: The letters in the New Westfield logo are red."}, {"type": "text", "text": "Please score the candidate exactly with the five integer ratings in JSON as instructed by the system prompt."}]}]}}
{"custom_id": "d5bcebb20dba11ecb1e81171463288e9_geval", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-mini-2025-04-14", "max_tokens": 200, "temperature": 1, "n": 20, "messages": [{"role": "system", "content": "You are an evaluation assistant. You will be given:\n  - A question Q.\n  - A gold/reference answer (one or more short reference sentences).\n  - A candidate/sample answer produced by a system.\n\nYour job is to **assign integer scores** (1..5) for the following criteria comparing the *candidate* to the *gold/reference*:\n\n1. correctness (1-5): How factually correct is the candidate vs the gold answer? (5 = fully correct, 1 = mostly or fully incorrect).\n2. completeness (1-5): How completely does the candidate cover the key points in the gold answer? (5 = covers all key points; 1 = almost none).\n3. precision (1-5): How concise and focused is the candidate (not too long answer)? (5 = concise & precise; 1 = verbose / many extraneous claims).\n4. coherence (1-5): Is the candidate fluent and well-structured? (5 = natural, coherent; 1 = disfluent or incoherent).\n5. relevance (1-5): Are the statements in the candidate relevant to the question and gold answer (not introducing unrelated claims)? (5 = fully relevant; 1 = mostly irrelevant).\n\nREQUIREMENTS (strict):\n- Output **ONLY** a JSON object EXACTLY of the form:\n  {\"correctness\": <1-5>, \"completeness\": <1-5>, \"precision\": <1-5>, \"coherence\": <1-5>, \"relevance\": <1-5>}\n- No additional text, explanation, or whitespace outside the JSON object.\n\nFEW-SHOT EXAMPLE (this demonstrates the required output; do not include the example in actual responses):\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"No, the capital of Germany is not Paris, the capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":5,\"coherence\":5,\"relevance\":5}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"The capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":3,\"completeness\":2,\"precision\":5,\"coherence\":5,\"relevance\":2}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"If capital stands for the central administrative region of a country, then no, Paris is not the capital of Germany. It's important to note what is the definintion of a 'capital'. However, due to the common popular opinion, a capital of a country is well defined.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":1,\"coherence\":4,\"relevance\":1}\n\nEND OF SYSTEM PROMPT."}, {"role": "user", "content": [{"type": "text", "text": "Question: "}, {"type": "text", "text": "Gold reference 1: \"No, the view from the top of Mori Tower is mostly of an urban area.\""}, {"type": "text", "text": "Candidate answer: No, the view from the top of Mori Tower is mostly of an urban area."}, {"type": "text", "text": "Please score the candidate exactly with the five integer ratings in JSON as instructed by the system prompt."}]}]}}
{"custom_id": "d5bf09920dba11ecb1e81171463288e9_geval", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-mini-2025-04-14", "max_tokens": 200, "temperature": 1, "n": 20, "messages": [{"role": "system", "content": "You are an evaluation assistant. You will be given:\n  - A question Q.\n  - A gold/reference answer (one or more short reference sentences).\n  - A candidate/sample answer produced by a system.\n\nYour job is to **assign integer scores** (1..5) for the following criteria comparing the *candidate* to the *gold/reference*:\n\n1. correctness (1-5): How factually correct is the candidate vs the gold answer? (5 = fully correct, 1 = mostly or fully incorrect).\n2. completeness (1-5): How completely does the candidate cover the key points in the gold answer? (5 = covers all key points; 1 = almost none).\n3. precision (1-5): How concise and focused is the candidate (not too long answer)? (5 = concise & precise; 1 = verbose / many extraneous claims).\n4. coherence (1-5): Is the candidate fluent and well-structured? (5 = natural, coherent; 1 = disfluent or incoherent).\n5. relevance (1-5): Are the statements in the candidate relevant to the question and gold answer (not introducing unrelated claims)? (5 = fully relevant; 1 = mostly irrelevant).\n\nREQUIREMENTS (strict):\n- Output **ONLY** a JSON object EXACTLY of the form:\n  {\"correctness\": <1-5>, \"completeness\": <1-5>, \"precision\": <1-5>, \"coherence\": <1-5>, \"relevance\": <1-5>}\n- No additional text, explanation, or whitespace outside the JSON object.\n\nFEW-SHOT EXAMPLE (this demonstrates the required output; do not include the example in actual responses):\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"No, the capital of Germany is not Paris, the capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":5,\"coherence\":5,\"relevance\":5}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"The capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":3,\"completeness\":2,\"precision\":5,\"coherence\":5,\"relevance\":2}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"If capital stands for the central administrative region of a country, then no, Paris is not the capital of Germany. It's important to note what is the definintion of a 'capital'. However, due to the common popular opinion, a capital of a country is well defined.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":1,\"coherence\":4,\"relevance\":1}\n\nEND OF SYSTEM PROMPT."}, {"role": "user", "content": [{"type": "text", "text": "Question: "}, {"type": "text", "text": "Gold reference 1: \"No, both don't have an awning in the front.\""}, {"type": "text", "text": "Candidate answer: Yes, both 9 Market Square and 29 Market Square in Knoxville have an awning in the front."}, {"type": "text", "text": "Please score the candidate exactly with the five integer ratings in JSON as instructed by the system prompt."}]}]}}
{"custom_id": "d5bf8ea80dba11ecb1e81171463288e9_geval", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-mini-2025-04-14", "max_tokens": 200, "temperature": 1, "n": 20, "messages": [{"role": "system", "content": "You are an evaluation assistant. You will be given:\n  - A question Q.\n  - A gold/reference answer (one or more short reference sentences).\n  - A candidate/sample answer produced by a system.\n\nYour job is to **assign integer scores** (1..5) for the following criteria comparing the *candidate* to the *gold/reference*:\n\n1. correctness (1-5): How factually correct is the candidate vs the gold answer? (5 = fully correct, 1 = mostly or fully incorrect).\n2. completeness (1-5): How completely does the candidate cover the key points in the gold answer? (5 = covers all key points; 1 = almost none).\n3. precision (1-5): How concise and focused is the candidate (not too long answer)? (5 = concise & precise; 1 = verbose / many extraneous claims).\n4. coherence (1-5): Is the candidate fluent and well-structured? (5 = natural, coherent; 1 = disfluent or incoherent).\n5. relevance (1-5): Are the statements in the candidate relevant to the question and gold answer (not introducing unrelated claims)? (5 = fully relevant; 1 = mostly irrelevant).\n\nREQUIREMENTS (strict):\n- Output **ONLY** a JSON object EXACTLY of the form:\n  {\"correctness\": <1-5>, \"completeness\": <1-5>, \"precision\": <1-5>, \"coherence\": <1-5>, \"relevance\": <1-5>}\n- No additional text, explanation, or whitespace outside the JSON object.\n\nFEW-SHOT EXAMPLE (this demonstrates the required output; do not include the example in actual responses):\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"No, the capital of Germany is not Paris, the capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":5,\"coherence\":5,\"relevance\":5}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"The capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":3,\"completeness\":2,\"precision\":5,\"coherence\":5,\"relevance\":2}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"If capital stands for the central administrative region of a country, then no, Paris is not the capital of Germany. It's important to note what is the definintion of a 'capital'. However, due to the common popular opinion, a capital of a country is well defined.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":1,\"coherence\":4,\"relevance\":1}\n\nEND OF SYSTEM PROMPT."}, {"role": "user", "content": [{"type": "text", "text": "Question: "}, {"type": "text", "text": "Gold reference 1: \"Nicotinia sylvestris has lighter colored blossoms than the Red Azalea Flower.\""}, {"type": "text", "text": "Candidate answer: Nicotinia sylvestris has lighter colored blossoms compared to the Red Azalea Flower."}, {"type": "text", "text": "Please score the candidate exactly with the five integer ratings in JSON as instructed by the system prompt."}]}]}}
{"custom_id": "d5be7f220dba11ecb1e81171463288e9_geval", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-mini-2025-04-14", "max_tokens": 200, "temperature": 1, "n": 20, "messages": [{"role": "system", "content": "You are an evaluation assistant. You will be given:\n  - A question Q.\n  - A gold/reference answer (one or more short reference sentences).\n  - A candidate/sample answer produced by a system.\n\nYour job is to **assign integer scores** (1..5) for the following criteria comparing the *candidate* to the *gold/reference*:\n\n1. correctness (1-5): How factually correct is the candidate vs the gold answer? (5 = fully correct, 1 = mostly or fully incorrect).\n2. completeness (1-5): How completely does the candidate cover the key points in the gold answer? (5 = covers all key points; 1 = almost none).\n3. precision (1-5): How concise and focused is the candidate (not too long answer)? (5 = concise & precise; 1 = verbose / many extraneous claims).\n4. coherence (1-5): Is the candidate fluent and well-structured? (5 = natural, coherent; 1 = disfluent or incoherent).\n5. relevance (1-5): Are the statements in the candidate relevant to the question and gold answer (not introducing unrelated claims)? (5 = fully relevant; 1 = mostly irrelevant).\n\nREQUIREMENTS (strict):\n- Output **ONLY** a JSON object EXACTLY of the form:\n  {\"correctness\": <1-5>, \"completeness\": <1-5>, \"precision\": <1-5>, \"coherence\": <1-5>, \"relevance\": <1-5>}\n- No additional text, explanation, or whitespace outside the JSON object.\n\nFEW-SHOT EXAMPLE (this demonstrates the required output; do not include the example in actual responses):\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"No, the capital of Germany is not Paris, the capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":5,\"coherence\":5,\"relevance\":5}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"The capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":3,\"completeness\":2,\"precision\":5,\"coherence\":5,\"relevance\":2}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"If capital stands for the central administrative region of a country, then no, Paris is not the capital of Germany. It's important to note what is the definintion of a 'capital'. However, due to the common popular opinion, a capital of a country is well defined.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":1,\"coherence\":4,\"relevance\":1}\n\nEND OF SYSTEM PROMPT."}, {"role": "user", "content": [{"type": "text", "text": "Question: "}, {"type": "text", "text": "Gold reference 1: \"A crossbody bag strap may be seen on the woman's right hand on the Mary Seacole statue at St Thomas' Hospital.\""}, {"type": "text", "text": "Candidate answer: In the woman's right hand on the Mary Seacole statue at St Thomas' Hospital, she holds a small bag."}, {"type": "text", "text": "Please score the candidate exactly with the five integer ratings in JSON as instructed by the system prompt."}]}]}}
{"custom_id": "d5bf97c20dba11ecb1e81171463288e9_geval", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-mini-2025-04-14", "max_tokens": 200, "temperature": 1, "n": 20, "messages": [{"role": "system", "content": "You are an evaluation assistant. You will be given:\n  - A question Q.\n  - A gold/reference answer (one or more short reference sentences).\n  - A candidate/sample answer produced by a system.\n\nYour job is to **assign integer scores** (1..5) for the following criteria comparing the *candidate* to the *gold/reference*:\n\n1. correctness (1-5): How factually correct is the candidate vs the gold answer? (5 = fully correct, 1 = mostly or fully incorrect).\n2. completeness (1-5): How completely does the candidate cover the key points in the gold answer? (5 = covers all key points; 1 = almost none).\n3. precision (1-5): How concise and focused is the candidate (not too long answer)? (5 = concise & precise; 1 = verbose / many extraneous claims).\n4. coherence (1-5): Is the candidate fluent and well-structured? (5 = natural, coherent; 1 = disfluent or incoherent).\n5. relevance (1-5): Are the statements in the candidate relevant to the question and gold answer (not introducing unrelated claims)? (5 = fully relevant; 1 = mostly irrelevant).\n\nREQUIREMENTS (strict):\n- Output **ONLY** a JSON object EXACTLY of the form:\n  {\"correctness\": <1-5>, \"completeness\": <1-5>, \"precision\": <1-5>, \"coherence\": <1-5>, \"relevance\": <1-5>}\n- No additional text, explanation, or whitespace outside the JSON object.\n\nFEW-SHOT EXAMPLE (this demonstrates the required output; do not include the example in actual responses):\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"No, the capital of Germany is not Paris, the capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":5,\"coherence\":5,\"relevance\":5}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"The capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":3,\"completeness\":2,\"precision\":5,\"coherence\":5,\"relevance\":2}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"If capital stands for the central administrative region of a country, then no, Paris is not the capital of Germany. It's important to note what is the definintion of a 'capital'. However, due to the common popular opinion, a capital of a country is well defined.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":1,\"coherence\":4,\"relevance\":1}\n\nEND OF SYSTEM PROMPT."}, {"role": "user", "content": [{"type": "text", "text": "Question: "}, {"type": "text", "text": "Gold reference 1: \"On the Salisbury Cathedral the gargoyle appears to be biting what the left cheek of a human face.\""}, {"type": "text", "text": "Candidate answer: The gargoyle on Salisbury Cathedral appears to be biting the cheek of a human face."}, {"type": "text", "text": "Please score the candidate exactly with the five integer ratings in JSON as instructed by the system prompt."}]}]}}
{"custom_id": "d5bc0bb60dba11ecb1e81171463288e9_geval", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-mini-2025-04-14", "max_tokens": 200, "temperature": 1, "n": 20, "messages": [{"role": "system", "content": "You are an evaluation assistant. You will be given:\n  - A question Q.\n  - A gold/reference answer (one or more short reference sentences).\n  - A candidate/sample answer produced by a system.\n\nYour job is to **assign integer scores** (1..5) for the following criteria comparing the *candidate* to the *gold/reference*:\n\n1. correctness (1-5): How factually correct is the candidate vs the gold answer? (5 = fully correct, 1 = mostly or fully incorrect).\n2. completeness (1-5): How completely does the candidate cover the key points in the gold answer? (5 = covers all key points; 1 = almost none).\n3. precision (1-5): How concise and focused is the candidate (not too long answer)? (5 = concise & precise; 1 = verbose / many extraneous claims).\n4. coherence (1-5): Is the candidate fluent and well-structured? (5 = natural, coherent; 1 = disfluent or incoherent).\n5. relevance (1-5): Are the statements in the candidate relevant to the question and gold answer (not introducing unrelated claims)? (5 = fully relevant; 1 = mostly irrelevant).\n\nREQUIREMENTS (strict):\n- Output **ONLY** a JSON object EXACTLY of the form:\n  {\"correctness\": <1-5>, \"completeness\": <1-5>, \"precision\": <1-5>, \"coherence\": <1-5>, \"relevance\": <1-5>}\n- No additional text, explanation, or whitespace outside the JSON object.\n\nFEW-SHOT EXAMPLE (this demonstrates the required output; do not include the example in actual responses):\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"No, the capital of Germany is not Paris, the capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":5,\"coherence\":5,\"relevance\":5}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"The capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":3,\"completeness\":2,\"precision\":5,\"coherence\":5,\"relevance\":2}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"If capital stands for the central administrative region of a country, then no, Paris is not the capital of Germany. It's important to note what is the definintion of a 'capital'. However, due to the common popular opinion, a capital of a country is well defined.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":1,\"coherence\":4,\"relevance\":1}\n\nEND OF SYSTEM PROMPT."}, {"role": "user", "content": [{"type": "text", "text": "Question: "}, {"type": "text", "text": "Gold reference 1: \"Yes, they have a bluish tint.\""}, {"type": "text", "text": "Candidate answer: The clouds in 'A Cherub Head in Different Views' appear to have a more bluish tint compared to those in 'Heads of Angels'."}, {"type": "text", "text": "Please score the candidate exactly with the five integer ratings in JSON as instructed by the system prompt."}]}]}}
{"custom_id": "d5bc49640dba11ecb1e81171463288e9_geval", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-mini-2025-04-14", "max_tokens": 200, "temperature": 1, "n": 20, "messages": [{"role": "system", "content": "You are an evaluation assistant. You will be given:\n  - A question Q.\n  - A gold/reference answer (one or more short reference sentences).\n  - A candidate/sample answer produced by a system.\n\nYour job is to **assign integer scores** (1..5) for the following criteria comparing the *candidate* to the *gold/reference*:\n\n1. correctness (1-5): How factually correct is the candidate vs the gold answer? (5 = fully correct, 1 = mostly or fully incorrect).\n2. completeness (1-5): How completely does the candidate cover the key points in the gold answer? (5 = covers all key points; 1 = almost none).\n3. precision (1-5): How concise and focused is the candidate (not too long answer)? (5 = concise & precise; 1 = verbose / many extraneous claims).\n4. coherence (1-5): Is the candidate fluent and well-structured? (5 = natural, coherent; 1 = disfluent or incoherent).\n5. relevance (1-5): Are the statements in the candidate relevant to the question and gold answer (not introducing unrelated claims)? (5 = fully relevant; 1 = mostly irrelevant).\n\nREQUIREMENTS (strict):\n- Output **ONLY** a JSON object EXACTLY of the form:\n  {\"correctness\": <1-5>, \"completeness\": <1-5>, \"precision\": <1-5>, \"coherence\": <1-5>, \"relevance\": <1-5>}\n- No additional text, explanation, or whitespace outside the JSON object.\n\nFEW-SHOT EXAMPLE (this demonstrates the required output; do not include the example in actual responses):\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"No, the capital of Germany is not Paris, the capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":5,\"coherence\":5,\"relevance\":5}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"The capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":3,\"completeness\":2,\"precision\":5,\"coherence\":5,\"relevance\":2}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"If capital stands for the central administrative region of a country, then no, Paris is not the capital of Germany. It's important to note what is the definintion of a 'capital'. However, due to the common popular opinion, a capital of a country is well defined.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":1,\"coherence\":4,\"relevance\":1}\n\nEND OF SYSTEM PROMPT."}, {"role": "user", "content": [{"type": "text", "text": "Question: "}, {"type": "text", "text": "Gold reference 1: \"Stars decorate the front of the Barrowland Ballroom.\""}, {"type": "text", "text": "Candidate answer: The front of the Barrowland Ballroom is decorated with stars."}, {"type": "text", "text": "Please score the candidate exactly with the five integer ratings in JSON as instructed by the system prompt."}]}]}}
{"custom_id": "d5bc7a740dba11ecb1e81171463288e9_geval", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-mini-2025-04-14", "max_tokens": 200, "temperature": 1, "n": 20, "messages": [{"role": "system", "content": "You are an evaluation assistant. You will be given:\n  - A question Q.\n  - A gold/reference answer (one or more short reference sentences).\n  - A candidate/sample answer produced by a system.\n\nYour job is to **assign integer scores** (1..5) for the following criteria comparing the *candidate* to the *gold/reference*:\n\n1. correctness (1-5): How factually correct is the candidate vs the gold answer? (5 = fully correct, 1 = mostly or fully incorrect).\n2. completeness (1-5): How completely does the candidate cover the key points in the gold answer? (5 = covers all key points; 1 = almost none).\n3. precision (1-5): How concise and focused is the candidate (not too long answer)? (5 = concise & precise; 1 = verbose / many extraneous claims).\n4. coherence (1-5): Is the candidate fluent and well-structured? (5 = natural, coherent; 1 = disfluent or incoherent).\n5. relevance (1-5): Are the statements in the candidate relevant to the question and gold answer (not introducing unrelated claims)? (5 = fully relevant; 1 = mostly irrelevant).\n\nREQUIREMENTS (strict):\n- Output **ONLY** a JSON object EXACTLY of the form:\n  {\"correctness\": <1-5>, \"completeness\": <1-5>, \"precision\": <1-5>, \"coherence\": <1-5>, \"relevance\": <1-5>}\n- No additional text, explanation, or whitespace outside the JSON object.\n\nFEW-SHOT EXAMPLE (this demonstrates the required output; do not include the example in actual responses):\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"No, the capital of Germany is not Paris, the capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":5,\"coherence\":5,\"relevance\":5}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"The capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":3,\"completeness\":2,\"precision\":5,\"coherence\":5,\"relevance\":2}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"If capital stands for the central administrative region of a country, then no, Paris is not the capital of Germany. It's important to note what is the definintion of a 'capital'. However, due to the common popular opinion, a capital of a country is well defined.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":1,\"coherence\":4,\"relevance\":1}\n\nEND OF SYSTEM PROMPT."}, {"role": "user", "content": [{"type": "text", "text": "Question: "}, {"type": "text", "text": "Gold reference 1: \"The Oriental Pearl Harbor's light system at night is customizable.\""}, {"type": "text", "text": "Candidate answer: The Oriental Pearl Tower's light system at night is customizable."}, {"type": "text", "text": "Please score the candidate exactly with the five integer ratings in JSON as instructed by the system prompt."}]}]}}
{"custom_id": "d5bc11b00dba11ecb1e81171463288e9_geval", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-mini-2025-04-14", "max_tokens": 200, "temperature": 1, "n": 20, "messages": [{"role": "system", "content": "You are an evaluation assistant. You will be given:\n  - A question Q.\n  - A gold/reference answer (one or more short reference sentences).\n  - A candidate/sample answer produced by a system.\n\nYour job is to **assign integer scores** (1..5) for the following criteria comparing the *candidate* to the *gold/reference*:\n\n1. correctness (1-5): How factually correct is the candidate vs the gold answer? (5 = fully correct, 1 = mostly or fully incorrect).\n2. completeness (1-5): How completely does the candidate cover the key points in the gold answer? (5 = covers all key points; 1 = almost none).\n3. precision (1-5): How concise and focused is the candidate (not too long answer)? (5 = concise & precise; 1 = verbose / many extraneous claims).\n4. coherence (1-5): Is the candidate fluent and well-structured? (5 = natural, coherent; 1 = disfluent or incoherent).\n5. relevance (1-5): Are the statements in the candidate relevant to the question and gold answer (not introducing unrelated claims)? (5 = fully relevant; 1 = mostly irrelevant).\n\nREQUIREMENTS (strict):\n- Output **ONLY** a JSON object EXACTLY of the form:\n  {\"correctness\": <1-5>, \"completeness\": <1-5>, \"precision\": <1-5>, \"coherence\": <1-5>, \"relevance\": <1-5>}\n- No additional text, explanation, or whitespace outside the JSON object.\n\nFEW-SHOT EXAMPLE (this demonstrates the required output; do not include the example in actual responses):\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"No, the capital of Germany is not Paris, the capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":5,\"coherence\":5,\"relevance\":5}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"The capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":3,\"completeness\":2,\"precision\":5,\"coherence\":5,\"relevance\":2}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"If capital stands for the central administrative region of a country, then no, Paris is not the capital of Germany. It's important to note what is the definintion of a 'capital'. However, due to the common popular opinion, a capital of a country is well defined.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":1,\"coherence\":4,\"relevance\":1}\n\nEND OF SYSTEM PROMPT."}, {"role": "user", "content": [{"type": "text", "text": "Question: "}, {"type": "text", "text": "Gold reference 1: \"The tops of the pavilions in Washington St Park are not all identical.\""}, {"type": "text", "text": "Candidate answer: The tops of the pavilions in Washington St Park are not all identical, as they feature different designs."}, {"type": "text", "text": "Please score the candidate exactly with the five integer ratings in JSON as instructed by the system prompt."}]}]}}
{"custom_id": "d5bcb8fe0dba11ecb1e81171463288e9_geval", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-mini-2025-04-14", "max_tokens": 200, "temperature": 1, "n": 20, "messages": [{"role": "system", "content": "You are an evaluation assistant. You will be given:\n  - A question Q.\n  - A gold/reference answer (one or more short reference sentences).\n  - A candidate/sample answer produced by a system.\n\nYour job is to **assign integer scores** (1..5) for the following criteria comparing the *candidate* to the *gold/reference*:\n\n1. correctness (1-5): How factually correct is the candidate vs the gold answer? (5 = fully correct, 1 = mostly or fully incorrect).\n2. completeness (1-5): How completely does the candidate cover the key points in the gold answer? (5 = covers all key points; 1 = almost none).\n3. precision (1-5): How concise and focused is the candidate (not too long answer)? (5 = concise & precise; 1 = verbose / many extraneous claims).\n4. coherence (1-5): Is the candidate fluent and well-structured? (5 = natural, coherent; 1 = disfluent or incoherent).\n5. relevance (1-5): Are the statements in the candidate relevant to the question and gold answer (not introducing unrelated claims)? (5 = fully relevant; 1 = mostly irrelevant).\n\nREQUIREMENTS (strict):\n- Output **ONLY** a JSON object EXACTLY of the form:\n  {\"correctness\": <1-5>, \"completeness\": <1-5>, \"precision\": <1-5>, \"coherence\": <1-5>, \"relevance\": <1-5>}\n- No additional text, explanation, or whitespace outside the JSON object.\n\nFEW-SHOT EXAMPLE (this demonstrates the required output; do not include the example in actual responses):\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"No, the capital of Germany is not Paris, the capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":5,\"coherence\":5,\"relevance\":5}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"The capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":3,\"completeness\":2,\"precision\":5,\"coherence\":5,\"relevance\":2}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"If capital stands for the central administrative region of a country, then no, Paris is not the capital of Germany. It's important to note what is the definintion of a 'capital'. However, due to the common popular opinion, a capital of a country is well defined.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":1,\"coherence\":4,\"relevance\":1}\n\nEND OF SYSTEM PROMPT."}, {"role": "user", "content": [{"type": "text", "text": "Question: "}, {"type": "text", "text": "Gold reference 1: \"Yes you can see skyscrapers behind the Modular Cactus sculpture.\""}, {"type": "text", "text": "Candidate answer: Yes, there are skyscraper buildings around the Modular Cactus sculpture."}, {"type": "text", "text": "Please score the candidate exactly with the five integer ratings in JSON as instructed by the system prompt."}]}]}}
{"custom_id": "d5bbf5220dba11ecb1e81171463288e9_geval", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-mini-2025-04-14", "max_tokens": 200, "temperature": 1, "n": 20, "messages": [{"role": "system", "content": "You are an evaluation assistant. You will be given:\n  - A question Q.\n  - A gold/reference answer (one or more short reference sentences).\n  - A candidate/sample answer produced by a system.\n\nYour job is to **assign integer scores** (1..5) for the following criteria comparing the *candidate* to the *gold/reference*:\n\n1. correctness (1-5): How factually correct is the candidate vs the gold answer? (5 = fully correct, 1 = mostly or fully incorrect).\n2. completeness (1-5): How completely does the candidate cover the key points in the gold answer? (5 = covers all key points; 1 = almost none).\n3. precision (1-5): How concise and focused is the candidate (not too long answer)? (5 = concise & precise; 1 = verbose / many extraneous claims).\n4. coherence (1-5): Is the candidate fluent and well-structured? (5 = natural, coherent; 1 = disfluent or incoherent).\n5. relevance (1-5): Are the statements in the candidate relevant to the question and gold answer (not introducing unrelated claims)? (5 = fully relevant; 1 = mostly irrelevant).\n\nREQUIREMENTS (strict):\n- Output **ONLY** a JSON object EXACTLY of the form:\n  {\"correctness\": <1-5>, \"completeness\": <1-5>, \"precision\": <1-5>, \"coherence\": <1-5>, \"relevance\": <1-5>}\n- No additional text, explanation, or whitespace outside the JSON object.\n\nFEW-SHOT EXAMPLE (this demonstrates the required output; do not include the example in actual responses):\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"No, the capital of Germany is not Paris, the capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":5,\"coherence\":5,\"relevance\":5}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"The capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":3,\"completeness\":2,\"precision\":5,\"coherence\":5,\"relevance\":2}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"If capital stands for the central administrative region of a country, then no, Paris is not the capital of Germany. It's important to note what is the definintion of a 'capital'. However, due to the common popular opinion, a capital of a country is well defined.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":1,\"coherence\":4,\"relevance\":1}\n\nEND OF SYSTEM PROMPT."}, {"role": "user", "content": [{"type": "text", "text": "Question: "}, {"type": "text", "text": "Gold reference 1: \"Ski athletes wear their numbers on their abdomen during competitions.\""}, {"type": "text", "text": "Candidate answer: Ski athletes wear their numbers on their competition suits during events."}, {"type": "text", "text": "Please score the candidate exactly with the five integer ratings in JSON as instructed by the system prompt."}]}]}}
{"custom_id": "d5be1c760dba11ecb1e81171463288e9_geval", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-mini-2025-04-14", "max_tokens": 200, "temperature": 1, "n": 20, "messages": [{"role": "system", "content": "You are an evaluation assistant. You will be given:\n  - A question Q.\n  - A gold/reference answer (one or more short reference sentences).\n  - A candidate/sample answer produced by a system.\n\nYour job is to **assign integer scores** (1..5) for the following criteria comparing the *candidate* to the *gold/reference*:\n\n1. correctness (1-5): How factually correct is the candidate vs the gold answer? (5 = fully correct, 1 = mostly or fully incorrect).\n2. completeness (1-5): How completely does the candidate cover the key points in the gold answer? (5 = covers all key points; 1 = almost none).\n3. precision (1-5): How concise and focused is the candidate (not too long answer)? (5 = concise & precise; 1 = verbose / many extraneous claims).\n4. coherence (1-5): Is the candidate fluent and well-structured? (5 = natural, coherent; 1 = disfluent or incoherent).\n5. relevance (1-5): Are the statements in the candidate relevant to the question and gold answer (not introducing unrelated claims)? (5 = fully relevant; 1 = mostly irrelevant).\n\nREQUIREMENTS (strict):\n- Output **ONLY** a JSON object EXACTLY of the form:\n  {\"correctness\": <1-5>, \"completeness\": <1-5>, \"precision\": <1-5>, \"coherence\": <1-5>, \"relevance\": <1-5>}\n- No additional text, explanation, or whitespace outside the JSON object.\n\nFEW-SHOT EXAMPLE (this demonstrates the required output; do not include the example in actual responses):\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"No, the capital of Germany is not Paris, the capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":5,\"coherence\":5,\"relevance\":5}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"The capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":3,\"completeness\":2,\"precision\":5,\"coherence\":5,\"relevance\":2}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"If capital stands for the central administrative region of a country, then no, Paris is not the capital of Germany. It's important to note what is the definintion of a 'capital'. However, due to the common popular opinion, a capital of a country is well defined.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":1,\"coherence\":4,\"relevance\":1}\n\nEND OF SYSTEM PROMPT."}, {"role": "user", "content": [{"type": "text", "text": "Question: "}, {"type": "text", "text": "Gold reference 1: \"The logo on China Merchants Bank Tower is red and silver .\""}, {"type": "text", "text": "Candidate answer: The logo on the China Merchants Bank Tower is red."}, {"type": "text", "text": "Please score the candidate exactly with the five integer ratings in JSON as instructed by the system prompt."}]}]}}
{"custom_id": "d5bd63580dba11ecb1e81171463288e9_geval", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-mini-2025-04-14", "max_tokens": 200, "temperature": 1, "n": 20, "messages": [{"role": "system", "content": "You are an evaluation assistant. You will be given:\n  - A question Q.\n  - A gold/reference answer (one or more short reference sentences).\n  - A candidate/sample answer produced by a system.\n\nYour job is to **assign integer scores** (1..5) for the following criteria comparing the *candidate* to the *gold/reference*:\n\n1. correctness (1-5): How factually correct is the candidate vs the gold answer? (5 = fully correct, 1 = mostly or fully incorrect).\n2. completeness (1-5): How completely does the candidate cover the key points in the gold answer? (5 = covers all key points; 1 = almost none).\n3. precision (1-5): How concise and focused is the candidate (not too long answer)? (5 = concise & precise; 1 = verbose / many extraneous claims).\n4. coherence (1-5): Is the candidate fluent and well-structured? (5 = natural, coherent; 1 = disfluent or incoherent).\n5. relevance (1-5): Are the statements in the candidate relevant to the question and gold answer (not introducing unrelated claims)? (5 = fully relevant; 1 = mostly irrelevant).\n\nREQUIREMENTS (strict):\n- Output **ONLY** a JSON object EXACTLY of the form:\n  {\"correctness\": <1-5>, \"completeness\": <1-5>, \"precision\": <1-5>, \"coherence\": <1-5>, \"relevance\": <1-5>}\n- No additional text, explanation, or whitespace outside the JSON object.\n\nFEW-SHOT EXAMPLE (this demonstrates the required output; do not include the example in actual responses):\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"No, the capital of Germany is not Paris, the capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":5,\"coherence\":5,\"relevance\":5}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"The capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":3,\"completeness\":2,\"precision\":5,\"coherence\":5,\"relevance\":2}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"If capital stands for the central administrative region of a country, then no, Paris is not the capital of Germany. It's important to note what is the definintion of a 'capital'. However, due to the common popular opinion, a capital of a country is well defined.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":1,\"coherence\":4,\"relevance\":1}\n\nEND OF SYSTEM PROMPT."}, {"role": "user", "content": [{"type": "text", "text": "Question: "}, {"type": "text", "text": "Gold reference 1: \"When you move inland from the coast in Big Sur, the increase in elevation is rapid.\""}, {"type": "text", "text": "Candidate answer: The increase in elevation as you move inland from the coast in Big Sur is generally gradual."}, {"type": "text", "text": "Please score the candidate exactly with the five integer ratings in JSON as instructed by the system prompt."}]}]}}
{"custom_id": "d5bfabae0dba11ecb1e81171463288e9_geval", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-mini-2025-04-14", "max_tokens": 200, "temperature": 1, "n": 20, "messages": [{"role": "system", "content": "You are an evaluation assistant. You will be given:\n  - A question Q.\n  - A gold/reference answer (one or more short reference sentences).\n  - A candidate/sample answer produced by a system.\n\nYour job is to **assign integer scores** (1..5) for the following criteria comparing the *candidate* to the *gold/reference*:\n\n1. correctness (1-5): How factually correct is the candidate vs the gold answer? (5 = fully correct, 1 = mostly or fully incorrect).\n2. completeness (1-5): How completely does the candidate cover the key points in the gold answer? (5 = covers all key points; 1 = almost none).\n3. precision (1-5): How concise and focused is the candidate (not too long answer)? (5 = concise & precise; 1 = verbose / many extraneous claims).\n4. coherence (1-5): Is the candidate fluent and well-structured? (5 = natural, coherent; 1 = disfluent or incoherent).\n5. relevance (1-5): Are the statements in the candidate relevant to the question and gold answer (not introducing unrelated claims)? (5 = fully relevant; 1 = mostly irrelevant).\n\nREQUIREMENTS (strict):\n- Output **ONLY** a JSON object EXACTLY of the form:\n  {\"correctness\": <1-5>, \"completeness\": <1-5>, \"precision\": <1-5>, \"coherence\": <1-5>, \"relevance\": <1-5>}\n- No additional text, explanation, or whitespace outside the JSON object.\n\nFEW-SHOT EXAMPLE (this demonstrates the required output; do not include the example in actual responses):\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"No, the capital of Germany is not Paris, the capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":5,\"coherence\":5,\"relevance\":5}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"The capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":3,\"completeness\":2,\"precision\":5,\"coherence\":5,\"relevance\":2}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"If capital stands for the central administrative region of a country, then no, Paris is not the capital of Germany. It's important to note what is the definintion of a 'capital'. However, due to the common popular opinion, a capital of a country is well defined.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":1,\"coherence\":4,\"relevance\":1}\n\nEND OF SYSTEM PROMPT."}, {"role": "user", "content": [{"type": "text", "text": "Question: "}, {"type": "text", "text": "Gold reference 1: \"The middle of the three flags in front of Stasiun Monorel Bukit Bintang is the US flag.\""}, {"type": "text", "text": "Candidate answer: The US flag is in the middle position among the three flags in front of Stasiun Monorel Bukit Bintang."}, {"type": "text", "text": "Please score the candidate exactly with the five integer ratings in JSON as instructed by the system prompt."}]}]}}
{"custom_id": "d5bd02000dba11ecb1e81171463288e9_geval", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-mini-2025-04-14", "max_tokens": 200, "temperature": 1, "n": 20, "messages": [{"role": "system", "content": "You are an evaluation assistant. You will be given:\n  - A question Q.\n  - A gold/reference answer (one or more short reference sentences).\n  - A candidate/sample answer produced by a system.\n\nYour job is to **assign integer scores** (1..5) for the following criteria comparing the *candidate* to the *gold/reference*:\n\n1. correctness (1-5): How factually correct is the candidate vs the gold answer? (5 = fully correct, 1 = mostly or fully incorrect).\n2. completeness (1-5): How completely does the candidate cover the key points in the gold answer? (5 = covers all key points; 1 = almost none).\n3. precision (1-5): How concise and focused is the candidate (not too long answer)? (5 = concise & precise; 1 = verbose / many extraneous claims).\n4. coherence (1-5): Is the candidate fluent and well-structured? (5 = natural, coherent; 1 = disfluent or incoherent).\n5. relevance (1-5): Are the statements in the candidate relevant to the question and gold answer (not introducing unrelated claims)? (5 = fully relevant; 1 = mostly irrelevant).\n\nREQUIREMENTS (strict):\n- Output **ONLY** a JSON object EXACTLY of the form:\n  {\"correctness\": <1-5>, \"completeness\": <1-5>, \"precision\": <1-5>, \"coherence\": <1-5>, \"relevance\": <1-5>}\n- No additional text, explanation, or whitespace outside the JSON object.\n\nFEW-SHOT EXAMPLE (this demonstrates the required output; do not include the example in actual responses):\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"No, the capital of Germany is not Paris, the capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":5,\"coherence\":5,\"relevance\":5}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"The capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":3,\"completeness\":2,\"precision\":5,\"coherence\":5,\"relevance\":2}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"If capital stands for the central administrative region of a country, then no, Paris is not the capital of Germany. It's important to note what is the definintion of a 'capital'. However, due to the common popular opinion, a capital of a country is well defined.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":1,\"coherence\":4,\"relevance\":1}\n\nEND OF SYSTEM PROMPT."}, {"role": "user", "content": [{"type": "text", "text": "Question: "}, {"type": "text", "text": "Gold reference 1: \"There are four halos present in Andrea Di Bartolo's Christ on the Road to Calvary.\""}, {"type": "text", "text": "Candidate answer: Andrea Di Bartolo's 'Christ on the Road to Calvary' features three halos."}, {"type": "text", "text": "Please score the candidate exactly with the five integer ratings in JSON as instructed by the system prompt."}]}]}}
{"custom_id": "d5bd63da0dba11ecb1e81171463288e9_geval", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-mini-2025-04-14", "max_tokens": 200, "temperature": 1, "n": 20, "messages": [{"role": "system", "content": "You are an evaluation assistant. You will be given:\n  - A question Q.\n  - A gold/reference answer (one or more short reference sentences).\n  - A candidate/sample answer produced by a system.\n\nYour job is to **assign integer scores** (1..5) for the following criteria comparing the *candidate* to the *gold/reference*:\n\n1. correctness (1-5): How factually correct is the candidate vs the gold answer? (5 = fully correct, 1 = mostly or fully incorrect).\n2. completeness (1-5): How completely does the candidate cover the key points in the gold answer? (5 = covers all key points; 1 = almost none).\n3. precision (1-5): How concise and focused is the candidate (not too long answer)? (5 = concise & precise; 1 = verbose / many extraneous claims).\n4. coherence (1-5): Is the candidate fluent and well-structured? (5 = natural, coherent; 1 = disfluent or incoherent).\n5. relevance (1-5): Are the statements in the candidate relevant to the question and gold answer (not introducing unrelated claims)? (5 = fully relevant; 1 = mostly irrelevant).\n\nREQUIREMENTS (strict):\n- Output **ONLY** a JSON object EXACTLY of the form:\n  {\"correctness\": <1-5>, \"completeness\": <1-5>, \"precision\": <1-5>, \"coherence\": <1-5>, \"relevance\": <1-5>}\n- No additional text, explanation, or whitespace outside the JSON object.\n\nFEW-SHOT EXAMPLE (this demonstrates the required output; do not include the example in actual responses):\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"No, the capital of Germany is not Paris, the capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":5,\"coherence\":5,\"relevance\":5}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"The capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":3,\"completeness\":2,\"precision\":5,\"coherence\":5,\"relevance\":2}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"If capital stands for the central administrative region of a country, then no, Paris is not the capital of Germany. It's important to note what is the definintion of a 'capital'. However, due to the common popular opinion, a capital of a country is well defined.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":1,\"coherence\":4,\"relevance\":1}\n\nEND OF SYSTEM PROMPT."}, {"role": "user", "content": [{"type": "text", "text": "Question: "}, {"type": "text", "text": "Gold reference 1: \"Trees grow near both Antilia Tower in Mumbai, India and McNears Beach Park.\""}, {"type": "text", "text": "Candidate answer: Palm trees grow near both Antilia Tower in Mumbai and McNears Beach Park."}, {"type": "text", "text": "Please score the candidate exactly with the five integer ratings in JSON as instructed by the system prompt."}]}]}}
{"custom_id": "d5bc7be60dba11ecb1e81171463288e9_geval", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-mini-2025-04-14", "max_tokens": 200, "temperature": 1, "n": 20, "messages": [{"role": "system", "content": "You are an evaluation assistant. You will be given:\n  - A question Q.\n  - A gold/reference answer (one or more short reference sentences).\n  - A candidate/sample answer produced by a system.\n\nYour job is to **assign integer scores** (1..5) for the following criteria comparing the *candidate* to the *gold/reference*:\n\n1. correctness (1-5): How factually correct is the candidate vs the gold answer? (5 = fully correct, 1 = mostly or fully incorrect).\n2. completeness (1-5): How completely does the candidate cover the key points in the gold answer? (5 = covers all key points; 1 = almost none).\n3. precision (1-5): How concise and focused is the candidate (not too long answer)? (5 = concise & precise; 1 = verbose / many extraneous claims).\n4. coherence (1-5): Is the candidate fluent and well-structured? (5 = natural, coherent; 1 = disfluent or incoherent).\n5. relevance (1-5): Are the statements in the candidate relevant to the question and gold answer (not introducing unrelated claims)? (5 = fully relevant; 1 = mostly irrelevant).\n\nREQUIREMENTS (strict):\n- Output **ONLY** a JSON object EXACTLY of the form:\n  {\"correctness\": <1-5>, \"completeness\": <1-5>, \"precision\": <1-5>, \"coherence\": <1-5>, \"relevance\": <1-5>}\n- No additional text, explanation, or whitespace outside the JSON object.\n\nFEW-SHOT EXAMPLE (this demonstrates the required output; do not include the example in actual responses):\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"No, the capital of Germany is not Paris, the capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":5,\"coherence\":5,\"relevance\":5}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"The capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":3,\"completeness\":2,\"precision\":5,\"coherence\":5,\"relevance\":2}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"If capital stands for the central administrative region of a country, then no, Paris is not the capital of Germany. It's important to note what is the definintion of a 'capital'. However, due to the common popular opinion, a capital of a country is well defined.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":1,\"coherence\":4,\"relevance\":1}\n\nEND OF SYSTEM PROMPT."}, {"role": "user", "content": [{"type": "text", "text": "Question: "}, {"type": "text", "text": "Gold reference 1: \"All the flames in the 2010 Olympic Cauldron of Vancouver aren't equidistant.\""}, {"type": "text", "text": "Candidate answer: No, the flames in the 2010 Olympic Cauldron of Vancouver are not equidistant; the design features five arms with flames positioned at varying distances."}, {"type": "text", "text": "Please score the candidate exactly with the five integer ratings in JSON as instructed by the system prompt."}]}]}}
{"custom_id": "d5bea6e60dba11ecb1e81171463288e9_geval", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-mini-2025-04-14", "max_tokens": 200, "temperature": 1, "n": 20, "messages": [{"role": "system", "content": "You are an evaluation assistant. You will be given:\n  - A question Q.\n  - A gold/reference answer (one or more short reference sentences).\n  - A candidate/sample answer produced by a system.\n\nYour job is to **assign integer scores** (1..5) for the following criteria comparing the *candidate* to the *gold/reference*:\n\n1. correctness (1-5): How factually correct is the candidate vs the gold answer? (5 = fully correct, 1 = mostly or fully incorrect).\n2. completeness (1-5): How completely does the candidate cover the key points in the gold answer? (5 = covers all key points; 1 = almost none).\n3. precision (1-5): How concise and focused is the candidate (not too long answer)? (5 = concise & precise; 1 = verbose / many extraneous claims).\n4. coherence (1-5): Is the candidate fluent and well-structured? (5 = natural, coherent; 1 = disfluent or incoherent).\n5. relevance (1-5): Are the statements in the candidate relevant to the question and gold answer (not introducing unrelated claims)? (5 = fully relevant; 1 = mostly irrelevant).\n\nREQUIREMENTS (strict):\n- Output **ONLY** a JSON object EXACTLY of the form:\n  {\"correctness\": <1-5>, \"completeness\": <1-5>, \"precision\": <1-5>, \"coherence\": <1-5>, \"relevance\": <1-5>}\n- No additional text, explanation, or whitespace outside the JSON object.\n\nFEW-SHOT EXAMPLE (this demonstrates the required output; do not include the example in actual responses):\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"No, the capital of Germany is not Paris, the capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":5,\"coherence\":5,\"relevance\":5}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"The capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":3,\"completeness\":2,\"precision\":5,\"coherence\":5,\"relevance\":2}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"If capital stands for the central administrative region of a country, then no, Paris is not the capital of Germany. It's important to note what is the definintion of a 'capital'. However, due to the common popular opinion, a capital of a country is well defined.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":1,\"coherence\":4,\"relevance\":1}\n\nEND OF SYSTEM PROMPT."}, {"role": "user", "content": [{"type": "text", "text": "Question: "}, {"type": "text", "text": "Gold reference 1: \"There is one street lamp by the pool beside the the Navy Pier Chicago.\""}, {"type": "text", "text": "Candidate answer: There are no specific details provided about the number of street lamps by the pool at Navy Pier."}, {"type": "text", "text": "Please score the candidate exactly with the five integer ratings in JSON as instructed by the system prompt."}]}]}}
{"custom_id": "d5bdd4460dba11ecb1e81171463288e9_geval", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-mini-2025-04-14", "max_tokens": 200, "temperature": 1, "n": 20, "messages": [{"role": "system", "content": "You are an evaluation assistant. You will be given:\n  - A question Q.\n  - A gold/reference answer (one or more short reference sentences).\n  - A candidate/sample answer produced by a system.\n\nYour job is to **assign integer scores** (1..5) for the following criteria comparing the *candidate* to the *gold/reference*:\n\n1. correctness (1-5): How factually correct is the candidate vs the gold answer? (5 = fully correct, 1 = mostly or fully incorrect).\n2. completeness (1-5): How completely does the candidate cover the key points in the gold answer? (5 = covers all key points; 1 = almost none).\n3. precision (1-5): How concise and focused is the candidate (not too long answer)? (5 = concise & precise; 1 = verbose / many extraneous claims).\n4. coherence (1-5): Is the candidate fluent and well-structured? (5 = natural, coherent; 1 = disfluent or incoherent).\n5. relevance (1-5): Are the statements in the candidate relevant to the question and gold answer (not introducing unrelated claims)? (5 = fully relevant; 1 = mostly irrelevant).\n\nREQUIREMENTS (strict):\n- Output **ONLY** a JSON object EXACTLY of the form:\n  {\"correctness\": <1-5>, \"completeness\": <1-5>, \"precision\": <1-5>, \"coherence\": <1-5>, \"relevance\": <1-5>}\n- No additional text, explanation, or whitespace outside the JSON object.\n\nFEW-SHOT EXAMPLE (this demonstrates the required output; do not include the example in actual responses):\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"No, the capital of Germany is not Paris, the capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":5,\"coherence\":5,\"relevance\":5}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"The capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":3,\"completeness\":2,\"precision\":5,\"coherence\":5,\"relevance\":2}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"If capital stands for the central administrative region of a country, then no, Paris is not the capital of Germany. It's important to note what is the definintion of a 'capital'. However, due to the common popular opinion, a capital of a country is well defined.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":1,\"coherence\":4,\"relevance\":1}\n\nEND OF SYSTEM PROMPT."}, {"role": "user", "content": [{"type": "text", "text": "Question: "}, {"type": "text", "text": "Gold reference 1: \"Yes, they have the same concrete exterior.\""}, {"type": "text", "text": "Candidate answer: Yes, both the Sloan Laboratory and the Caltech Bridge Laboratory have a similar concrete exterior."}, {"type": "text", "text": "Please score the candidate exactly with the five integer ratings in JSON as instructed by the system prompt."}]}]}}
{"custom_id": "d5bcb78c0dba11ecb1e81171463288e9_geval", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-mini-2025-04-14", "max_tokens": 200, "temperature": 1, "n": 20, "messages": [{"role": "system", "content": "You are an evaluation assistant. You will be given:\n  - A question Q.\n  - A gold/reference answer (one or more short reference sentences).\n  - A candidate/sample answer produced by a system.\n\nYour job is to **assign integer scores** (1..5) for the following criteria comparing the *candidate* to the *gold/reference*:\n\n1. correctness (1-5): How factually correct is the candidate vs the gold answer? (5 = fully correct, 1 = mostly or fully incorrect).\n2. completeness (1-5): How completely does the candidate cover the key points in the gold answer? (5 = covers all key points; 1 = almost none).\n3. precision (1-5): How concise and focused is the candidate (not too long answer)? (5 = concise & precise; 1 = verbose / many extraneous claims).\n4. coherence (1-5): Is the candidate fluent and well-structured? (5 = natural, coherent; 1 = disfluent or incoherent).\n5. relevance (1-5): Are the statements in the candidate relevant to the question and gold answer (not introducing unrelated claims)? (5 = fully relevant; 1 = mostly irrelevant).\n\nREQUIREMENTS (strict):\n- Output **ONLY** a JSON object EXACTLY of the form:\n  {\"correctness\": <1-5>, \"completeness\": <1-5>, \"precision\": <1-5>, \"coherence\": <1-5>, \"relevance\": <1-5>}\n- No additional text, explanation, or whitespace outside the JSON object.\n\nFEW-SHOT EXAMPLE (this demonstrates the required output; do not include the example in actual responses):\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"No, the capital of Germany is not Paris, the capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":5,\"coherence\":5,\"relevance\":5}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"The capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":3,\"completeness\":2,\"precision\":5,\"coherence\":5,\"relevance\":2}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"If capital stands for the central administrative region of a country, then no, Paris is not the capital of Germany. It's important to note what is the definintion of a 'capital'. However, due to the common popular opinion, a capital of a country is well defined.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":1,\"coherence\":4,\"relevance\":1}\n\nEND OF SYSTEM PROMPT."}, {"role": "user", "content": [{"type": "text", "text": "Question: "}, {"type": "text", "text": "Gold reference 1: \"There are more windows in the back wall of the Academy of Fine Arts in Gdańsk than the front wall of the Burlington House of the Royal Academy of Arts.\""}, {"type": "text", "text": "Candidate answer: The back wall of the Academy of Fine Arts in Gdańsk has more windows than the front wall of Burlington House of the Royal Academy of Arts."}, {"type": "text", "text": "Please score the candidate exactly with the five integer ratings in JSON as instructed by the system prompt."}]}]}}
{"custom_id": "d5bbebd60dba11ecb1e81171463288e9_geval", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-mini-2025-04-14", "max_tokens": 200, "temperature": 1, "n": 20, "messages": [{"role": "system", "content": "You are an evaluation assistant. You will be given:\n  - A question Q.\n  - A gold/reference answer (one or more short reference sentences).\n  - A candidate/sample answer produced by a system.\n\nYour job is to **assign integer scores** (1..5) for the following criteria comparing the *candidate* to the *gold/reference*:\n\n1. correctness (1-5): How factually correct is the candidate vs the gold answer? (5 = fully correct, 1 = mostly or fully incorrect).\n2. completeness (1-5): How completely does the candidate cover the key points in the gold answer? (5 = covers all key points; 1 = almost none).\n3. precision (1-5): How concise and focused is the candidate (not too long answer)? (5 = concise & precise; 1 = verbose / many extraneous claims).\n4. coherence (1-5): Is the candidate fluent and well-structured? (5 = natural, coherent; 1 = disfluent or incoherent).\n5. relevance (1-5): Are the statements in the candidate relevant to the question and gold answer (not introducing unrelated claims)? (5 = fully relevant; 1 = mostly irrelevant).\n\nREQUIREMENTS (strict):\n- Output **ONLY** a JSON object EXACTLY of the form:\n  {\"correctness\": <1-5>, \"completeness\": <1-5>, \"precision\": <1-5>, \"coherence\": <1-5>, \"relevance\": <1-5>}\n- No additional text, explanation, or whitespace outside the JSON object.\n\nFEW-SHOT EXAMPLE (this demonstrates the required output; do not include the example in actual responses):\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"No, the capital of Germany is not Paris, the capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":5,\"coherence\":5,\"relevance\":5}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"The capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":3,\"completeness\":2,\"precision\":5,\"coherence\":5,\"relevance\":2}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"If capital stands for the central administrative region of a country, then no, Paris is not the capital of Germany. It's important to note what is the definintion of a 'capital'. However, due to the common popular opinion, a capital of a country is well defined.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":1,\"coherence\":4,\"relevance\":1}\n\nEND OF SYSTEM PROMPT."}, {"role": "user", "content": [{"type": "text", "text": "Question: "}, {"type": "text", "text": "Gold reference 1: \"The ends of the Chocolate cosmos's flower petals curl downward.\""}, {"type": "text", "text": "Candidate answer: The ends of the Chocolate cosmos's flower petals curl upward."}, {"type": "text", "text": "Please score the candidate exactly with the five integer ratings in JSON as instructed by the system prompt."}]}]}}
{"custom_id": "d5bf37500dba11ecb1e81171463288e9_geval", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-mini-2025-04-14", "max_tokens": 200, "temperature": 1, "n": 20, "messages": [{"role": "system", "content": "You are an evaluation assistant. You will be given:\n  - A question Q.\n  - A gold/reference answer (one or more short reference sentences).\n  - A candidate/sample answer produced by a system.\n\nYour job is to **assign integer scores** (1..5) for the following criteria comparing the *candidate* to the *gold/reference*:\n\n1. correctness (1-5): How factually correct is the candidate vs the gold answer? (5 = fully correct, 1 = mostly or fully incorrect).\n2. completeness (1-5): How completely does the candidate cover the key points in the gold answer? (5 = covers all key points; 1 = almost none).\n3. precision (1-5): How concise and focused is the candidate (not too long answer)? (5 = concise & precise; 1 = verbose / many extraneous claims).\n4. coherence (1-5): Is the candidate fluent and well-structured? (5 = natural, coherent; 1 = disfluent or incoherent).\n5. relevance (1-5): Are the statements in the candidate relevant to the question and gold answer (not introducing unrelated claims)? (5 = fully relevant; 1 = mostly irrelevant).\n\nREQUIREMENTS (strict):\n- Output **ONLY** a JSON object EXACTLY of the form:\n  {\"correctness\": <1-5>, \"completeness\": <1-5>, \"precision\": <1-5>, \"coherence\": <1-5>, \"relevance\": <1-5>}\n- No additional text, explanation, or whitespace outside the JSON object.\n\nFEW-SHOT EXAMPLE (this demonstrates the required output; do not include the example in actual responses):\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"No, the capital of Germany is not Paris, the capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":5,\"coherence\":5,\"relevance\":5}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"The capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":3,\"completeness\":2,\"precision\":5,\"coherence\":5,\"relevance\":2}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"If capital stands for the central administrative region of a country, then no, Paris is not the capital of Germany. It's important to note what is the definintion of a 'capital'. However, due to the common popular opinion, a capital of a country is well defined.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":1,\"coherence\":4,\"relevance\":1}\n\nEND OF SYSTEM PROMPT."}, {"role": "user", "content": [{"type": "text", "text": "Question: "}, {"type": "text", "text": "Gold reference 1: \"People climb up to The Basilica of the Sacre Cœur in Paris via stairs.\""}, {"type": "text", "text": "Candidate answer: People can climb up to The Basilica of the Sacré-Cœur in Paris by ascending the steps leading up from the surrounding area, as well as using nearby streets and pathways."}, {"type": "text", "text": "Please score the candidate exactly with the five integer ratings in JSON as instructed by the system prompt."}]}]}}
{"custom_id": "d5bd72260dba11ecb1e81171463288e9_geval", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-mini-2025-04-14", "max_tokens": 200, "temperature": 1, "n": 20, "messages": [{"role": "system", "content": "You are an evaluation assistant. You will be given:\n  - A question Q.\n  - A gold/reference answer (one or more short reference sentences).\n  - A candidate/sample answer produced by a system.\n\nYour job is to **assign integer scores** (1..5) for the following criteria comparing the *candidate* to the *gold/reference*:\n\n1. correctness (1-5): How factually correct is the candidate vs the gold answer? (5 = fully correct, 1 = mostly or fully incorrect).\n2. completeness (1-5): How completely does the candidate cover the key points in the gold answer? (5 = covers all key points; 1 = almost none).\n3. precision (1-5): How concise and focused is the candidate (not too long answer)? (5 = concise & precise; 1 = verbose / many extraneous claims).\n4. coherence (1-5): Is the candidate fluent and well-structured? (5 = natural, coherent; 1 = disfluent or incoherent).\n5. relevance (1-5): Are the statements in the candidate relevant to the question and gold answer (not introducing unrelated claims)? (5 = fully relevant; 1 = mostly irrelevant).\n\nREQUIREMENTS (strict):\n- Output **ONLY** a JSON object EXACTLY of the form:\n  {\"correctness\": <1-5>, \"completeness\": <1-5>, \"precision\": <1-5>, \"coherence\": <1-5>, \"relevance\": <1-5>}\n- No additional text, explanation, or whitespace outside the JSON object.\n\nFEW-SHOT EXAMPLE (this demonstrates the required output; do not include the example in actual responses):\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"No, the capital of Germany is not Paris, the capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":5,\"coherence\":5,\"relevance\":5}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"The capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":3,\"completeness\":2,\"precision\":5,\"coherence\":5,\"relevance\":2}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"If capital stands for the central administrative region of a country, then no, Paris is not the capital of Germany. It's important to note what is the definintion of a 'capital'. However, due to the common popular opinion, a capital of a country is well defined.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":1,\"coherence\":4,\"relevance\":1}\n\nEND OF SYSTEM PROMPT."}, {"role": "user", "content": [{"type": "text", "text": "Question: "}, {"type": "text", "text": "Gold reference 1: \"No, of the two, the Philippine National Museum is the only one with a fountain in front of it.\""}, {"type": "text", "text": "Candidate answer: Yes, there is a fountain in front of The Philippine National Museum (of Fine Arts) and the Hanoi Arts Museum."}, {"type": "text", "text": "Please score the candidate exactly with the five integer ratings in JSON as instructed by the system prompt."}]}]}}
{"custom_id": "d5bf03de0dba11ecb1e81171463288e9_geval", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-mini-2025-04-14", "max_tokens": 200, "temperature": 1, "n": 20, "messages": [{"role": "system", "content": "You are an evaluation assistant. You will be given:\n  - A question Q.\n  - A gold/reference answer (one or more short reference sentences).\n  - A candidate/sample answer produced by a system.\n\nYour job is to **assign integer scores** (1..5) for the following criteria comparing the *candidate* to the *gold/reference*:\n\n1. correctness (1-5): How factually correct is the candidate vs the gold answer? (5 = fully correct, 1 = mostly or fully incorrect).\n2. completeness (1-5): How completely does the candidate cover the key points in the gold answer? (5 = covers all key points; 1 = almost none).\n3. precision (1-5): How concise and focused is the candidate (not too long answer)? (5 = concise & precise; 1 = verbose / many extraneous claims).\n4. coherence (1-5): Is the candidate fluent and well-structured? (5 = natural, coherent; 1 = disfluent or incoherent).\n5. relevance (1-5): Are the statements in the candidate relevant to the question and gold answer (not introducing unrelated claims)? (5 = fully relevant; 1 = mostly irrelevant).\n\nREQUIREMENTS (strict):\n- Output **ONLY** a JSON object EXACTLY of the form:\n  {\"correctness\": <1-5>, \"completeness\": <1-5>, \"precision\": <1-5>, \"coherence\": <1-5>, \"relevance\": <1-5>}\n- No additional text, explanation, or whitespace outside the JSON object.\n\nFEW-SHOT EXAMPLE (this demonstrates the required output; do not include the example in actual responses):\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"No, the capital of Germany is not Paris, the capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":5,\"coherence\":5,\"relevance\":5}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"The capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":3,\"completeness\":2,\"precision\":5,\"coherence\":5,\"relevance\":2}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"If capital stands for the central administrative region of a country, then no, Paris is not the capital of Germany. It's important to note what is the definintion of a 'capital'. However, due to the common popular opinion, a capital of a country is well defined.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":1,\"coherence\":4,\"relevance\":1}\n\nEND OF SYSTEM PROMPT."}, {"role": "user", "content": [{"type": "text", "text": "Question: "}, {"type": "text", "text": "Gold reference 1: \"The women athletes had boater hats at the opening ceremony of the Rio 2016 Summer Olympics.\""}, {"type": "text", "text": "Candidate answer: At the opening ceremony of the Rio 2016 Summer Olympics, women athletes wore wide-brimmed hats."}, {"type": "text", "text": "Please score the candidate exactly with the five integer ratings in JSON as instructed by the system prompt."}]}]}}
{"custom_id": "d5beabf00dba11ecb1e81171463288e9_geval", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-mini-2025-04-14", "max_tokens": 200, "temperature": 1, "n": 20, "messages": [{"role": "system", "content": "You are an evaluation assistant. You will be given:\n  - A question Q.\n  - A gold/reference answer (one or more short reference sentences).\n  - A candidate/sample answer produced by a system.\n\nYour job is to **assign integer scores** (1..5) for the following criteria comparing the *candidate* to the *gold/reference*:\n\n1. correctness (1-5): How factually correct is the candidate vs the gold answer? (5 = fully correct, 1 = mostly or fully incorrect).\n2. completeness (1-5): How completely does the candidate cover the key points in the gold answer? (5 = covers all key points; 1 = almost none).\n3. precision (1-5): How concise and focused is the candidate (not too long answer)? (5 = concise & precise; 1 = verbose / many extraneous claims).\n4. coherence (1-5): Is the candidate fluent and well-structured? (5 = natural, coherent; 1 = disfluent or incoherent).\n5. relevance (1-5): Are the statements in the candidate relevant to the question and gold answer (not introducing unrelated claims)? (5 = fully relevant; 1 = mostly irrelevant).\n\nREQUIREMENTS (strict):\n- Output **ONLY** a JSON object EXACTLY of the form:\n  {\"correctness\": <1-5>, \"completeness\": <1-5>, \"precision\": <1-5>, \"coherence\": <1-5>, \"relevance\": <1-5>}\n- No additional text, explanation, or whitespace outside the JSON object.\n\nFEW-SHOT EXAMPLE (this demonstrates the required output; do not include the example in actual responses):\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"No, the capital of Germany is not Paris, the capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":5,\"coherence\":5,\"relevance\":5}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"The capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":3,\"completeness\":2,\"precision\":5,\"coherence\":5,\"relevance\":2}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"If capital stands for the central administrative region of a country, then no, Paris is not the capital of Germany. It's important to note what is the definintion of a 'capital'. However, due to the common popular opinion, a capital of a country is well defined.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":1,\"coherence\":4,\"relevance\":1}\n\nEND OF SYSTEM PROMPT."}, {"role": "user", "content": [{"type": "text", "text": "Question: "}, {"type": "text", "text": "Gold reference 1: \"The yellow strips on the Florida Technical College sign are darker at the top.\""}, {"type": "text", "text": "Candidate answer: The yellow strips on the Florida Technical College sign are darker at the bottom."}, {"type": "text", "text": "Please score the candidate exactly with the five integer ratings in JSON as instructed by the system prompt."}]}]}}
{"custom_id": "d5bf5ca80dba11ecb1e81171463288e9_geval", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-mini-2025-04-14", "max_tokens": 200, "temperature": 1, "n": 20, "messages": [{"role": "system", "content": "You are an evaluation assistant. You will be given:\n  - A question Q.\n  - A gold/reference answer (one or more short reference sentences).\n  - A candidate/sample answer produced by a system.\n\nYour job is to **assign integer scores** (1..5) for the following criteria comparing the *candidate* to the *gold/reference*:\n\n1. correctness (1-5): How factually correct is the candidate vs the gold answer? (5 = fully correct, 1 = mostly or fully incorrect).\n2. completeness (1-5): How completely does the candidate cover the key points in the gold answer? (5 = covers all key points; 1 = almost none).\n3. precision (1-5): How concise and focused is the candidate (not too long answer)? (5 = concise & precise; 1 = verbose / many extraneous claims).\n4. coherence (1-5): Is the candidate fluent and well-structured? (5 = natural, coherent; 1 = disfluent or incoherent).\n5. relevance (1-5): Are the statements in the candidate relevant to the question and gold answer (not introducing unrelated claims)? (5 = fully relevant; 1 = mostly irrelevant).\n\nREQUIREMENTS (strict):\n- Output **ONLY** a JSON object EXACTLY of the form:\n  {\"correctness\": <1-5>, \"completeness\": <1-5>, \"precision\": <1-5>, \"coherence\": <1-5>, \"relevance\": <1-5>}\n- No additional text, explanation, or whitespace outside the JSON object.\n\nFEW-SHOT EXAMPLE (this demonstrates the required output; do not include the example in actual responses):\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"No, the capital of Germany is not Paris, the capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":5,\"coherence\":5,\"relevance\":5}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"The capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":3,\"completeness\":2,\"precision\":5,\"coherence\":5,\"relevance\":2}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"If capital stands for the central administrative region of a country, then no, Paris is not the capital of Germany. It's important to note what is the definintion of a 'capital'. However, due to the common popular opinion, a capital of a country is well defined.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":1,\"coherence\":4,\"relevance\":1}\n\nEND OF SYSTEM PROMPT."}, {"role": "user", "content": [{"type": "text", "text": "Question: "}, {"type": "text", "text": "Gold reference 1: \"No, they are not both tall.\""}, {"type": "text", "text": "Candidate answer: Yes, both the Kashmiri traditional dress and Turkish traditional fashion feature tall hats."}, {"type": "text", "text": "Please score the candidate exactly with the five integer ratings in JSON as instructed by the system prompt."}]}]}}
{"custom_id": "d5bdb0ba0dba11ecb1e81171463288e9_geval", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-mini-2025-04-14", "max_tokens": 200, "temperature": 1, "n": 20, "messages": [{"role": "system", "content": "You are an evaluation assistant. You will be given:\n  - A question Q.\n  - A gold/reference answer (one or more short reference sentences).\n  - A candidate/sample answer produced by a system.\n\nYour job is to **assign integer scores** (1..5) for the following criteria comparing the *candidate* to the *gold/reference*:\n\n1. correctness (1-5): How factually correct is the candidate vs the gold answer? (5 = fully correct, 1 = mostly or fully incorrect).\n2. completeness (1-5): How completely does the candidate cover the key points in the gold answer? (5 = covers all key points; 1 = almost none).\n3. precision (1-5): How concise and focused is the candidate (not too long answer)? (5 = concise & precise; 1 = verbose / many extraneous claims).\n4. coherence (1-5): Is the candidate fluent and well-structured? (5 = natural, coherent; 1 = disfluent or incoherent).\n5. relevance (1-5): Are the statements in the candidate relevant to the question and gold answer (not introducing unrelated claims)? (5 = fully relevant; 1 = mostly irrelevant).\n\nREQUIREMENTS (strict):\n- Output **ONLY** a JSON object EXACTLY of the form:\n  {\"correctness\": <1-5>, \"completeness\": <1-5>, \"precision\": <1-5>, \"coherence\": <1-5>, \"relevance\": <1-5>}\n- No additional text, explanation, or whitespace outside the JSON object.\n\nFEW-SHOT EXAMPLE (this demonstrates the required output; do not include the example in actual responses):\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"No, the capital of Germany is not Paris, the capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":5,\"coherence\":5,\"relevance\":5}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"The capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":3,\"completeness\":2,\"precision\":5,\"coherence\":5,\"relevance\":2}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"If capital stands for the central administrative region of a country, then no, Paris is not the capital of Germany. It's important to note what is the definintion of a 'capital'. However, due to the common popular opinion, a capital of a country is well defined.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":1,\"coherence\":4,\"relevance\":1}\n\nEND OF SYSTEM PROMPT."}, {"role": "user", "content": [{"type": "text", "text": "Question: "}, {"type": "text", "text": "Gold reference 1: \"Two unbroken circles can be seen in the stained glass window in the Chapter House of the Worcester Art Museum.\""}, {"type": "text", "text": "Candidate answer: The stained glass window in the Chapter House of the Worcester Art Museum features multiple unbroken circles."}, {"type": "text", "text": "Please score the candidate exactly with the five integer ratings in JSON as instructed by the system prompt."}]}]}}
{"custom_id": "d5bc70c40dba11ecb1e81171463288e9_geval", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-mini-2025-04-14", "max_tokens": 200, "temperature": 1, "n": 20, "messages": [{"role": "system", "content": "You are an evaluation assistant. You will be given:\n  - A question Q.\n  - A gold/reference answer (one or more short reference sentences).\n  - A candidate/sample answer produced by a system.\n\nYour job is to **assign integer scores** (1..5) for the following criteria comparing the *candidate* to the *gold/reference*:\n\n1. correctness (1-5): How factually correct is the candidate vs the gold answer? (5 = fully correct, 1 = mostly or fully incorrect).\n2. completeness (1-5): How completely does the candidate cover the key points in the gold answer? (5 = covers all key points; 1 = almost none).\n3. precision (1-5): How concise and focused is the candidate (not too long answer)? (5 = concise & precise; 1 = verbose / many extraneous claims).\n4. coherence (1-5): Is the candidate fluent and well-structured? (5 = natural, coherent; 1 = disfluent or incoherent).\n5. relevance (1-5): Are the statements in the candidate relevant to the question and gold answer (not introducing unrelated claims)? (5 = fully relevant; 1 = mostly irrelevant).\n\nREQUIREMENTS (strict):\n- Output **ONLY** a JSON object EXACTLY of the form:\n  {\"correctness\": <1-5>, \"completeness\": <1-5>, \"precision\": <1-5>, \"coherence\": <1-5>, \"relevance\": <1-5>}\n- No additional text, explanation, or whitespace outside the JSON object.\n\nFEW-SHOT EXAMPLE (this demonstrates the required output; do not include the example in actual responses):\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"No, the capital of Germany is not Paris, the capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":5,\"coherence\":5,\"relevance\":5}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"The capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":3,\"completeness\":2,\"precision\":5,\"coherence\":5,\"relevance\":2}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"If capital stands for the central administrative region of a country, then no, Paris is not the capital of Germany. It's important to note what is the definintion of a 'capital'. However, due to the common popular opinion, a capital of a country is well defined.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":1,\"coherence\":4,\"relevance\":1}\n\nEND OF SYSTEM PROMPT."}, {"role": "user", "content": [{"type": "text", "text": "Question: "}, {"type": "text", "text": "Gold reference 1: \"Barabri and Grenadine goats both have spotted coats.\""}, {"type": "text", "text": "Candidate answer: The Barabri goat typically has a coat with a mix of white and brown spots, while the Grenadine goat often features a black and white pattern."}, {"type": "text", "text": "Please score the candidate exactly with the five integer ratings in JSON as instructed by the system prompt."}]}]}}
{"custom_id": "d5bec5680dba11ecb1e81171463288e9_geval", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-mini-2025-04-14", "max_tokens": 200, "temperature": 1, "n": 20, "messages": [{"role": "system", "content": "You are an evaluation assistant. You will be given:\n  - A question Q.\n  - A gold/reference answer (one or more short reference sentences).\n  - A candidate/sample answer produced by a system.\n\nYour job is to **assign integer scores** (1..5) for the following criteria comparing the *candidate* to the *gold/reference*:\n\n1. correctness (1-5): How factually correct is the candidate vs the gold answer? (5 = fully correct, 1 = mostly or fully incorrect).\n2. completeness (1-5): How completely does the candidate cover the key points in the gold answer? (5 = covers all key points; 1 = almost none).\n3. precision (1-5): How concise and focused is the candidate (not too long answer)? (5 = concise & precise; 1 = verbose / many extraneous claims).\n4. coherence (1-5): Is the candidate fluent and well-structured? (5 = natural, coherent; 1 = disfluent or incoherent).\n5. relevance (1-5): Are the statements in the candidate relevant to the question and gold answer (not introducing unrelated claims)? (5 = fully relevant; 1 = mostly irrelevant).\n\nREQUIREMENTS (strict):\n- Output **ONLY** a JSON object EXACTLY of the form:\n  {\"correctness\": <1-5>, \"completeness\": <1-5>, \"precision\": <1-5>, \"coherence\": <1-5>, \"relevance\": <1-5>}\n- No additional text, explanation, or whitespace outside the JSON object.\n\nFEW-SHOT EXAMPLE (this demonstrates the required output; do not include the example in actual responses):\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"No, the capital of Germany is not Paris, the capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":5,\"coherence\":5,\"relevance\":5}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"The capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":3,\"completeness\":2,\"precision\":5,\"coherence\":5,\"relevance\":2}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"If capital stands for the central administrative region of a country, then no, Paris is not the capital of Germany. It's important to note what is the definintion of a 'capital'. However, due to the common popular opinion, a capital of a country is well defined.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":1,\"coherence\":4,\"relevance\":1}\n\nEND OF SYSTEM PROMPT."}, {"role": "user", "content": [{"type": "text", "text": "Question: "}, {"type": "text", "text": "Gold reference 1: \"The Hygrocybe anomala and the Entoloma both grow on elongated stems.\""}, {"type": "text", "text": "Candidate answer: Yes, both Hygrocybe anomala and Entoloma species typically grow on elongated stems."}, {"type": "text", "text": "Please score the candidate exactly with the five integer ratings in JSON as instructed by the system prompt."}]}]}}
{"custom_id": "d5bf8e120dba11ecb1e81171463288e9_geval", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-mini-2025-04-14", "max_tokens": 200, "temperature": 1, "n": 20, "messages": [{"role": "system", "content": "You are an evaluation assistant. You will be given:\n  - A question Q.\n  - A gold/reference answer (one or more short reference sentences).\n  - A candidate/sample answer produced by a system.\n\nYour job is to **assign integer scores** (1..5) for the following criteria comparing the *candidate* to the *gold/reference*:\n\n1. correctness (1-5): How factually correct is the candidate vs the gold answer? (5 = fully correct, 1 = mostly or fully incorrect).\n2. completeness (1-5): How completely does the candidate cover the key points in the gold answer? (5 = covers all key points; 1 = almost none).\n3. precision (1-5): How concise and focused is the candidate (not too long answer)? (5 = concise & precise; 1 = verbose / many extraneous claims).\n4. coherence (1-5): Is the candidate fluent and well-structured? (5 = natural, coherent; 1 = disfluent or incoherent).\n5. relevance (1-5): Are the statements in the candidate relevant to the question and gold answer (not introducing unrelated claims)? (5 = fully relevant; 1 = mostly irrelevant).\n\nREQUIREMENTS (strict):\n- Output **ONLY** a JSON object EXACTLY of the form:\n  {\"correctness\": <1-5>, \"completeness\": <1-5>, \"precision\": <1-5>, \"coherence\": <1-5>, \"relevance\": <1-5>}\n- No additional text, explanation, or whitespace outside the JSON object.\n\nFEW-SHOT EXAMPLE (this demonstrates the required output; do not include the example in actual responses):\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"No, the capital of Germany is not Paris, the capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":5,\"coherence\":5,\"relevance\":5}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"The capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":3,\"completeness\":2,\"precision\":5,\"coherence\":5,\"relevance\":2}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"If capital stands for the central administrative region of a country, then no, Paris is not the capital of Germany. It's important to note what is the definintion of a 'capital'. However, due to the common popular opinion, a capital of a country is well defined.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":1,\"coherence\":4,\"relevance\":1}\n\nEND OF SYSTEM PROMPT."}, {"role": "user", "content": [{"type": "text", "text": "Question: "}, {"type": "text", "text": "Gold reference 1: \"The staircase of the Grand Palais has more than one set of stairs.\""}, {"type": "text", "text": "Candidate answer: Yes, the staircase of the Grand Palais has more than one set of stairs."}, {"type": "text", "text": "Please score the candidate exactly with the five integer ratings in JSON as instructed by the system prompt."}]}]}}
{"custom_id": "d5bd6d300dba11ecb1e81171463288e9_geval", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-mini-2025-04-14", "max_tokens": 200, "temperature": 1, "n": 20, "messages": [{"role": "system", "content": "You are an evaluation assistant. You will be given:\n  - A question Q.\n  - A gold/reference answer (one or more short reference sentences).\n  - A candidate/sample answer produced by a system.\n\nYour job is to **assign integer scores** (1..5) for the following criteria comparing the *candidate* to the *gold/reference*:\n\n1. correctness (1-5): How factually correct is the candidate vs the gold answer? (5 = fully correct, 1 = mostly or fully incorrect).\n2. completeness (1-5): How completely does the candidate cover the key points in the gold answer? (5 = covers all key points; 1 = almost none).\n3. precision (1-5): How concise and focused is the candidate (not too long answer)? (5 = concise & precise; 1 = verbose / many extraneous claims).\n4. coherence (1-5): Is the candidate fluent and well-structured? (5 = natural, coherent; 1 = disfluent or incoherent).\n5. relevance (1-5): Are the statements in the candidate relevant to the question and gold answer (not introducing unrelated claims)? (5 = fully relevant; 1 = mostly irrelevant).\n\nREQUIREMENTS (strict):\n- Output **ONLY** a JSON object EXACTLY of the form:\n  {\"correctness\": <1-5>, \"completeness\": <1-5>, \"precision\": <1-5>, \"coherence\": <1-5>, \"relevance\": <1-5>}\n- No additional text, explanation, or whitespace outside the JSON object.\n\nFEW-SHOT EXAMPLE (this demonstrates the required output; do not include the example in actual responses):\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"No, the capital of Germany is not Paris, the capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":5,\"coherence\":5,\"relevance\":5}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"The capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":3,\"completeness\":2,\"precision\":5,\"coherence\":5,\"relevance\":2}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"If capital stands for the central administrative region of a country, then no, Paris is not the capital of Germany. It's important to note what is the definintion of a 'capital'. However, due to the common popular opinion, a capital of a country is well defined.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":1,\"coherence\":4,\"relevance\":1}\n\nEND OF SYSTEM PROMPT."}, {"role": "user", "content": [{"type": "text", "text": "Question: "}, {"type": "text", "text": "Gold reference 1: \"Palm trees and deciduous tress can be seen.\""}, {"type": "text", "text": "Candidate answer: In the North East area of Barcelona, you can see trees such as plane trees, which are commonly found along streets and avenues."}, {"type": "text", "text": "Please score the candidate exactly with the five integer ratings in JSON as instructed by the system prompt."}]}]}}
{"custom_id": "d5bc798e0dba11ecb1e81171463288e9_geval", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-mini-2025-04-14", "max_tokens": 200, "temperature": 1, "n": 20, "messages": [{"role": "system", "content": "You are an evaluation assistant. You will be given:\n  - A question Q.\n  - A gold/reference answer (one or more short reference sentences).\n  - A candidate/sample answer produced by a system.\n\nYour job is to **assign integer scores** (1..5) for the following criteria comparing the *candidate* to the *gold/reference*:\n\n1. correctness (1-5): How factually correct is the candidate vs the gold answer? (5 = fully correct, 1 = mostly or fully incorrect).\n2. completeness (1-5): How completely does the candidate cover the key points in the gold answer? (5 = covers all key points; 1 = almost none).\n3. precision (1-5): How concise and focused is the candidate (not too long answer)? (5 = concise & precise; 1 = verbose / many extraneous claims).\n4. coherence (1-5): Is the candidate fluent and well-structured? (5 = natural, coherent; 1 = disfluent or incoherent).\n5. relevance (1-5): Are the statements in the candidate relevant to the question and gold answer (not introducing unrelated claims)? (5 = fully relevant; 1 = mostly irrelevant).\n\nREQUIREMENTS (strict):\n- Output **ONLY** a JSON object EXACTLY of the form:\n  {\"correctness\": <1-5>, \"completeness\": <1-5>, \"precision\": <1-5>, \"coherence\": <1-5>, \"relevance\": <1-5>}\n- No additional text, explanation, or whitespace outside the JSON object.\n\nFEW-SHOT EXAMPLE (this demonstrates the required output; do not include the example in actual responses):\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"No, the capital of Germany is not Paris, the capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":5,\"coherence\":5,\"relevance\":5}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"The capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":3,\"completeness\":2,\"precision\":5,\"coherence\":5,\"relevance\":2}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"If capital stands for the central administrative region of a country, then no, Paris is not the capital of Germany. It's important to note what is the definintion of a 'capital'. However, due to the common popular opinion, a capital of a country is well defined.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":1,\"coherence\":4,\"relevance\":1}\n\nEND OF SYSTEM PROMPT."}, {"role": "user", "content": [{"type": "text", "text": "Question: "}, {"type": "text", "text": "Gold reference 1: \"While looking at the sculptures at the top of the stairs in the Kunsthistorisches Museum, the sculpture of the lions is taller than the sculpture of the man with a sword.\""}, {"type": "text", "text": "Candidate answer: The sculpture of the man with a sword is taller than the sculpture of the lions."}, {"type": "text", "text": "Please score the candidate exactly with the five integer ratings in JSON as instructed by the system prompt."}]}]}}
{"custom_id": "d5bbceb20dba11ecb1e81171463288e9_geval", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-mini-2025-04-14", "max_tokens": 200, "temperature": 1, "n": 20, "messages": [{"role": "system", "content": "You are an evaluation assistant. You will be given:\n  - A question Q.\n  - A gold/reference answer (one or more short reference sentences).\n  - A candidate/sample answer produced by a system.\n\nYour job is to **assign integer scores** (1..5) for the following criteria comparing the *candidate* to the *gold/reference*:\n\n1. correctness (1-5): How factually correct is the candidate vs the gold answer? (5 = fully correct, 1 = mostly or fully incorrect).\n2. completeness (1-5): How completely does the candidate cover the key points in the gold answer? (5 = covers all key points; 1 = almost none).\n3. precision (1-5): How concise and focused is the candidate (not too long answer)? (5 = concise & precise; 1 = verbose / many extraneous claims).\n4. coherence (1-5): Is the candidate fluent and well-structured? (5 = natural, coherent; 1 = disfluent or incoherent).\n5. relevance (1-5): Are the statements in the candidate relevant to the question and gold answer (not introducing unrelated claims)? (5 = fully relevant; 1 = mostly irrelevant).\n\nREQUIREMENTS (strict):\n- Output **ONLY** a JSON object EXACTLY of the form:\n  {\"correctness\": <1-5>, \"completeness\": <1-5>, \"precision\": <1-5>, \"coherence\": <1-5>, \"relevance\": <1-5>}\n- No additional text, explanation, or whitespace outside the JSON object.\n\nFEW-SHOT EXAMPLE (this demonstrates the required output; do not include the example in actual responses):\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"No, the capital of Germany is not Paris, the capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":5,\"coherence\":5,\"relevance\":5}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"The capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":3,\"completeness\":2,\"precision\":5,\"coherence\":5,\"relevance\":2}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"If capital stands for the central administrative region of a country, then no, Paris is not the capital of Germany. It's important to note what is the definintion of a 'capital'. However, due to the common popular opinion, a capital of a country is well defined.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":1,\"coherence\":4,\"relevance\":1}\n\nEND OF SYSTEM PROMPT."}, {"role": "user", "content": [{"type": "text", "text": "Question: "}, {"type": "text", "text": "Gold reference 1: \"There are Roman numerals on the clock face in the Old Town Square in Prague.\""}, {"type": "text", "text": "Candidate answer: The clock face in the Old Town Square in Prague features both Roman numerals and astronomical symbols."}, {"type": "text", "text": "Please score the candidate exactly with the five integer ratings in JSON as instructed by the system prompt."}]}]}}
{"custom_id": "d5bf3db80dba11ecb1e81171463288e9_geval", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-mini-2025-04-14", "max_tokens": 200, "temperature": 1, "n": 20, "messages": [{"role": "system", "content": "You are an evaluation assistant. You will be given:\n  - A question Q.\n  - A gold/reference answer (one or more short reference sentences).\n  - A candidate/sample answer produced by a system.\n\nYour job is to **assign integer scores** (1..5) for the following criteria comparing the *candidate* to the *gold/reference*:\n\n1. correctness (1-5): How factually correct is the candidate vs the gold answer? (5 = fully correct, 1 = mostly or fully incorrect).\n2. completeness (1-5): How completely does the candidate cover the key points in the gold answer? (5 = covers all key points; 1 = almost none).\n3. precision (1-5): How concise and focused is the candidate (not too long answer)? (5 = concise & precise; 1 = verbose / many extraneous claims).\n4. coherence (1-5): Is the candidate fluent and well-structured? (5 = natural, coherent; 1 = disfluent or incoherent).\n5. relevance (1-5): Are the statements in the candidate relevant to the question and gold answer (not introducing unrelated claims)? (5 = fully relevant; 1 = mostly irrelevant).\n\nREQUIREMENTS (strict):\n- Output **ONLY** a JSON object EXACTLY of the form:\n  {\"correctness\": <1-5>, \"completeness\": <1-5>, \"precision\": <1-5>, \"coherence\": <1-5>, \"relevance\": <1-5>}\n- No additional text, explanation, or whitespace outside the JSON object.\n\nFEW-SHOT EXAMPLE (this demonstrates the required output; do not include the example in actual responses):\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"No, the capital of Germany is not Paris, the capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":5,\"coherence\":5,\"relevance\":5}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"The capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":3,\"completeness\":2,\"precision\":5,\"coherence\":5,\"relevance\":2}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"If capital stands for the central administrative region of a country, then no, Paris is not the capital of Germany. It's important to note what is the definintion of a 'capital'. However, due to the common popular opinion, a capital of a country is well defined.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":1,\"coherence\":4,\"relevance\":1}\n\nEND OF SYSTEM PROMPT."}, {"role": "user", "content": [{"type": "text", "text": "Question: "}, {"type": "text", "text": "Gold reference 1: \"Yes, the Prince of Wales building is taller.\""}, {"type": "text", "text": "Candidate answer: The Prince of Wales building is taller than the Imperial Arms building at Earls Court."}, {"type": "text", "text": "Please score the candidate exactly with the five integer ratings in JSON as instructed by the system prompt."}]}]}}
{"custom_id": "d5bf358e0dba11ecb1e81171463288e9_geval", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-mini-2025-04-14", "max_tokens": 200, "temperature": 1, "n": 20, "messages": [{"role": "system", "content": "You are an evaluation assistant. You will be given:\n  - A question Q.\n  - A gold/reference answer (one or more short reference sentences).\n  - A candidate/sample answer produced by a system.\n\nYour job is to **assign integer scores** (1..5) for the following criteria comparing the *candidate* to the *gold/reference*:\n\n1. correctness (1-5): How factually correct is the candidate vs the gold answer? (5 = fully correct, 1 = mostly or fully incorrect).\n2. completeness (1-5): How completely does the candidate cover the key points in the gold answer? (5 = covers all key points; 1 = almost none).\n3. precision (1-5): How concise and focused is the candidate (not too long answer)? (5 = concise & precise; 1 = verbose / many extraneous claims).\n4. coherence (1-5): Is the candidate fluent and well-structured? (5 = natural, coherent; 1 = disfluent or incoherent).\n5. relevance (1-5): Are the statements in the candidate relevant to the question and gold answer (not introducing unrelated claims)? (5 = fully relevant; 1 = mostly irrelevant).\n\nREQUIREMENTS (strict):\n- Output **ONLY** a JSON object EXACTLY of the form:\n  {\"correctness\": <1-5>, \"completeness\": <1-5>, \"precision\": <1-5>, \"coherence\": <1-5>, \"relevance\": <1-5>}\n- No additional text, explanation, or whitespace outside the JSON object.\n\nFEW-SHOT EXAMPLE (this demonstrates the required output; do not include the example in actual responses):\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"No, the capital of Germany is not Paris, the capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":5,\"coherence\":5,\"relevance\":5}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"The capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":3,\"completeness\":2,\"precision\":5,\"coherence\":5,\"relevance\":2}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"If capital stands for the central administrative region of a country, then no, Paris is not the capital of Germany. It's important to note what is the definintion of a 'capital'. However, due to the common popular opinion, a capital of a country is well defined.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":1,\"coherence\":4,\"relevance\":1}\n\nEND OF SYSTEM PROMPT."}, {"role": "user", "content": [{"type": "text", "text": "Question: "}, {"type": "text", "text": "Gold reference 1: \"Lausis is sitting on three lions in \"The Triumph of Fame\".\""}, {"type": "text", "text": "Candidate answer: Lausis is sitting on two lions in \"The Triumph of Fame.\""}, {"type": "text", "text": "Please score the candidate exactly with the five integer ratings in JSON as instructed by the system prompt."}]}]}}
{"custom_id": "d5bd43960dba11ecb1e81171463288e9_geval", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-mini-2025-04-14", "max_tokens": 200, "temperature": 1, "n": 20, "messages": [{"role": "system", "content": "You are an evaluation assistant. You will be given:\n  - A question Q.\n  - A gold/reference answer (one or more short reference sentences).\n  - A candidate/sample answer produced by a system.\n\nYour job is to **assign integer scores** (1..5) for the following criteria comparing the *candidate* to the *gold/reference*:\n\n1. correctness (1-5): How factually correct is the candidate vs the gold answer? (5 = fully correct, 1 = mostly or fully incorrect).\n2. completeness (1-5): How completely does the candidate cover the key points in the gold answer? (5 = covers all key points; 1 = almost none).\n3. precision (1-5): How concise and focused is the candidate (not too long answer)? (5 = concise & precise; 1 = verbose / many extraneous claims).\n4. coherence (1-5): Is the candidate fluent and well-structured? (5 = natural, coherent; 1 = disfluent or incoherent).\n5. relevance (1-5): Are the statements in the candidate relevant to the question and gold answer (not introducing unrelated claims)? (5 = fully relevant; 1 = mostly irrelevant).\n\nREQUIREMENTS (strict):\n- Output **ONLY** a JSON object EXACTLY of the form:\n  {\"correctness\": <1-5>, \"completeness\": <1-5>, \"precision\": <1-5>, \"coherence\": <1-5>, \"relevance\": <1-5>}\n- No additional text, explanation, or whitespace outside the JSON object.\n\nFEW-SHOT EXAMPLE (this demonstrates the required output; do not include the example in actual responses):\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"No, the capital of Germany is not Paris, the capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":5,\"coherence\":5,\"relevance\":5}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"The capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":3,\"completeness\":2,\"precision\":5,\"coherence\":5,\"relevance\":2}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"If capital stands for the central administrative region of a country, then no, Paris is not the capital of Germany. It's important to note what is the definintion of a 'capital'. However, due to the common popular opinion, a capital of a country is well defined.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":1,\"coherence\":4,\"relevance\":1}\n\nEND OF SYSTEM PROMPT."}, {"role": "user", "content": [{"type": "text", "text": "Question: "}, {"type": "text", "text": "Gold reference 1: \"No, the Physharmonica at Organeum doesn't have fewer keys.\""}, {"type": "text", "text": "Candidate answer: Yes, the Physharmonica has fewer black keys than the Magnus electric chord organ."}, {"type": "text", "text": "Please score the candidate exactly with the five integer ratings in JSON as instructed by the system prompt."}]}]}}
{"custom_id": "d5beb0a00dba11ecb1e81171463288e9_geval", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-mini-2025-04-14", "max_tokens": 200, "temperature": 1, "n": 20, "messages": [{"role": "system", "content": "You are an evaluation assistant. You will be given:\n  - A question Q.\n  - A gold/reference answer (one or more short reference sentences).\n  - A candidate/sample answer produced by a system.\n\nYour job is to **assign integer scores** (1..5) for the following criteria comparing the *candidate* to the *gold/reference*:\n\n1. correctness (1-5): How factually correct is the candidate vs the gold answer? (5 = fully correct, 1 = mostly or fully incorrect).\n2. completeness (1-5): How completely does the candidate cover the key points in the gold answer? (5 = covers all key points; 1 = almost none).\n3. precision (1-5): How concise and focused is the candidate (not too long answer)? (5 = concise & precise; 1 = verbose / many extraneous claims).\n4. coherence (1-5): Is the candidate fluent and well-structured? (5 = natural, coherent; 1 = disfluent or incoherent).\n5. relevance (1-5): Are the statements in the candidate relevant to the question and gold answer (not introducing unrelated claims)? (5 = fully relevant; 1 = mostly irrelevant).\n\nREQUIREMENTS (strict):\n- Output **ONLY** a JSON object EXACTLY of the form:\n  {\"correctness\": <1-5>, \"completeness\": <1-5>, \"precision\": <1-5>, \"coherence\": <1-5>, \"relevance\": <1-5>}\n- No additional text, explanation, or whitespace outside the JSON object.\n\nFEW-SHOT EXAMPLE (this demonstrates the required output; do not include the example in actual responses):\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"No, the capital of Germany is not Paris, the capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":5,\"coherence\":5,\"relevance\":5}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"The capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":3,\"completeness\":2,\"precision\":5,\"coherence\":5,\"relevance\":2}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"If capital stands for the central administrative region of a country, then no, Paris is not the capital of Germany. It's important to note what is the definintion of a 'capital'. However, due to the common popular opinion, a capital of a country is well defined.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":1,\"coherence\":4,\"relevance\":1}\n\nEND OF SYSTEM PROMPT."}, {"role": "user", "content": [{"type": "text", "text": "Question: "}, {"type": "text", "text": "Gold reference 1: \"The Tio Pepe has a more modern style of architecture than the Puerta del Sol.\""}, {"type": "text", "text": "Candidate answer: The Tio Pepe in Madrid has a more modern type of architecture overall compared to the Puerta del Sol in Toledo."}, {"type": "text", "text": "Please score the candidate exactly with the five integer ratings in JSON as instructed by the system prompt."}]}]}}
{"custom_id": "d5bd3ee60dba11ecb1e81171463288e9_geval", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-mini-2025-04-14", "max_tokens": 200, "temperature": 1, "n": 20, "messages": [{"role": "system", "content": "You are an evaluation assistant. You will be given:\n  - A question Q.\n  - A gold/reference answer (one or more short reference sentences).\n  - A candidate/sample answer produced by a system.\n\nYour job is to **assign integer scores** (1..5) for the following criteria comparing the *candidate* to the *gold/reference*:\n\n1. correctness (1-5): How factually correct is the candidate vs the gold answer? (5 = fully correct, 1 = mostly or fully incorrect).\n2. completeness (1-5): How completely does the candidate cover the key points in the gold answer? (5 = covers all key points; 1 = almost none).\n3. precision (1-5): How concise and focused is the candidate (not too long answer)? (5 = concise & precise; 1 = verbose / many extraneous claims).\n4. coherence (1-5): Is the candidate fluent and well-structured? (5 = natural, coherent; 1 = disfluent or incoherent).\n5. relevance (1-5): Are the statements in the candidate relevant to the question and gold answer (not introducing unrelated claims)? (5 = fully relevant; 1 = mostly irrelevant).\n\nREQUIREMENTS (strict):\n- Output **ONLY** a JSON object EXACTLY of the form:\n  {\"correctness\": <1-5>, \"completeness\": <1-5>, \"precision\": <1-5>, \"coherence\": <1-5>, \"relevance\": <1-5>}\n- No additional text, explanation, or whitespace outside the JSON object.\n\nFEW-SHOT EXAMPLE (this demonstrates the required output; do not include the example in actual responses):\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"No, the capital of Germany is not Paris, the capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":5,\"coherence\":5,\"relevance\":5}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"The capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":3,\"completeness\":2,\"precision\":5,\"coherence\":5,\"relevance\":2}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"If capital stands for the central administrative region of a country, then no, Paris is not the capital of Germany. It's important to note what is the definintion of a 'capital'. However, due to the common popular opinion, a capital of a country is well defined.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":1,\"coherence\":4,\"relevance\":1}\n\nEND OF SYSTEM PROMPT."}, {"role": "user", "content": [{"type": "text", "text": "Question: "}, {"type": "text", "text": "Gold reference 1: \"Both Epcot Norway and the Disney World Imagination Pavilion have prominent triangular shapes.\""}, {"type": "text", "text": "Candidate answer: The prominent geometric shape in the design of both Epcot Norway and the Disney World Imagination Pavilion is the sphere."}, {"type": "text", "text": "Please score the candidate exactly with the five integer ratings in JSON as instructed by the system prompt."}]}]}}
{"custom_id": "d5bd210e0dba11ecb1e81171463288e9_geval", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-mini-2025-04-14", "max_tokens": 200, "temperature": 1, "n": 20, "messages": [{"role": "system", "content": "You are an evaluation assistant. You will be given:\n  - A question Q.\n  - A gold/reference answer (one or more short reference sentences).\n  - A candidate/sample answer produced by a system.\n\nYour job is to **assign integer scores** (1..5) for the following criteria comparing the *candidate* to the *gold/reference*:\n\n1. correctness (1-5): How factually correct is the candidate vs the gold answer? (5 = fully correct, 1 = mostly or fully incorrect).\n2. completeness (1-5): How completely does the candidate cover the key points in the gold answer? (5 = covers all key points; 1 = almost none).\n3. precision (1-5): How concise and focused is the candidate (not too long answer)? (5 = concise & precise; 1 = verbose / many extraneous claims).\n4. coherence (1-5): Is the candidate fluent and well-structured? (5 = natural, coherent; 1 = disfluent or incoherent).\n5. relevance (1-5): Are the statements in the candidate relevant to the question and gold answer (not introducing unrelated claims)? (5 = fully relevant; 1 = mostly irrelevant).\n\nREQUIREMENTS (strict):\n- Output **ONLY** a JSON object EXACTLY of the form:\n  {\"correctness\": <1-5>, \"completeness\": <1-5>, \"precision\": <1-5>, \"coherence\": <1-5>, \"relevance\": <1-5>}\n- No additional text, explanation, or whitespace outside the JSON object.\n\nFEW-SHOT EXAMPLE (this demonstrates the required output; do not include the example in actual responses):\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"No, the capital of Germany is not Paris, the capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":5,\"coherence\":5,\"relevance\":5}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"The capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":3,\"completeness\":2,\"precision\":5,\"coherence\":5,\"relevance\":2}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"If capital stands for the central administrative region of a country, then no, Paris is not the capital of Germany. It's important to note what is the definintion of a 'capital'. However, due to the common popular opinion, a capital of a country is well defined.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":1,\"coherence\":4,\"relevance\":1}\n\nEND OF SYSTEM PROMPT."}, {"role": "user", "content": [{"type": "text", "text": "Question: "}, {"type": "text", "text": "Gold reference 1: \"Both the Johnson house in San Marcos and Fisher Hall in San Marcos have balconies.\""}, {"type": "text", "text": "Candidate answer: Both the Johnson House and Fisher Hall feature exterior walkable balconies on the second floor."}, {"type": "text", "text": "Please score the candidate exactly with the five integer ratings in JSON as instructed by the system prompt."}]}]}}
{"custom_id": "d5bc40fe0dba11ecb1e81171463288e9_geval", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-mini-2025-04-14", "max_tokens": 200, "temperature": 1, "n": 20, "messages": [{"role": "system", "content": "You are an evaluation assistant. You will be given:\n  - A question Q.\n  - A gold/reference answer (one or more short reference sentences).\n  - A candidate/sample answer produced by a system.\n\nYour job is to **assign integer scores** (1..5) for the following criteria comparing the *candidate* to the *gold/reference*:\n\n1. correctness (1-5): How factually correct is the candidate vs the gold answer? (5 = fully correct, 1 = mostly or fully incorrect).\n2. completeness (1-5): How completely does the candidate cover the key points in the gold answer? (5 = covers all key points; 1 = almost none).\n3. precision (1-5): How concise and focused is the candidate (not too long answer)? (5 = concise & precise; 1 = verbose / many extraneous claims).\n4. coherence (1-5): Is the candidate fluent and well-structured? (5 = natural, coherent; 1 = disfluent or incoherent).\n5. relevance (1-5): Are the statements in the candidate relevant to the question and gold answer (not introducing unrelated claims)? (5 = fully relevant; 1 = mostly irrelevant).\n\nREQUIREMENTS (strict):\n- Output **ONLY** a JSON object EXACTLY of the form:\n  {\"correctness\": <1-5>, \"completeness\": <1-5>, \"precision\": <1-5>, \"coherence\": <1-5>, \"relevance\": <1-5>}\n- No additional text, explanation, or whitespace outside the JSON object.\n\nFEW-SHOT EXAMPLE (this demonstrates the required output; do not include the example in actual responses):\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"No, the capital of Germany is not Paris, the capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":5,\"coherence\":5,\"relevance\":5}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"The capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":3,\"completeness\":2,\"precision\":5,\"coherence\":5,\"relevance\":2}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"If capital stands for the central administrative region of a country, then no, Paris is not the capital of Germany. It's important to note what is the definintion of a 'capital'. However, due to the common popular opinion, a capital of a country is well defined.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":1,\"coherence\":4,\"relevance\":1}\n\nEND OF SYSTEM PROMPT."}, {"role": "user", "content": [{"type": "text", "text": "Question: "}, {"type": "text", "text": "Gold reference 1: \"The banners along side the Jane Foster Library addition entrance to Cornell University Law School are orange and red.\""}, {"type": "text", "text": "Candidate answer: The banners alongside the Jane Foster Library addition entrance to Cornell University Law School are orange and red."}, {"type": "text", "text": "Please score the candidate exactly with the five integer ratings in JSON as instructed by the system prompt."}]}]}}
{"custom_id": "d5bbce580dba11ecb1e81171463288e9_geval", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-mini-2025-04-14", "max_tokens": 200, "temperature": 1, "n": 20, "messages": [{"role": "system", "content": "You are an evaluation assistant. You will be given:\n  - A question Q.\n  - A gold/reference answer (one or more short reference sentences).\n  - A candidate/sample answer produced by a system.\n\nYour job is to **assign integer scores** (1..5) for the following criteria comparing the *candidate* to the *gold/reference*:\n\n1. correctness (1-5): How factually correct is the candidate vs the gold answer? (5 = fully correct, 1 = mostly or fully incorrect).\n2. completeness (1-5): How completely does the candidate cover the key points in the gold answer? (5 = covers all key points; 1 = almost none).\n3. precision (1-5): How concise and focused is the candidate (not too long answer)? (5 = concise & precise; 1 = verbose / many extraneous claims).\n4. coherence (1-5): Is the candidate fluent and well-structured? (5 = natural, coherent; 1 = disfluent or incoherent).\n5. relevance (1-5): Are the statements in the candidate relevant to the question and gold answer (not introducing unrelated claims)? (5 = fully relevant; 1 = mostly irrelevant).\n\nREQUIREMENTS (strict):\n- Output **ONLY** a JSON object EXACTLY of the form:\n  {\"correctness\": <1-5>, \"completeness\": <1-5>, \"precision\": <1-5>, \"coherence\": <1-5>, \"relevance\": <1-5>}\n- No additional text, explanation, or whitespace outside the JSON object.\n\nFEW-SHOT EXAMPLE (this demonstrates the required output; do not include the example in actual responses):\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"No, the capital of Germany is not Paris, the capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":5,\"coherence\":5,\"relevance\":5}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"The capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":3,\"completeness\":2,\"precision\":5,\"coherence\":5,\"relevance\":2}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"If capital stands for the central administrative region of a country, then no, Paris is not the capital of Germany. It's important to note what is the definintion of a 'capital'. However, due to the common popular opinion, a capital of a country is well defined.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":1,\"coherence\":4,\"relevance\":1}\n\nEND OF SYSTEM PROMPT."}, {"role": "user", "content": [{"type": "text", "text": "Question: "}, {"type": "text", "text": "Gold reference 1: \"The facades atop the cathedral are gold.\""}, {"type": "text", "text": "Candidate answer: The statues at the top of the facade of Rosario Cathedral are white."}, {"type": "text", "text": "Please score the candidate exactly with the five integer ratings in JSON as instructed by the system prompt."}]}]}}
{"custom_id": "d5bf1acc0dba11ecb1e81171463288e9_geval", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-mini-2025-04-14", "max_tokens": 200, "temperature": 1, "n": 20, "messages": [{"role": "system", "content": "You are an evaluation assistant. You will be given:\n  - A question Q.\n  - A gold/reference answer (one or more short reference sentences).\n  - A candidate/sample answer produced by a system.\n\nYour job is to **assign integer scores** (1..5) for the following criteria comparing the *candidate* to the *gold/reference*:\n\n1. correctness (1-5): How factually correct is the candidate vs the gold answer? (5 = fully correct, 1 = mostly or fully incorrect).\n2. completeness (1-5): How completely does the candidate cover the key points in the gold answer? (5 = covers all key points; 1 = almost none).\n3. precision (1-5): How concise and focused is the candidate (not too long answer)? (5 = concise & precise; 1 = verbose / many extraneous claims).\n4. coherence (1-5): Is the candidate fluent and well-structured? (5 = natural, coherent; 1 = disfluent or incoherent).\n5. relevance (1-5): Are the statements in the candidate relevant to the question and gold answer (not introducing unrelated claims)? (5 = fully relevant; 1 = mostly irrelevant).\n\nREQUIREMENTS (strict):\n- Output **ONLY** a JSON object EXACTLY of the form:\n  {\"correctness\": <1-5>, \"completeness\": <1-5>, \"precision\": <1-5>, \"coherence\": <1-5>, \"relevance\": <1-5>}\n- No additional text, explanation, or whitespace outside the JSON object.\n\nFEW-SHOT EXAMPLE (this demonstrates the required output; do not include the example in actual responses):\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"No, the capital of Germany is not Paris, the capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":5,\"coherence\":5,\"relevance\":5}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"The capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":3,\"completeness\":2,\"precision\":5,\"coherence\":5,\"relevance\":2}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"If capital stands for the central administrative region of a country, then no, Paris is not the capital of Germany. It's important to note what is the definintion of a 'capital'. However, due to the common popular opinion, a capital of a country is well defined.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":1,\"coherence\":4,\"relevance\":1}\n\nEND OF SYSTEM PROMPT."}, {"role": "user", "content": [{"type": "text", "text": "Question: "}, {"type": "text", "text": "Gold reference 1: \"No, there isn't any space between vendors at the Grand Bazaar in Istanbul.\""}, {"type": "text", "text": "Candidate answer: Yes, there is space between vendors at the Grand Bazaar in Istanbul, as seen in the images."}, {"type": "text", "text": "Please score the candidate exactly with the five integer ratings in JSON as instructed by the system prompt."}]}]}}
{"custom_id": "d5bcc8440dba11ecb1e81171463288e9_geval", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-mini-2025-04-14", "max_tokens": 200, "temperature": 1, "n": 20, "messages": [{"role": "system", "content": "You are an evaluation assistant. You will be given:\n  - A question Q.\n  - A gold/reference answer (one or more short reference sentences).\n  - A candidate/sample answer produced by a system.\n\nYour job is to **assign integer scores** (1..5) for the following criteria comparing the *candidate* to the *gold/reference*:\n\n1. correctness (1-5): How factually correct is the candidate vs the gold answer? (5 = fully correct, 1 = mostly or fully incorrect).\n2. completeness (1-5): How completely does the candidate cover the key points in the gold answer? (5 = covers all key points; 1 = almost none).\n3. precision (1-5): How concise and focused is the candidate (not too long answer)? (5 = concise & precise; 1 = verbose / many extraneous claims).\n4. coherence (1-5): Is the candidate fluent and well-structured? (5 = natural, coherent; 1 = disfluent or incoherent).\n5. relevance (1-5): Are the statements in the candidate relevant to the question and gold answer (not introducing unrelated claims)? (5 = fully relevant; 1 = mostly irrelevant).\n\nREQUIREMENTS (strict):\n- Output **ONLY** a JSON object EXACTLY of the form:\n  {\"correctness\": <1-5>, \"completeness\": <1-5>, \"precision\": <1-5>, \"coherence\": <1-5>, \"relevance\": <1-5>}\n- No additional text, explanation, or whitespace outside the JSON object.\n\nFEW-SHOT EXAMPLE (this demonstrates the required output; do not include the example in actual responses):\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"No, the capital of Germany is not Paris, the capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":5,\"coherence\":5,\"relevance\":5}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"The capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":3,\"completeness\":2,\"precision\":5,\"coherence\":5,\"relevance\":2}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"If capital stands for the central administrative region of a country, then no, Paris is not the capital of Germany. It's important to note what is the definintion of a 'capital'. However, due to the common popular opinion, a capital of a country is well defined.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":1,\"coherence\":4,\"relevance\":1}\n\nEND OF SYSTEM PROMPT."}, {"role": "user", "content": [{"type": "text", "text": "Question: "}, {"type": "text", "text": "Gold reference 1: \"Yao Ming wore a red blazer during the 2008 Summer Olympics Opening Ceremony.\""}, {"type": "text", "text": "Candidate answer: Yao Ming wore a red blazer during the 2008 Summer Olympics Opening Ceremony."}, {"type": "text", "text": "Please score the candidate exactly with the five integer ratings in JSON as instructed by the system prompt."}]}]}}
{"custom_id": "d5beb7080dba11ecb1e81171463288e9_geval", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-mini-2025-04-14", "max_tokens": 200, "temperature": 1, "n": 20, "messages": [{"role": "system", "content": "You are an evaluation assistant. You will be given:\n  - A question Q.\n  - A gold/reference answer (one or more short reference sentences).\n  - A candidate/sample answer produced by a system.\n\nYour job is to **assign integer scores** (1..5) for the following criteria comparing the *candidate* to the *gold/reference*:\n\n1. correctness (1-5): How factually correct is the candidate vs the gold answer? (5 = fully correct, 1 = mostly or fully incorrect).\n2. completeness (1-5): How completely does the candidate cover the key points in the gold answer? (5 = covers all key points; 1 = almost none).\n3. precision (1-5): How concise and focused is the candidate (not too long answer)? (5 = concise & precise; 1 = verbose / many extraneous claims).\n4. coherence (1-5): Is the candidate fluent and well-structured? (5 = natural, coherent; 1 = disfluent or incoherent).\n5. relevance (1-5): Are the statements in the candidate relevant to the question and gold answer (not introducing unrelated claims)? (5 = fully relevant; 1 = mostly irrelevant).\n\nREQUIREMENTS (strict):\n- Output **ONLY** a JSON object EXACTLY of the form:\n  {\"correctness\": <1-5>, \"completeness\": <1-5>, \"precision\": <1-5>, \"coherence\": <1-5>, \"relevance\": <1-5>}\n- No additional text, explanation, or whitespace outside the JSON object.\n\nFEW-SHOT EXAMPLE (this demonstrates the required output; do not include the example in actual responses):\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"No, the capital of Germany is not Paris, the capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":5,\"coherence\":5,\"relevance\":5}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"The capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":3,\"completeness\":2,\"precision\":5,\"coherence\":5,\"relevance\":2}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"If capital stands for the central administrative region of a country, then no, Paris is not the capital of Germany. It's important to note what is the definintion of a 'capital'. However, due to the common popular opinion, a capital of a country is well defined.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":1,\"coherence\":4,\"relevance\":1}\n\nEND OF SYSTEM PROMPT."}, {"role": "user", "content": [{"type": "text", "text": "Question: "}, {"type": "text", "text": "Gold reference 1: \"The angel is holding a flower.\""}, {"type": "text", "text": "Candidate answer: The angel in Jan van Eyck's \"The Ghent Altarpiece: Angel of The Annunciation\" is holding a lily."}, {"type": "text", "text": "Please score the candidate exactly with the five integer ratings in JSON as instructed by the system prompt."}]}]}}
{"custom_id": "d5bc32e40dba11ecb1e81171463288e9_geval", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-mini-2025-04-14", "max_tokens": 200, "temperature": 1, "n": 20, "messages": [{"role": "system", "content": "You are an evaluation assistant. You will be given:\n  - A question Q.\n  - A gold/reference answer (one or more short reference sentences).\n  - A candidate/sample answer produced by a system.\n\nYour job is to **assign integer scores** (1..5) for the following criteria comparing the *candidate* to the *gold/reference*:\n\n1. correctness (1-5): How factually correct is the candidate vs the gold answer? (5 = fully correct, 1 = mostly or fully incorrect).\n2. completeness (1-5): How completely does the candidate cover the key points in the gold answer? (5 = covers all key points; 1 = almost none).\n3. precision (1-5): How concise and focused is the candidate (not too long answer)? (5 = concise & precise; 1 = verbose / many extraneous claims).\n4. coherence (1-5): Is the candidate fluent and well-structured? (5 = natural, coherent; 1 = disfluent or incoherent).\n5. relevance (1-5): Are the statements in the candidate relevant to the question and gold answer (not introducing unrelated claims)? (5 = fully relevant; 1 = mostly irrelevant).\n\nREQUIREMENTS (strict):\n- Output **ONLY** a JSON object EXACTLY of the form:\n  {\"correctness\": <1-5>, \"completeness\": <1-5>, \"precision\": <1-5>, \"coherence\": <1-5>, \"relevance\": <1-5>}\n- No additional text, explanation, or whitespace outside the JSON object.\n\nFEW-SHOT EXAMPLE (this demonstrates the required output; do not include the example in actual responses):\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"No, the capital of Germany is not Paris, the capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":5,\"coherence\":5,\"relevance\":5}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"The capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":3,\"completeness\":2,\"precision\":5,\"coherence\":5,\"relevance\":2}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"If capital stands for the central administrative region of a country, then no, Paris is not the capital of Germany. It's important to note what is the definintion of a 'capital'. However, due to the common popular opinion, a capital of a country is well defined.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":1,\"coherence\":4,\"relevance\":1}\n\nEND OF SYSTEM PROMPT."}, {"role": "user", "content": [{"type": "text", "text": "Question: "}, {"type": "text", "text": "Gold reference 1: \"There are two flags flying from the flagpole in front of Savannah Technical College.\""}, {"type": "text", "text": "Candidate answer: There are two flags flying from the flagpole in front of Savannah Technical College."}, {"type": "text", "text": "Please score the candidate exactly with the five integer ratings in JSON as instructed by the system prompt."}]}]}}
{"custom_id": "d5bf2eae0dba11ecb1e81171463288e9_geval", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-mini-2025-04-14", "max_tokens": 200, "temperature": 1, "n": 20, "messages": [{"role": "system", "content": "You are an evaluation assistant. You will be given:\n  - A question Q.\n  - A gold/reference answer (one or more short reference sentences).\n  - A candidate/sample answer produced by a system.\n\nYour job is to **assign integer scores** (1..5) for the following criteria comparing the *candidate* to the *gold/reference*:\n\n1. correctness (1-5): How factually correct is the candidate vs the gold answer? (5 = fully correct, 1 = mostly or fully incorrect).\n2. completeness (1-5): How completely does the candidate cover the key points in the gold answer? (5 = covers all key points; 1 = almost none).\n3. precision (1-5): How concise and focused is the candidate (not too long answer)? (5 = concise & precise; 1 = verbose / many extraneous claims).\n4. coherence (1-5): Is the candidate fluent and well-structured? (5 = natural, coherent; 1 = disfluent or incoherent).\n5. relevance (1-5): Are the statements in the candidate relevant to the question and gold answer (not introducing unrelated claims)? (5 = fully relevant; 1 = mostly irrelevant).\n\nREQUIREMENTS (strict):\n- Output **ONLY** a JSON object EXACTLY of the form:\n  {\"correctness\": <1-5>, \"completeness\": <1-5>, \"precision\": <1-5>, \"coherence\": <1-5>, \"relevance\": <1-5>}\n- No additional text, explanation, or whitespace outside the JSON object.\n\nFEW-SHOT EXAMPLE (this demonstrates the required output; do not include the example in actual responses):\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"No, the capital of Germany is not Paris, the capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":5,\"coherence\":5,\"relevance\":5}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"The capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":3,\"completeness\":2,\"precision\":5,\"coherence\":5,\"relevance\":2}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"If capital stands for the central administrative region of a country, then no, Paris is not the capital of Germany. It's important to note what is the definintion of a 'capital'. However, due to the common popular opinion, a capital of a country is well defined.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":1,\"coherence\":4,\"relevance\":1}\n\nEND OF SYSTEM PROMPT."}, {"role": "user", "content": [{"type": "text", "text": "Question: "}, {"type": "text", "text": "Gold reference 1: \"The headlights of the Alfa Romeo GTV6 are round.\""}, {"type": "text", "text": "Candidate answer: The headlights of the Alfa Romeo GTV6 are square."}, {"type": "text", "text": "Please score the candidate exactly with the five integer ratings in JSON as instructed by the system prompt."}]}]}}
{"custom_id": "d5be01a00dba11ecb1e81171463288e9_geval", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-mini-2025-04-14", "max_tokens": 200, "temperature": 1, "n": 20, "messages": [{"role": "system", "content": "You are an evaluation assistant. You will be given:\n  - A question Q.\n  - A gold/reference answer (one or more short reference sentences).\n  - A candidate/sample answer produced by a system.\n\nYour job is to **assign integer scores** (1..5) for the following criteria comparing the *candidate* to the *gold/reference*:\n\n1. correctness (1-5): How factually correct is the candidate vs the gold answer? (5 = fully correct, 1 = mostly or fully incorrect).\n2. completeness (1-5): How completely does the candidate cover the key points in the gold answer? (5 = covers all key points; 1 = almost none).\n3. precision (1-5): How concise and focused is the candidate (not too long answer)? (5 = concise & precise; 1 = verbose / many extraneous claims).\n4. coherence (1-5): Is the candidate fluent and well-structured? (5 = natural, coherent; 1 = disfluent or incoherent).\n5. relevance (1-5): Are the statements in the candidate relevant to the question and gold answer (not introducing unrelated claims)? (5 = fully relevant; 1 = mostly irrelevant).\n\nREQUIREMENTS (strict):\n- Output **ONLY** a JSON object EXACTLY of the form:\n  {\"correctness\": <1-5>, \"completeness\": <1-5>, \"precision\": <1-5>, \"coherence\": <1-5>, \"relevance\": <1-5>}\n- No additional text, explanation, or whitespace outside the JSON object.\n\nFEW-SHOT EXAMPLE (this demonstrates the required output; do not include the example in actual responses):\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"No, the capital of Germany is not Paris, the capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":5,\"coherence\":5,\"relevance\":5}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"The capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":3,\"completeness\":2,\"precision\":5,\"coherence\":5,\"relevance\":2}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"If capital stands for the central administrative region of a country, then no, Paris is not the capital of Germany. It's important to note what is the definintion of a 'capital'. However, due to the common popular opinion, a capital of a country is well defined.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":1,\"coherence\":4,\"relevance\":1}\n\nEND OF SYSTEM PROMPT."}, {"role": "user", "content": [{"type": "text", "text": "Question: "}, {"type": "text", "text": "Gold reference 1: \"The center of both the Aster amellus and the Wood Anemone is yellow.\""}, {"type": "text", "text": "Candidate answer: The center of both the Aster amellus and the Wood Anemone is yellow."}, {"type": "text", "text": "Please score the candidate exactly with the five integer ratings in JSON as instructed by the system prompt."}]}]}}
{"custom_id": "d5bc7d1c0dba11ecb1e81171463288e9_geval", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-mini-2025-04-14", "max_tokens": 200, "temperature": 1, "n": 20, "messages": [{"role": "system", "content": "You are an evaluation assistant. You will be given:\n  - A question Q.\n  - A gold/reference answer (one or more short reference sentences).\n  - A candidate/sample answer produced by a system.\n\nYour job is to **assign integer scores** (1..5) for the following criteria comparing the *candidate* to the *gold/reference*:\n\n1. correctness (1-5): How factually correct is the candidate vs the gold answer? (5 = fully correct, 1 = mostly or fully incorrect).\n2. completeness (1-5): How completely does the candidate cover the key points in the gold answer? (5 = covers all key points; 1 = almost none).\n3. precision (1-5): How concise and focused is the candidate (not too long answer)? (5 = concise & precise; 1 = verbose / many extraneous claims).\n4. coherence (1-5): Is the candidate fluent and well-structured? (5 = natural, coherent; 1 = disfluent or incoherent).\n5. relevance (1-5): Are the statements in the candidate relevant to the question and gold answer (not introducing unrelated claims)? (5 = fully relevant; 1 = mostly irrelevant).\n\nREQUIREMENTS (strict):\n- Output **ONLY** a JSON object EXACTLY of the form:\n  {\"correctness\": <1-5>, \"completeness\": <1-5>, \"precision\": <1-5>, \"coherence\": <1-5>, \"relevance\": <1-5>}\n- No additional text, explanation, or whitespace outside the JSON object.\n\nFEW-SHOT EXAMPLE (this demonstrates the required output; do not include the example in actual responses):\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"No, the capital of Germany is not Paris, the capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":5,\"coherence\":5,\"relevance\":5}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"The capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":3,\"completeness\":2,\"precision\":5,\"coherence\":5,\"relevance\":2}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"If capital stands for the central administrative region of a country, then no, Paris is not the capital of Germany. It's important to note what is the definintion of a 'capital'. However, due to the common popular opinion, a capital of a country is well defined.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":1,\"coherence\":4,\"relevance\":1}\n\nEND OF SYSTEM PROMPT."}, {"role": "user", "content": [{"type": "text", "text": "Question: "}, {"type": "text", "text": "Gold reference 1: \"There are three columns of non-English text above the most distant cliff in the artwork.\""}, {"type": "text", "text": "Candidate answer: There are two columns of non-English text above the most distant cliff in T'ang Yin's artwork."}, {"type": "text", "text": "Please score the candidate exactly with the five integer ratings in JSON as instructed by the system prompt."}]}]}}
{"custom_id": "d5bdc21c0dba11ecb1e81171463288e9_geval", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-mini-2025-04-14", "max_tokens": 200, "temperature": 1, "n": 20, "messages": [{"role": "system", "content": "You are an evaluation assistant. You will be given:\n  - A question Q.\n  - A gold/reference answer (one or more short reference sentences).\n  - A candidate/sample answer produced by a system.\n\nYour job is to **assign integer scores** (1..5) for the following criteria comparing the *candidate* to the *gold/reference*:\n\n1. correctness (1-5): How factually correct is the candidate vs the gold answer? (5 = fully correct, 1 = mostly or fully incorrect).\n2. completeness (1-5): How completely does the candidate cover the key points in the gold answer? (5 = covers all key points; 1 = almost none).\n3. precision (1-5): How concise and focused is the candidate (not too long answer)? (5 = concise & precise; 1 = verbose / many extraneous claims).\n4. coherence (1-5): Is the candidate fluent and well-structured? (5 = natural, coherent; 1 = disfluent or incoherent).\n5. relevance (1-5): Are the statements in the candidate relevant to the question and gold answer (not introducing unrelated claims)? (5 = fully relevant; 1 = mostly irrelevant).\n\nREQUIREMENTS (strict):\n- Output **ONLY** a JSON object EXACTLY of the form:\n  {\"correctness\": <1-5>, \"completeness\": <1-5>, \"precision\": <1-5>, \"coherence\": <1-5>, \"relevance\": <1-5>}\n- No additional text, explanation, or whitespace outside the JSON object.\n\nFEW-SHOT EXAMPLE (this demonstrates the required output; do not include the example in actual responses):\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"No, the capital of Germany is not Paris, the capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":5,\"coherence\":5,\"relevance\":5}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"The capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":3,\"completeness\":2,\"precision\":5,\"coherence\":5,\"relevance\":2}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"If capital stands for the central administrative region of a country, then no, Paris is not the capital of Germany. It's important to note what is the definintion of a 'capital'. However, due to the common popular opinion, a capital of a country is well defined.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":1,\"coherence\":4,\"relevance\":1}\n\nEND OF SYSTEM PROMPT."}, {"role": "user", "content": [{"type": "text", "text": "Question: "}, {"type": "text", "text": "Gold reference 1: \"The Church of Saint's Olga and Elizabeth has more steeples than St Patrick Roman Catholic Church in Elizabeth, N.J..\""}, {"type": "text", "text": "Candidate answer: The Church of Saints Olga and Elizabeth has more steeples, with three steeples compared to St. Patrick Roman Catholic Church, which has two."}, {"type": "text", "text": "Please score the candidate exactly with the five integer ratings in JSON as instructed by the system prompt."}]}]}}
{"custom_id": "d5be14c40dba11ecb1e81171463288e9_geval", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-mini-2025-04-14", "max_tokens": 200, "temperature": 1, "n": 20, "messages": [{"role": "system", "content": "You are an evaluation assistant. You will be given:\n  - A question Q.\n  - A gold/reference answer (one or more short reference sentences).\n  - A candidate/sample answer produced by a system.\n\nYour job is to **assign integer scores** (1..5) for the following criteria comparing the *candidate* to the *gold/reference*:\n\n1. correctness (1-5): How factually correct is the candidate vs the gold answer? (5 = fully correct, 1 = mostly or fully incorrect).\n2. completeness (1-5): How completely does the candidate cover the key points in the gold answer? (5 = covers all key points; 1 = almost none).\n3. precision (1-5): How concise and focused is the candidate (not too long answer)? (5 = concise & precise; 1 = verbose / many extraneous claims).\n4. coherence (1-5): Is the candidate fluent and well-structured? (5 = natural, coherent; 1 = disfluent or incoherent).\n5. relevance (1-5): Are the statements in the candidate relevant to the question and gold answer (not introducing unrelated claims)? (5 = fully relevant; 1 = mostly irrelevant).\n\nREQUIREMENTS (strict):\n- Output **ONLY** a JSON object EXACTLY of the form:\n  {\"correctness\": <1-5>, \"completeness\": <1-5>, \"precision\": <1-5>, \"coherence\": <1-5>, \"relevance\": <1-5>}\n- No additional text, explanation, or whitespace outside the JSON object.\n\nFEW-SHOT EXAMPLE (this demonstrates the required output; do not include the example in actual responses):\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"No, the capital of Germany is not Paris, the capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":5,\"coherence\":5,\"relevance\":5}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"The capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":3,\"completeness\":2,\"precision\":5,\"coherence\":5,\"relevance\":2}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"If capital stands for the central administrative region of a country, then no, Paris is not the capital of Germany. It's important to note what is the definintion of a 'capital'. However, due to the common popular opinion, a capital of a country is well defined.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":1,\"coherence\":4,\"relevance\":1}\n\nEND OF SYSTEM PROMPT."}, {"role": "user", "content": [{"type": "text", "text": "Question: "}, {"type": "text", "text": "Gold reference 1: \"Yes the sculptures of Near to Reading Abbey and The Burghers of Calais are black in color.\""}, {"type": "text", "text": "Candidate answer: Yes, both the Modern Sculpture near Reading Abbey and The Burghers of Calais are black."}, {"type": "text", "text": "Please score the candidate exactly with the five integer ratings in JSON as instructed by the system prompt."}]}]}}
{"custom_id": "d5becc340dba11ecb1e81171463288e9_geval", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-mini-2025-04-14", "max_tokens": 200, "temperature": 1, "n": 20, "messages": [{"role": "system", "content": "You are an evaluation assistant. You will be given:\n  - A question Q.\n  - A gold/reference answer (one or more short reference sentences).\n  - A candidate/sample answer produced by a system.\n\nYour job is to **assign integer scores** (1..5) for the following criteria comparing the *candidate* to the *gold/reference*:\n\n1. correctness (1-5): How factually correct is the candidate vs the gold answer? (5 = fully correct, 1 = mostly or fully incorrect).\n2. completeness (1-5): How completely does the candidate cover the key points in the gold answer? (5 = covers all key points; 1 = almost none).\n3. precision (1-5): How concise and focused is the candidate (not too long answer)? (5 = concise & precise; 1 = verbose / many extraneous claims).\n4. coherence (1-5): Is the candidate fluent and well-structured? (5 = natural, coherent; 1 = disfluent or incoherent).\n5. relevance (1-5): Are the statements in the candidate relevant to the question and gold answer (not introducing unrelated claims)? (5 = fully relevant; 1 = mostly irrelevant).\n\nREQUIREMENTS (strict):\n- Output **ONLY** a JSON object EXACTLY of the form:\n  {\"correctness\": <1-5>, \"completeness\": <1-5>, \"precision\": <1-5>, \"coherence\": <1-5>, \"relevance\": <1-5>}\n- No additional text, explanation, or whitespace outside the JSON object.\n\nFEW-SHOT EXAMPLE (this demonstrates the required output; do not include the example in actual responses):\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"No, the capital of Germany is not Paris, the capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":5,\"coherence\":5,\"relevance\":5}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"The capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":3,\"completeness\":2,\"precision\":5,\"coherence\":5,\"relevance\":2}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"If capital stands for the central administrative region of a country, then no, Paris is not the capital of Germany. It's important to note what is the definintion of a 'capital'. However, due to the common popular opinion, a capital of a country is well defined.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":1,\"coherence\":4,\"relevance\":1}\n\nEND OF SYSTEM PROMPT."}, {"role": "user", "content": [{"type": "text", "text": "Question: "}, {"type": "text", "text": "Gold reference 1: \"No, the man's bangs do not cover part of his forehead in both of the Self-portraits by Jacques-Louis David\""}, {"type": "text", "text": "Candidate answer: Yes, in both self-portraits by Jacques-Louis David, the man's bangs cover part of his forehead."}, {"type": "text", "text": "Please score the candidate exactly with the five integer ratings in JSON as instructed by the system prompt."}]}]}}
{"custom_id": "d5bc1b380dba11ecb1e81171463288e9_geval", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-mini-2025-04-14", "max_tokens": 200, "temperature": 1, "n": 20, "messages": [{"role": "system", "content": "You are an evaluation assistant. You will be given:\n  - A question Q.\n  - A gold/reference answer (one or more short reference sentences).\n  - A candidate/sample answer produced by a system.\n\nYour job is to **assign integer scores** (1..5) for the following criteria comparing the *candidate* to the *gold/reference*:\n\n1. correctness (1-5): How factually correct is the candidate vs the gold answer? (5 = fully correct, 1 = mostly or fully incorrect).\n2. completeness (1-5): How completely does the candidate cover the key points in the gold answer? (5 = covers all key points; 1 = almost none).\n3. precision (1-5): How concise and focused is the candidate (not too long answer)? (5 = concise & precise; 1 = verbose / many extraneous claims).\n4. coherence (1-5): Is the candidate fluent and well-structured? (5 = natural, coherent; 1 = disfluent or incoherent).\n5. relevance (1-5): Are the statements in the candidate relevant to the question and gold answer (not introducing unrelated claims)? (5 = fully relevant; 1 = mostly irrelevant).\n\nREQUIREMENTS (strict):\n- Output **ONLY** a JSON object EXACTLY of the form:\n  {\"correctness\": <1-5>, \"completeness\": <1-5>, \"precision\": <1-5>, \"coherence\": <1-5>, \"relevance\": <1-5>}\n- No additional text, explanation, or whitespace outside the JSON object.\n\nFEW-SHOT EXAMPLE (this demonstrates the required output; do not include the example in actual responses):\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"No, the capital of Germany is not Paris, the capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":5,\"coherence\":5,\"relevance\":5}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"The capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":3,\"completeness\":2,\"precision\":5,\"coherence\":5,\"relevance\":2}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"If capital stands for the central administrative region of a country, then no, Paris is not the capital of Germany. It's important to note what is the definintion of a 'capital'. However, due to the common popular opinion, a capital of a country is well defined.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":1,\"coherence\":4,\"relevance\":1}\n\nEND OF SYSTEM PROMPT."}, {"role": "user", "content": [{"type": "text", "text": "Question: "}, {"type": "text", "text": "Gold reference 1: \"There are six lights suspended from the ceiling of the reading room in Rush Rhees Library at the University of Rochester.\""}, {"type": "text", "text": "Candidate answer: There are eight lights suspended from the ceiling of the Reading room in Rush Rhees Library at the University of Rochester."}, {"type": "text", "text": "Please score the candidate exactly with the five integer ratings in JSON as instructed by the system prompt."}]}]}}
{"custom_id": "d5bfa3a20dba11ecb1e81171463288e9_geval", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-mini-2025-04-14", "max_tokens": 200, "temperature": 1, "n": 20, "messages": [{"role": "system", "content": "You are an evaluation assistant. You will be given:\n  - A question Q.\n  - A gold/reference answer (one or more short reference sentences).\n  - A candidate/sample answer produced by a system.\n\nYour job is to **assign integer scores** (1..5) for the following criteria comparing the *candidate* to the *gold/reference*:\n\n1. correctness (1-5): How factually correct is the candidate vs the gold answer? (5 = fully correct, 1 = mostly or fully incorrect).\n2. completeness (1-5): How completely does the candidate cover the key points in the gold answer? (5 = covers all key points; 1 = almost none).\n3. precision (1-5): How concise and focused is the candidate (not too long answer)? (5 = concise & precise; 1 = verbose / many extraneous claims).\n4. coherence (1-5): Is the candidate fluent and well-structured? (5 = natural, coherent; 1 = disfluent or incoherent).\n5. relevance (1-5): Are the statements in the candidate relevant to the question and gold answer (not introducing unrelated claims)? (5 = fully relevant; 1 = mostly irrelevant).\n\nREQUIREMENTS (strict):\n- Output **ONLY** a JSON object EXACTLY of the form:\n  {\"correctness\": <1-5>, \"completeness\": <1-5>, \"precision\": <1-5>, \"coherence\": <1-5>, \"relevance\": <1-5>}\n- No additional text, explanation, or whitespace outside the JSON object.\n\nFEW-SHOT EXAMPLE (this demonstrates the required output; do not include the example in actual responses):\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"No, the capital of Germany is not Paris, the capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":5,\"coherence\":5,\"relevance\":5}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"The capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":3,\"completeness\":2,\"precision\":5,\"coherence\":5,\"relevance\":2}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"If capital stands for the central administrative region of a country, then no, Paris is not the capital of Germany. It's important to note what is the definintion of a 'capital'. However, due to the common popular opinion, a capital of a country is well defined.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":1,\"coherence\":4,\"relevance\":1}\n\nEND OF SYSTEM PROMPT."}, {"role": "user", "content": [{"type": "text", "text": "Question: "}, {"type": "text", "text": "Gold reference 1: \"No, there were more than three people fully nude and covered in paint.\""}, {"type": "text", "text": "Candidate answer: No, there were at least three people fully nude and covered in paint in Museumplein on 12th August 2017."}, {"type": "text", "text": "Please score the candidate exactly with the five integer ratings in JSON as instructed by the system prompt."}]}]}}
{"custom_id": "d5bd8d4c0dba11ecb1e81171463288e9_geval", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-mini-2025-04-14", "max_tokens": 200, "temperature": 1, "n": 20, "messages": [{"role": "system", "content": "You are an evaluation assistant. You will be given:\n  - A question Q.\n  - A gold/reference answer (one or more short reference sentences).\n  - A candidate/sample answer produced by a system.\n\nYour job is to **assign integer scores** (1..5) for the following criteria comparing the *candidate* to the *gold/reference*:\n\n1. correctness (1-5): How factually correct is the candidate vs the gold answer? (5 = fully correct, 1 = mostly or fully incorrect).\n2. completeness (1-5): How completely does the candidate cover the key points in the gold answer? (5 = covers all key points; 1 = almost none).\n3. precision (1-5): How concise and focused is the candidate (not too long answer)? (5 = concise & precise; 1 = verbose / many extraneous claims).\n4. coherence (1-5): Is the candidate fluent and well-structured? (5 = natural, coherent; 1 = disfluent or incoherent).\n5. relevance (1-5): Are the statements in the candidate relevant to the question and gold answer (not introducing unrelated claims)? (5 = fully relevant; 1 = mostly irrelevant).\n\nREQUIREMENTS (strict):\n- Output **ONLY** a JSON object EXACTLY of the form:\n  {\"correctness\": <1-5>, \"completeness\": <1-5>, \"precision\": <1-5>, \"coherence\": <1-5>, \"relevance\": <1-5>}\n- No additional text, explanation, or whitespace outside the JSON object.\n\nFEW-SHOT EXAMPLE (this demonstrates the required output; do not include the example in actual responses):\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"No, the capital of Germany is not Paris, the capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":5,\"coherence\":5,\"relevance\":5}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"The capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":3,\"completeness\":2,\"precision\":5,\"coherence\":5,\"relevance\":2}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"If capital stands for the central administrative region of a country, then no, Paris is not the capital of Germany. It's important to note what is the definintion of a 'capital'. However, due to the common popular opinion, a capital of a country is well defined.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":1,\"coherence\":4,\"relevance\":1}\n\nEND OF SYSTEM PROMPT."}, {"role": "user", "content": [{"type": "text", "text": "Question: "}, {"type": "text", "text": "Gold reference 1: \"Hydnum Umbilicatum is shinier on top.\""}, {"type": "text", "text": "Candidate answer: Hydnum umbilicatum is shinier on top compared to Leccinum melaneum."}, {"type": "text", "text": "Please score the candidate exactly with the five integer ratings in JSON as instructed by the system prompt."}]}]}}
{"custom_id": "d5bc4f900dba11ecb1e81171463288e9_geval", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-mini-2025-04-14", "max_tokens": 200, "temperature": 1, "n": 20, "messages": [{"role": "system", "content": "You are an evaluation assistant. You will be given:\n  - A question Q.\n  - A gold/reference answer (one or more short reference sentences).\n  - A candidate/sample answer produced by a system.\n\nYour job is to **assign integer scores** (1..5) for the following criteria comparing the *candidate* to the *gold/reference*:\n\n1. correctness (1-5): How factually correct is the candidate vs the gold answer? (5 = fully correct, 1 = mostly or fully incorrect).\n2. completeness (1-5): How completely does the candidate cover the key points in the gold answer? (5 = covers all key points; 1 = almost none).\n3. precision (1-5): How concise and focused is the candidate (not too long answer)? (5 = concise & precise; 1 = verbose / many extraneous claims).\n4. coherence (1-5): Is the candidate fluent and well-structured? (5 = natural, coherent; 1 = disfluent or incoherent).\n5. relevance (1-5): Are the statements in the candidate relevant to the question and gold answer (not introducing unrelated claims)? (5 = fully relevant; 1 = mostly irrelevant).\n\nREQUIREMENTS (strict):\n- Output **ONLY** a JSON object EXACTLY of the form:\n  {\"correctness\": <1-5>, \"completeness\": <1-5>, \"precision\": <1-5>, \"coherence\": <1-5>, \"relevance\": <1-5>}\n- No additional text, explanation, or whitespace outside the JSON object.\n\nFEW-SHOT EXAMPLE (this demonstrates the required output; do not include the example in actual responses):\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"No, the capital of Germany is not Paris, the capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":5,\"coherence\":5,\"relevance\":5}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"The capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":3,\"completeness\":2,\"precision\":5,\"coherence\":5,\"relevance\":2}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"If capital stands for the central administrative region of a country, then no, Paris is not the capital of Germany. It's important to note what is the definintion of a 'capital'. However, due to the common popular opinion, a capital of a country is well defined.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":1,\"coherence\":4,\"relevance\":1}\n\nEND OF SYSTEM PROMPT."}, {"role": "user", "content": [{"type": "text", "text": "Question: "}, {"type": "text", "text": "Gold reference 1: \"A net is behind discus throwers while they compete.\""}, {"type": "text", "text": "Candidate answer: The protective barrier behind discus throwers is a net that catches the discus after it is thrown."}, {"type": "text", "text": "Please score the candidate exactly with the five integer ratings in JSON as instructed by the system prompt."}]}]}}
{"custom_id": "d5be7b800dba11ecb1e81171463288e9_geval", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-mini-2025-04-14", "max_tokens": 200, "temperature": 1, "n": 20, "messages": [{"role": "system", "content": "You are an evaluation assistant. You will be given:\n  - A question Q.\n  - A gold/reference answer (one or more short reference sentences).\n  - A candidate/sample answer produced by a system.\n\nYour job is to **assign integer scores** (1..5) for the following criteria comparing the *candidate* to the *gold/reference*:\n\n1. correctness (1-5): How factually correct is the candidate vs the gold answer? (5 = fully correct, 1 = mostly or fully incorrect).\n2. completeness (1-5): How completely does the candidate cover the key points in the gold answer? (5 = covers all key points; 1 = almost none).\n3. precision (1-5): How concise and focused is the candidate (not too long answer)? (5 = concise & precise; 1 = verbose / many extraneous claims).\n4. coherence (1-5): Is the candidate fluent and well-structured? (5 = natural, coherent; 1 = disfluent or incoherent).\n5. relevance (1-5): Are the statements in the candidate relevant to the question and gold answer (not introducing unrelated claims)? (5 = fully relevant; 1 = mostly irrelevant).\n\nREQUIREMENTS (strict):\n- Output **ONLY** a JSON object EXACTLY of the form:\n  {\"correctness\": <1-5>, \"completeness\": <1-5>, \"precision\": <1-5>, \"coherence\": <1-5>, \"relevance\": <1-5>}\n- No additional text, explanation, or whitespace outside the JSON object.\n\nFEW-SHOT EXAMPLE (this demonstrates the required output; do not include the example in actual responses):\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"No, the capital of Germany is not Paris, the capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":5,\"coherence\":5,\"relevance\":5}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"The capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":3,\"completeness\":2,\"precision\":5,\"coherence\":5,\"relevance\":2}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"If capital stands for the central administrative region of a country, then no, Paris is not the capital of Germany. It's important to note what is the definintion of a 'capital'. However, due to the common popular opinion, a capital of a country is well defined.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":1,\"coherence\":4,\"relevance\":1}\n\nEND OF SYSTEM PROMPT."}, {"role": "user", "content": [{"type": "text", "text": "Question: "}, {"type": "text", "text": "Gold reference 1: \"The middle of the podium is the tallest.\""}, {"type": "text", "text": "Candidate answer: The tallest part of the podium for the 2014 Winter Olympics men's 1500m award ceremony is the center platform where the gold medalist Zbigniew Brodka stood."}, {"type": "text", "text": "Please score the candidate exactly with the five integer ratings in JSON as instructed by the system prompt."}]}]}}
{"custom_id": "d5bd9b700dba11ecb1e81171463288e9_geval", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-mini-2025-04-14", "max_tokens": 200, "temperature": 1, "n": 20, "messages": [{"role": "system", "content": "You are an evaluation assistant. You will be given:\n  - A question Q.\n  - A gold/reference answer (one or more short reference sentences).\n  - A candidate/sample answer produced by a system.\n\nYour job is to **assign integer scores** (1..5) for the following criteria comparing the *candidate* to the *gold/reference*:\n\n1. correctness (1-5): How factually correct is the candidate vs the gold answer? (5 = fully correct, 1 = mostly or fully incorrect).\n2. completeness (1-5): How completely does the candidate cover the key points in the gold answer? (5 = covers all key points; 1 = almost none).\n3. precision (1-5): How concise and focused is the candidate (not too long answer)? (5 = concise & precise; 1 = verbose / many extraneous claims).\n4. coherence (1-5): Is the candidate fluent and well-structured? (5 = natural, coherent; 1 = disfluent or incoherent).\n5. relevance (1-5): Are the statements in the candidate relevant to the question and gold answer (not introducing unrelated claims)? (5 = fully relevant; 1 = mostly irrelevant).\n\nREQUIREMENTS (strict):\n- Output **ONLY** a JSON object EXACTLY of the form:\n  {\"correctness\": <1-5>, \"completeness\": <1-5>, \"precision\": <1-5>, \"coherence\": <1-5>, \"relevance\": <1-5>}\n- No additional text, explanation, or whitespace outside the JSON object.\n\nFEW-SHOT EXAMPLE (this demonstrates the required output; do not include the example in actual responses):\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"No, the capital of Germany is not Paris, the capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":5,\"coherence\":5,\"relevance\":5}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"The capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":3,\"completeness\":2,\"precision\":5,\"coherence\":5,\"relevance\":2}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"If capital stands for the central administrative region of a country, then no, Paris is not the capital of Germany. It's important to note what is the definintion of a 'capital'. However, due to the common popular opinion, a capital of a country is well defined.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":1,\"coherence\":4,\"relevance\":1}\n\nEND OF SYSTEM PROMPT."}, {"role": "user", "content": [{"type": "text", "text": "Question: "}, {"type": "text", "text": "Gold reference 1: \"The Bel-Tun player has a number on both his shorts and his shirt.\""}, {"type": "text", "text": "Candidate answer: Yes, the Bel-Tun player has a number on both his shorts and his shirt."}, {"type": "text", "text": "Please score the candidate exactly with the five integer ratings in JSON as instructed by the system prompt."}]}]}}
{"custom_id": "d5bd0d0e0dba11ecb1e81171463288e9_geval", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-mini-2025-04-14", "max_tokens": 200, "temperature": 1, "n": 20, "messages": [{"role": "system", "content": "You are an evaluation assistant. You will be given:\n  - A question Q.\n  - A gold/reference answer (one or more short reference sentences).\n  - A candidate/sample answer produced by a system.\n\nYour job is to **assign integer scores** (1..5) for the following criteria comparing the *candidate* to the *gold/reference*:\n\n1. correctness (1-5): How factually correct is the candidate vs the gold answer? (5 = fully correct, 1 = mostly or fully incorrect).\n2. completeness (1-5): How completely does the candidate cover the key points in the gold answer? (5 = covers all key points; 1 = almost none).\n3. precision (1-5): How concise and focused is the candidate (not too long answer)? (5 = concise & precise; 1 = verbose / many extraneous claims).\n4. coherence (1-5): Is the candidate fluent and well-structured? (5 = natural, coherent; 1 = disfluent or incoherent).\n5. relevance (1-5): Are the statements in the candidate relevant to the question and gold answer (not introducing unrelated claims)? (5 = fully relevant; 1 = mostly irrelevant).\n\nREQUIREMENTS (strict):\n- Output **ONLY** a JSON object EXACTLY of the form:\n  {\"correctness\": <1-5>, \"completeness\": <1-5>, \"precision\": <1-5>, \"coherence\": <1-5>, \"relevance\": <1-5>}\n- No additional text, explanation, or whitespace outside the JSON object.\n\nFEW-SHOT EXAMPLE (this demonstrates the required output; do not include the example in actual responses):\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"No, the capital of Germany is not Paris, the capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":5,\"coherence\":5,\"relevance\":5}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"The capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":3,\"completeness\":2,\"precision\":5,\"coherence\":5,\"relevance\":2}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"If capital stands for the central administrative region of a country, then no, Paris is not the capital of Germany. It's important to note what is the definintion of a 'capital'. However, due to the common popular opinion, a capital of a country is well defined.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":1,\"coherence\":4,\"relevance\":1}\n\nEND OF SYSTEM PROMPT."}, {"role": "user", "content": [{"type": "text", "text": "Question: "}, {"type": "text", "text": "Gold reference 1: \"The American flag is flown in front of 481 8th Ave, New York.\""}, {"type": "text", "text": "Candidate answer: The flag being flown in front of 481 8th Ave, New York, is the American flag."}, {"type": "text", "text": "Please score the candidate exactly with the five integer ratings in JSON as instructed by the system prompt."}]}]}}
{"custom_id": "d5bf12520dba11ecb1e81171463288e9_geval", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-mini-2025-04-14", "max_tokens": 200, "temperature": 1, "n": 20, "messages": [{"role": "system", "content": "You are an evaluation assistant. You will be given:\n  - A question Q.\n  - A gold/reference answer (one or more short reference sentences).\n  - A candidate/sample answer produced by a system.\n\nYour job is to **assign integer scores** (1..5) for the following criteria comparing the *candidate* to the *gold/reference*:\n\n1. correctness (1-5): How factually correct is the candidate vs the gold answer? (5 = fully correct, 1 = mostly or fully incorrect).\n2. completeness (1-5): How completely does the candidate cover the key points in the gold answer? (5 = covers all key points; 1 = almost none).\n3. precision (1-5): How concise and focused is the candidate (not too long answer)? (5 = concise & precise; 1 = verbose / many extraneous claims).\n4. coherence (1-5): Is the candidate fluent and well-structured? (5 = natural, coherent; 1 = disfluent or incoherent).\n5. relevance (1-5): Are the statements in the candidate relevant to the question and gold answer (not introducing unrelated claims)? (5 = fully relevant; 1 = mostly irrelevant).\n\nREQUIREMENTS (strict):\n- Output **ONLY** a JSON object EXACTLY of the form:\n  {\"correctness\": <1-5>, \"completeness\": <1-5>, \"precision\": <1-5>, \"coherence\": <1-5>, \"relevance\": <1-5>}\n- No additional text, explanation, or whitespace outside the JSON object.\n\nFEW-SHOT EXAMPLE (this demonstrates the required output; do not include the example in actual responses):\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"No, the capital of Germany is not Paris, the capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":5,\"coherence\":5,\"relevance\":5}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"The capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":3,\"completeness\":2,\"precision\":5,\"coherence\":5,\"relevance\":2}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"If capital stands for the central administrative region of a country, then no, Paris is not the capital of Germany. It's important to note what is the definintion of a 'capital'. However, due to the common popular opinion, a capital of a country is well defined.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":1,\"coherence\":4,\"relevance\":1}\n\nEND OF SYSTEM PROMPT."}, {"role": "user", "content": [{"type": "text", "text": "Question: "}, {"type": "text", "text": "Gold reference 1: \"The Olympic ring appears twice on the front of the shirt that Olympic torchbearer Fred Atkins wore in 2000.\""}, {"type": "text", "text": "Candidate answer: The Olympic rings appear twice on the front of the shirt that Olympic torchbearer Fred Atkins wore in 2000."}, {"type": "text", "text": "Please score the candidate exactly with the five integer ratings in JSON as instructed by the system prompt."}]}]}}
{"custom_id": "d5bc10c00dba11ecb1e81171463288e9_geval", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-mini-2025-04-14", "max_tokens": 200, "temperature": 1, "n": 20, "messages": [{"role": "system", "content": "You are an evaluation assistant. You will be given:\n  - A question Q.\n  - A gold/reference answer (one or more short reference sentences).\n  - A candidate/sample answer produced by a system.\n\nYour job is to **assign integer scores** (1..5) for the following criteria comparing the *candidate* to the *gold/reference*:\n\n1. correctness (1-5): How factually correct is the candidate vs the gold answer? (5 = fully correct, 1 = mostly or fully incorrect).\n2. completeness (1-5): How completely does the candidate cover the key points in the gold answer? (5 = covers all key points; 1 = almost none).\n3. precision (1-5): How concise and focused is the candidate (not too long answer)? (5 = concise & precise; 1 = verbose / many extraneous claims).\n4. coherence (1-5): Is the candidate fluent and well-structured? (5 = natural, coherent; 1 = disfluent or incoherent).\n5. relevance (1-5): Are the statements in the candidate relevant to the question and gold answer (not introducing unrelated claims)? (5 = fully relevant; 1 = mostly irrelevant).\n\nREQUIREMENTS (strict):\n- Output **ONLY** a JSON object EXACTLY of the form:\n  {\"correctness\": <1-5>, \"completeness\": <1-5>, \"precision\": <1-5>, \"coherence\": <1-5>, \"relevance\": <1-5>}\n- No additional text, explanation, or whitespace outside the JSON object.\n\nFEW-SHOT EXAMPLE (this demonstrates the required output; do not include the example in actual responses):\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"No, the capital of Germany is not Paris, the capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":5,\"coherence\":5,\"relevance\":5}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"The capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":3,\"completeness\":2,\"precision\":5,\"coherence\":5,\"relevance\":2}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"If capital stands for the central administrative region of a country, then no, Paris is not the capital of Germany. It's important to note what is the definintion of a 'capital'. However, due to the common popular opinion, a capital of a country is well defined.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":1,\"coherence\":4,\"relevance\":1}\n\nEND OF SYSTEM PROMPT."}, {"role": "user", "content": [{"type": "text", "text": "Question: "}, {"type": "text", "text": "Gold reference 1: \"Each dragon arum blossom has one petal.\""}, {"type": "text", "text": "Candidate answer: Each dragon arum blossom (Dracunculus vulgaris) typically has six petals."}, {"type": "text", "text": "Please score the candidate exactly with the five integer ratings in JSON as instructed by the system prompt."}]}]}}
{"custom_id": "d5bdd7840dba11ecb1e81171463288e9_geval", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-mini-2025-04-14", "max_tokens": 200, "temperature": 1, "n": 20, "messages": [{"role": "system", "content": "You are an evaluation assistant. You will be given:\n  - A question Q.\n  - A gold/reference answer (one or more short reference sentences).\n  - A candidate/sample answer produced by a system.\n\nYour job is to **assign integer scores** (1..5) for the following criteria comparing the *candidate* to the *gold/reference*:\n\n1. correctness (1-5): How factually correct is the candidate vs the gold answer? (5 = fully correct, 1 = mostly or fully incorrect).\n2. completeness (1-5): How completely does the candidate cover the key points in the gold answer? (5 = covers all key points; 1 = almost none).\n3. precision (1-5): How concise and focused is the candidate (not too long answer)? (5 = concise & precise; 1 = verbose / many extraneous claims).\n4. coherence (1-5): Is the candidate fluent and well-structured? (5 = natural, coherent; 1 = disfluent or incoherent).\n5. relevance (1-5): Are the statements in the candidate relevant to the question and gold answer (not introducing unrelated claims)? (5 = fully relevant; 1 = mostly irrelevant).\n\nREQUIREMENTS (strict):\n- Output **ONLY** a JSON object EXACTLY of the form:\n  {\"correctness\": <1-5>, \"completeness\": <1-5>, \"precision\": <1-5>, \"coherence\": <1-5>, \"relevance\": <1-5>}\n- No additional text, explanation, or whitespace outside the JSON object.\n\nFEW-SHOT EXAMPLE (this demonstrates the required output; do not include the example in actual responses):\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"No, the capital of Germany is not Paris, the capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":5,\"coherence\":5,\"relevance\":5}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"The capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":3,\"completeness\":2,\"precision\":5,\"coherence\":5,\"relevance\":2}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"If capital stands for the central administrative region of a country, then no, Paris is not the capital of Germany. It's important to note what is the definintion of a 'capital'. However, due to the common popular opinion, a capital of a country is well defined.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":1,\"coherence\":4,\"relevance\":1}\n\nEND OF SYSTEM PROMPT."}, {"role": "user", "content": [{"type": "text", "text": "Question: "}, {"type": "text", "text": "Gold reference 1: \"The Black oystercatcher has an orange beak.\""}, {"type": "text", "text": "Candidate answer: The Black-oystercatcher has a bright orange beak."}, {"type": "text", "text": "Please score the candidate exactly with the five integer ratings in JSON as instructed by the system prompt."}]}]}}
{"custom_id": "d5beeb4c0dba11ecb1e81171463288e9_geval", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-mini-2025-04-14", "max_tokens": 200, "temperature": 1, "n": 20, "messages": [{"role": "system", "content": "You are an evaluation assistant. You will be given:\n  - A question Q.\n  - A gold/reference answer (one or more short reference sentences).\n  - A candidate/sample answer produced by a system.\n\nYour job is to **assign integer scores** (1..5) for the following criteria comparing the *candidate* to the *gold/reference*:\n\n1. correctness (1-5): How factually correct is the candidate vs the gold answer? (5 = fully correct, 1 = mostly or fully incorrect).\n2. completeness (1-5): How completely does the candidate cover the key points in the gold answer? (5 = covers all key points; 1 = almost none).\n3. precision (1-5): How concise and focused is the candidate (not too long answer)? (5 = concise & precise; 1 = verbose / many extraneous claims).\n4. coherence (1-5): Is the candidate fluent and well-structured? (5 = natural, coherent; 1 = disfluent or incoherent).\n5. relevance (1-5): Are the statements in the candidate relevant to the question and gold answer (not introducing unrelated claims)? (5 = fully relevant; 1 = mostly irrelevant).\n\nREQUIREMENTS (strict):\n- Output **ONLY** a JSON object EXACTLY of the form:\n  {\"correctness\": <1-5>, \"completeness\": <1-5>, \"precision\": <1-5>, \"coherence\": <1-5>, \"relevance\": <1-5>}\n- No additional text, explanation, or whitespace outside the JSON object.\n\nFEW-SHOT EXAMPLE (this demonstrates the required output; do not include the example in actual responses):\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"No, the capital of Germany is not Paris, the capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":5,\"coherence\":5,\"relevance\":5}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"The capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":3,\"completeness\":2,\"precision\":5,\"coherence\":5,\"relevance\":2}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"If capital stands for the central administrative region of a country, then no, Paris is not the capital of Germany. It's important to note what is the definintion of a 'capital'. However, due to the common popular opinion, a capital of a country is well defined.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":1,\"coherence\":4,\"relevance\":1}\n\nEND OF SYSTEM PROMPT."}, {"role": "user", "content": [{"type": "text", "text": "Question: "}, {"type": "text", "text": "Gold reference 1: \"The clock on the face of Bournemouth: The College is not centered with respect to the building.\""}, {"type": "text", "text": "Candidate answer: Yes, the clock on the face of Bournemouth: The College is centered with respect to the building."}, {"type": "text", "text": "Please score the candidate exactly with the five integer ratings in JSON as instructed by the system prompt."}]}]}}
{"custom_id": "d5bfad340dba11ecb1e81171463288e9_geval", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-mini-2025-04-14", "max_tokens": 200, "temperature": 1, "n": 20, "messages": [{"role": "system", "content": "You are an evaluation assistant. You will be given:\n  - A question Q.\n  - A gold/reference answer (one or more short reference sentences).\n  - A candidate/sample answer produced by a system.\n\nYour job is to **assign integer scores** (1..5) for the following criteria comparing the *candidate* to the *gold/reference*:\n\n1. correctness (1-5): How factually correct is the candidate vs the gold answer? (5 = fully correct, 1 = mostly or fully incorrect).\n2. completeness (1-5): How completely does the candidate cover the key points in the gold answer? (5 = covers all key points; 1 = almost none).\n3. precision (1-5): How concise and focused is the candidate (not too long answer)? (5 = concise & precise; 1 = verbose / many extraneous claims).\n4. coherence (1-5): Is the candidate fluent and well-structured? (5 = natural, coherent; 1 = disfluent or incoherent).\n5. relevance (1-5): Are the statements in the candidate relevant to the question and gold answer (not introducing unrelated claims)? (5 = fully relevant; 1 = mostly irrelevant).\n\nREQUIREMENTS (strict):\n- Output **ONLY** a JSON object EXACTLY of the form:\n  {\"correctness\": <1-5>, \"completeness\": <1-5>, \"precision\": <1-5>, \"coherence\": <1-5>, \"relevance\": <1-5>}\n- No additional text, explanation, or whitespace outside the JSON object.\n\nFEW-SHOT EXAMPLE (this demonstrates the required output; do not include the example in actual responses):\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"No, the capital of Germany is not Paris, the capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":5,\"coherence\":5,\"relevance\":5}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"The capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":3,\"completeness\":2,\"precision\":5,\"coherence\":5,\"relevance\":2}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"If capital stands for the central administrative region of a country, then no, Paris is not the capital of Germany. It's important to note what is the definintion of a 'capital'. However, due to the common popular opinion, a capital of a country is well defined.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":1,\"coherence\":4,\"relevance\":1}\n\nEND OF SYSTEM PROMPT."}, {"role": "user", "content": [{"type": "text", "text": "Question: "}, {"type": "text", "text": "Gold reference 1: \"The men in Henri de Toulouse-Lautrec's paintings \"The Englishman (William Tom Warrener, 1861–1934) at the Moulin Rouge\" and \"Baraque de la Goulue à la Foire du Trône: La danse au Moulin Rouge)\" are wearing tall hats.\""}, {"type": "text", "text": "Candidate answer: The men in Henri de Toulouse-Lautrec's paintings are wearing top hats."}, {"type": "text", "text": "Please score the candidate exactly with the five integer ratings in JSON as instructed by the system prompt."}]}]}}
{"custom_id": "d5bfa1860dba11ecb1e81171463288e9_geval", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-mini-2025-04-14", "max_tokens": 200, "temperature": 1, "n": 20, "messages": [{"role": "system", "content": "You are an evaluation assistant. You will be given:\n  - A question Q.\n  - A gold/reference answer (one or more short reference sentences).\n  - A candidate/sample answer produced by a system.\n\nYour job is to **assign integer scores** (1..5) for the following criteria comparing the *candidate* to the *gold/reference*:\n\n1. correctness (1-5): How factually correct is the candidate vs the gold answer? (5 = fully correct, 1 = mostly or fully incorrect).\n2. completeness (1-5): How completely does the candidate cover the key points in the gold answer? (5 = covers all key points; 1 = almost none).\n3. precision (1-5): How concise and focused is the candidate (not too long answer)? (5 = concise & precise; 1 = verbose / many extraneous claims).\n4. coherence (1-5): Is the candidate fluent and well-structured? (5 = natural, coherent; 1 = disfluent or incoherent).\n5. relevance (1-5): Are the statements in the candidate relevant to the question and gold answer (not introducing unrelated claims)? (5 = fully relevant; 1 = mostly irrelevant).\n\nREQUIREMENTS (strict):\n- Output **ONLY** a JSON object EXACTLY of the form:\n  {\"correctness\": <1-5>, \"completeness\": <1-5>, \"precision\": <1-5>, \"coherence\": <1-5>, \"relevance\": <1-5>}\n- No additional text, explanation, or whitespace outside the JSON object.\n\nFEW-SHOT EXAMPLE (this demonstrates the required output; do not include the example in actual responses):\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"No, the capital of Germany is not Paris, the capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":5,\"coherence\":5,\"relevance\":5}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"The capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":3,\"completeness\":2,\"precision\":5,\"coherence\":5,\"relevance\":2}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"If capital stands for the central administrative region of a country, then no, Paris is not the capital of Germany. It's important to note what is the definintion of a 'capital'. However, due to the common popular opinion, a capital of a country is well defined.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":1,\"coherence\":4,\"relevance\":1}\n\nEND OF SYSTEM PROMPT."}, {"role": "user", "content": [{"type": "text", "text": "Question: "}, {"type": "text", "text": "Gold reference 1: \"There are two handles on the container next to the fountain in the painting \"Women feeding fish in a Pompeian Atrium by Luigi Bazzani.\""}, {"type": "text", "text": "Candidate answer: The container next to the fountain in the painting \"Women feeding fish in a Pompeian Atrium by Luigi Bazzani\" has two handles."}, {"type": "text", "text": "Please score the candidate exactly with the five integer ratings in JSON as instructed by the system prompt."}]}]}}
{"custom_id": "d5be50a60dba11ecb1e81171463288e9_geval", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-mini-2025-04-14", "max_tokens": 200, "temperature": 1, "n": 20, "messages": [{"role": "system", "content": "You are an evaluation assistant. You will be given:\n  - A question Q.\n  - A gold/reference answer (one or more short reference sentences).\n  - A candidate/sample answer produced by a system.\n\nYour job is to **assign integer scores** (1..5) for the following criteria comparing the *candidate* to the *gold/reference*:\n\n1. correctness (1-5): How factually correct is the candidate vs the gold answer? (5 = fully correct, 1 = mostly or fully incorrect).\n2. completeness (1-5): How completely does the candidate cover the key points in the gold answer? (5 = covers all key points; 1 = almost none).\n3. precision (1-5): How concise and focused is the candidate (not too long answer)? (5 = concise & precise; 1 = verbose / many extraneous claims).\n4. coherence (1-5): Is the candidate fluent and well-structured? (5 = natural, coherent; 1 = disfluent or incoherent).\n5. relevance (1-5): Are the statements in the candidate relevant to the question and gold answer (not introducing unrelated claims)? (5 = fully relevant; 1 = mostly irrelevant).\n\nREQUIREMENTS (strict):\n- Output **ONLY** a JSON object EXACTLY of the form:\n  {\"correctness\": <1-5>, \"completeness\": <1-5>, \"precision\": <1-5>, \"coherence\": <1-5>, \"relevance\": <1-5>}\n- No additional text, explanation, or whitespace outside the JSON object.\n\nFEW-SHOT EXAMPLE (this demonstrates the required output; do not include the example in actual responses):\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"No, the capital of Germany is not Paris, the capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":5,\"coherence\":5,\"relevance\":5}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"The capital of Germany is Berlin.\"\n  Expected JSON output: {\"correctness\":3,\"completeness\":2,\"precision\":5,\"coherence\":5,\"relevance\":2}\n\n  Q: \"Is Paris the capital of Germany ?\"\n  Gold: \"No, Paris is not the capital of Germany.\"\n  Candidate: \"If capital stands for the central administrative region of a country, then no, Paris is not the capital of Germany. It's important to note what is the definintion of a 'capital'. However, due to the common popular opinion, a capital of a country is well defined.\"\n  Expected JSON output: {\"correctness\":5,\"completeness\":5,\"precision\":1,\"coherence\":4,\"relevance\":1}\n\nEND OF SYSTEM PROMPT."}, {"role": "user", "content": [{"type": "text", "text": "Question: "}, {"type": "text", "text": "Gold reference 1: \"The Montachusett Regional Vocational Technical School's structure is wider.\""}, {"type": "text", "text": "Candidate answer: The Montachusett Regional Vocational Technical School building is wider."}, {"type": "text", "text": "Please score the candidate exactly with the five integer ratings in JSON as instructed by the system prompt."}]}]}}
